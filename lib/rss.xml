<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[笔记]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>笔记</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Fri, 25 Jul 2025 16:20:00 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Fri, 25 Jul 2025 16:18:57 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[Maven 基础]]></title><description><![CDATA[ 
 <br><br>aaaa<br><br>Maven就是项目构建和管理工具，包含一个项目对象模型（POM）,大部分的情况下，通过配置pom的信息，管理项目中的依赖，报告以及项目的构建过程。<br>常用的命令：<br>清理：删除前面编译的结果，为后面重新编译和打包等做前期处理<br>编译compile：将java源文件编译成字节码文件<br>测试：针对项目中的关键点进行测试，主要使用在白盒测试中<br>报告：生成测试结果或者运行结果<br>打包package：通过此命令，可以将包含多个packege以及目录的文件生成一个压缩文件（jar或者war）<br>安装：将 jar 安装到本地仓库<br>部署：部署项目<br><br>到官网下载压缩包，解压到某个英文目录下。<br>本地仓库的默认目录：<br>​	C:\Users\mameiping.m2\repository<br>settings.xml当中进行配置<br>本地仓库<br>&lt;localRepository&gt;D:\maven-lib&lt;/localRepository&gt;
<br>远程仓库<br>&lt;mirror&gt;
		&lt;id&gt;aliyunmaven&lt;/id&gt;
		&lt;mirrorOf&gt;*&lt;/mirrorOf&gt;
		&lt;name&gt;alibaba&lt;/name&gt;
		&lt;url&gt;https://maven.aliyun.com/repository/public&lt;/url&gt;
	 &lt;/mirror&gt;
<br>jdk版本<br>&lt;profile&gt;
		  &lt;id&gt;jdk1.8&lt;/id&gt;
		  &lt;activation&gt;
			&lt;jdk&gt;1.8&lt;/jdk&gt;
			&lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
		  &lt;/activation&gt;
		  &lt;properties&gt;
			&lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
			&lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
			&lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;
			&lt;encoding&gt;UTF-8&lt;/encoding&gt;
		  &lt;/properties&gt;
	&lt;/profile&gt;
<br><br>本地仓库：当前使用的机器上，当程序运行的时候，先会去本地仓库获取相关的jar包<br>远程仓库：非本地，外网或者公司内部集中管理。<br>​	中央仓库：为全世界maven提供服务，在国外，速度有点慢<br>​	中央仓库的镜像：分担中央仓库的压力，在不同的地方都在服务器<br>​	私服：为当前局域网范围内提供服务<br><br><br>groupid，artifactId以及version称为依赖的坐标<br>&lt;groupId&gt;mysql&lt;/groupId&gt;
&lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
&lt;version&gt;6.0.6&lt;/version&gt;
<br><br>compile：默认范围，应用程序在编译，测试，运行时都需要相关的jar包<br>test：只用于测试相关的代码中的依赖，常用于junit<br>provided：当编译和测试时需要此类的依赖（jar包），而运行时不需要的情况下，可以指定成此范围。常见于servlet依赖<br>system：和provided类似，必须显式提供本地jar包所在的位置。<br><br><br>父工程当中定义的依赖，子工程不需要重复定义，直接继承。<br><br>A ，B工程，A工程依赖B工程，B工程中的所有依赖，A工程也可以直接使用（B工程的依赖会传递给A工程）。<br><br>项目存在依赖的传递，同样的依赖，多层传递，版本号不同的情况，用最接近它的那一层的版本。<br>依赖路径层次相同的情况下，谁先声明，用谁的。<br>不想使用某个依赖下的特定依赖包，可以使用排除方式。使用exclusions排除，不需要指定版本。<br><br>在properties标签当中定义一个自定义标签，设置版本号<br>在使用的时候，用${自定义标签名}方式使用<br>&lt;properties&gt;
        &lt;jdbc.mysql&gt;6.0.6&lt;/jdbc.mysql&gt;
    &lt;/properties&gt;
    
&lt;!--            使用指定版本号--&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;mysql&lt;/groupId&gt;
                &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
                &lt;version&gt;${jdbc.mysql}&lt;/version&gt;
            &lt;/dependency&gt;
]]></description><link>教程\1.maven.html</link><guid isPermaLink="false">教程/1.maven.md</guid><pubDate>Sun, 03 Dec 2023 08:56:23 GMT</pubDate></item><item><title><![CDATA[ORM模型]]></title><description><![CDATA[<a class="tag" href="?query=tag:和" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#和</a> 
 <br><br>yaml<br>javaclass aaa{

}
<br><br><br>由于 JDBC 的缺陷，ResultSet 和 POJO 的映射是一个比较大的难题。实际工作中基本上不使用 JDBC<br>ORM(Object Relational Mapping)：主要是用来解决数据库表和POJO之间的映射关系。<br><br><br>Mybatis是持久层的框架，基于JDBC，对JDBC进行封装，支持普通的SQL查询，存储过程以及关系映射。几乎消除了JDBC的代码以及参数的手工设置，对结果集进行映射。<br>缺点：移植困难。Mybatis需要自己编写SQL，不同的数据库存在方言。<br>主要是和hibernate相比较。<br><br><img style="zoom:60%;" alt="01.运行流程" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171315849.png" referrerpolicy="no-referrer"><br><br><br><br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN"
"http://mybatis.org/dtd/mybatis-3-config.dtd" &gt;
&lt;configuration&gt;
 &lt;mappers&gt;
 &lt;/mappers&gt;
&lt;/configuration&gt;
<br><br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
"http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;
&lt;mapper namespace=""&gt;

&lt;/mapper&gt;
<br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.16&lt;/version&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
<br><br>&lt;configuration&gt;

    &lt;environments default="dev"&gt;
        &lt;environment id="dev"&gt;
            &lt;transactionManager type="JDBC"&gt;&lt;/transactionManager&gt;
            &lt;dataSource type="unpooled"&gt;
                &lt;property name="driver" value="com.mysql.cj.jdbc.Driver"/&gt;
                &lt;property name="url" value="jdbc:mysql://localhost:3306/school?serverTimezone=UTC&amp;amp;useSSL=false"/&gt;
                &lt;property name="username" value="root"/&gt;
                &lt;property name="password" value="root"/&gt;
            &lt;/dataSource&gt;
        &lt;/environment&gt;
    &lt;/environments&gt;
    &lt;mappers&gt;
        &lt;mapper resource="mappers/ScoreMapper.xml"/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
<br><br>@Data
@NoArgsConstructor
@AllArgsConstructor
public class Score {
    String sno;
    String cno;
    double degree;
}

<br>编写Mapper映射文件<br>&lt;mapper namespace="net.wanho"&gt;
    &lt;select id="selectAll" resultType="net.wanho.domain.Score"&gt;
        select * from score
    &lt;/select&gt;

&lt;/mapper&gt;
<br><br>&lt;mappers&gt;
        &lt;mapper resource="mappers/ScoreMapper.xml"/&gt;
    &lt;/mappers&gt;
<br><br>/**
     * 入门案例
     */
    @Test
    public void test01() throws IOException {
        String config = "config.xml";
        Reader reader = Resources.getResourceAsReader(config);
        SqlSessionFactory factory = new SqlSessionFactoryBuilder().build(reader);
        SqlSession sqlSession = factory.openSession();
        List&lt;Score&gt; list = sqlSession.selectList("net.wanho.selectAll");
        list.forEach(System.out::println);

    }
<br><br>dao文件和xml的映射通过dao的全类名+方法名去映射。<br>xml文件的namespace需要设置成dao的全类名，select，insert，delete等标签的id和dao接口中的方法名一致。<br><br><br>public interface CourseDao {
    List&lt;Course&gt; selectall();
}
<br><br>&lt;mapper namespace="net.wanho.mapper.CourseDao"&gt;
    &lt;select id="selectAll" resultType="net.wanho.domain.Course"&gt;
        select * from course
    &lt;/select&gt;
&lt;/mapper&gt;
<br><br>常用注解：@Insert，@Update，@Delete，@Select，@ResultMap，@Option<br>简单的单表的操作，可以使用注解方式，复杂的查询不建议使用<br>思考题：<br>mybatis的dao接口中的方法是否可以重载？<br>如果采用的xml方式配置sql的话，由于xml当中sql和dao接口使用namespace+id的方式映射，则不能重载。<br>如果使用接口方式编程，则可以重载。<br><br><br><br>    &lt;settings&gt;
&lt;!--        日志配置--&gt;
        &lt;setting name="logImpl" value="STDOUT_LOGGING"/&gt;
&lt;!--        &lt;setting name="logImpl" value="log4J"/&gt;--&gt;
    &lt;/settings&gt;
<br><br>数据库当中属性使用下划线进行设计，但是pojo使用的驼峰，可以全局设置下划线转驼峰<br>&lt;settings&gt;
&lt;!--        下划线转驼峰--&gt;
        &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt;
    &lt;/settings&gt;
<br>如果查询sql中的列名和POJO当中列名不一致的话，如何解决：<br>1：下划线和驼峰，可以全局设置<br>2：可以使用别名<br>3：自定义映射  resultMap  <br>​	resultMap使用场合：数据库sql查询列名和pojo不一致的情况下<br>​											   关联查询需要映射对象属性时使用<br><br>&lt;typeAliases&gt;
&lt;!--        &lt;typeAlias type="net.wanho.domain.Employee" alias="employee"&gt;&lt;/typeAlias&gt;--&gt;
        &lt;package name="net.wanho.domain"/&gt;
    &lt;/typeAliases&gt;
<br><br> &lt;mappers&gt;
&lt;!--        设置成class以及使用package来配置,都有隐形的条件:--&gt;
&lt;!--        1: 编译后,xml文件和dao文件需要同一个文件夹下--&gt;
&lt;!--        2: xml文件和dao的文件名除了扩展名之外,需要一样(包括大小写)--&gt;
&lt;!--        &lt;mapper class="net.wanho.mapper.CourseMapper"/&gt;--&gt;
&lt;!--        &lt;mapper class="net.wanho.mapper.EmployeeMapper"/&gt;--&gt;
        &lt;package name="net.wanho.mapper"/&gt;
    &lt;/mappers&gt;
<br><br><br>在pojo对象属性和sql列名不一致的情况下使用<br>在关联查询的时候使用<br>sql的select标签的属性，不能使用resultType，必须使用resultMap<br><br>1： 简单数据类型的多个参数，可以使用@Param注解指定参数名称<br>2： 使用map传递，参数名使用 key的名称<br>3： 直接用POJO对象传递，xml的参数需要和POJO属性一致(大小写必须一致，而且需要有getter/setter)<br><br>#： 类似于preparedStatement，使用参数占位符，可以避免sql注入问题。进行类型处理。String，date类型都会增加单引号。<br>$:  拼接字符串，可能引起sql注入。一般用于动态列名以及模糊查询。不会进行类型处理。<br>模糊查询<br>1： 使用$进行拼接字符串<br>2： 使用concat， like concat('%',#{},‘%’)<br>3：使用动态标签bind，定义了一个局部变量    like  #{变量}<br><br>1：在insert标签上使用useGeneratedKey=true，指定keyColumn和keyProperty属性<br>2：使用selectKey子标签来进行<br><br><br>动态where会根据条件，去掉第一个条件开始的and或者or<br>&lt;select id="selectList" resultType="teacher"&gt;
        select * from teacher
        &lt;where&gt;
            &lt;if test="tno !=null and tno !=''"&gt;
                and tno = #{tno}
            &lt;/if&gt;
            &lt;if test="tname !=null and tname !=''"&gt;
                and tname like  concat('%',#{tname},'%')
            &lt;/if&gt;
        &lt;/where&gt;

    &lt;/select&gt;
<br><br>&lt;select id="selectSeason" resultType="SalaryVO"&gt;
        SELECT userid
                ,case #{season} when 'A' then '第一季度'
                    when 'B' then '第二季度'
                    when 'C' then '第三季度'
                    when 'D' then '第四季度'
                end seasonTitle
                ,sum(money)  money
        from salary
        &lt;where&gt;
            &lt;if test="userid !=0"&gt;
                userid = #{userid}
            &lt;/if&gt;
            &lt;if test="season != null "&gt;
                &lt;choose&gt;
                    &lt;when test='season =="A"'&gt;
                        and  `month` in (1,2,3)
                    &lt;/when&gt;
                    &lt;when test='season =="B"'&gt;
                        and  `month` in (4,5,6)
                    &lt;/when&gt;
                    &lt;when test='season =="C"'&gt;
                        and  `month` in (7,8,9)
                    &lt;/when&gt;
                    &lt;otherwise&gt;
                        and  `month` in (10,11,12)
                    &lt;/otherwise&gt;
                &lt;/choose&gt;
            &lt;/if&gt;
        &lt;/where&gt;
        group by userid
    &lt;/select&gt;
<br><br> &lt;insert id="insertBatch"&gt;
        insert  into teacher(tno,tname,tsex)
        values
        &lt;foreach collection="list" open="" close="" separator="," item="teacher"&gt;
            (#{teacher.tno},#{teacher.tname},#{teacher.tsex})
        &lt;/foreach&gt;
    &lt;/insert&gt;

    &lt;delete id="delete"&gt;
        delete from teacher
        where tno in
        &lt;foreach collection="list" open="(" close=")" separator="," item="tno"&gt;
            #{tno}
        &lt;/foreach&gt;
    &lt;/delete&gt;
<br><br>对于一些常用的sql进行抽取，可以重复利用。<br>&lt;sql id="selectColumn"&gt;
        select sno,sname,ssex,sbirthday,class
        from student
    &lt;/sql&gt;
    &lt;select id="selectAll" resultMap="stuMap"&gt;
        &lt;include refid="selectColumn"&gt;
    &lt;/select&gt;
    &lt;select id="selectOne" resultMap="stuMap"&gt;
        &lt;include refid="selectColumn"&gt;
        where sno = #{sno}
    &lt;/select&gt;
<br><br>动态的替换字符串，添加部分字符串。<br>&lt;select id="selectByCon" resultType="net.wanho.domain.Student"&gt;
        &lt;include refid="selectColumn" /&gt;
        &lt;trim prefix="where" prefixOverrides="and | or"&gt;
            &lt;if test="sno !=null and sno !=''"&gt;
                and sno = #{sno}
            &lt;/if&gt;
            &lt;if test="sname !=null and sname !=''"&gt;
                &lt;bind name="bindSname" value="'%' +sname + '%' "/&gt;
                and sname like #{bindSname}
            &lt;/if&gt;
            &lt;if test="ssex !=null and ssex !=''"&gt;
                and ssex = #{ssex}
            &lt;/if&gt;
        &lt;/trim&gt;
    &lt;/select&gt;
<br><br>&lt;select id="selectBySname" resultType="net.wanho.domain.Student"&gt;
        &lt;include refid="selectColumn" /&gt;
        &lt;where&gt;
            &lt;if test="sname !=null and sname !=''"&gt;
                &lt;bind name="bindSname" value="'%' +sname + '%' "/&gt;
                and sname like #{bindSname}
            &lt;/if&gt;
        &lt;/where&gt;
    &lt;/select&gt;
<br><br>&lt;update id="update"&gt;
        update student
        &lt;set&gt;
           &lt;if test="sname!=null and sname !=''"&gt;
               sname = #{sname},
           &lt;/if&gt;
            &lt;if test="ssex!=null and ssex !=''"&gt;
                ssex = #{ssex},
            &lt;/if&gt;
            &lt;if test="sbirthday!=null and sbirthday !=''"&gt;
                sbirthday = #{sbirthday},
            &lt;/if&gt;
            &lt;if test="clsname!=null and clsname !=''"&gt;
                class = #{clsname},
            &lt;/if&gt;
        &lt;/set&gt;
        where sno =#{sno}
    &lt;/update&gt;
<br><br><br>在主entity当中，增加一个属性，为辅助对象类型<br>需要在mapper的xml文件当中使用resultMap，并且使用association标签，来定义映射关系<br>SQL语句可以分成一次SQL或者多次SQL的形式<br>&lt;resultMap id="courseMap" type="course" autoMapping="true"&gt;
        &lt;association property="teacher" column="tno"
                     javaType="net.wanho.domain.Teacher" autoMapping="true"&gt;
            &lt;!--           &lt;id column="tno" property="tno"/&gt;--&gt;
            &lt;!--           &lt;result column="tname" property="tname"&gt;&lt;/result&gt;--&gt;
        &lt;/association&gt;
    &lt;/resultMap&gt;
    &lt;select id="selectRelated" resultMap="courseMap"&gt;
        select c.*,t.tname,t.tsex,t.tbirthday
        from course c
        left join  teacher t on
            c.tno = t.tno
    &lt;/select&gt;


    &lt;resultMap id="courseMap1" type="course" autoMapping="true"&gt;
        &lt;association property="teacher" column="tno"
                     javaType="net.wanho.domain.Teacher" autoMapping="true"
                     select="net.wanho.mapper.TeacherMapper.selectByTno"  &gt;
        &lt;/association&gt;
    &lt;/resultMap&gt;

    &lt;select id="selectRelatedList" resultMap="courseMap1"&gt;
        select * from course
    &lt;/select&gt;
<br><br>在主entity当中，增加一个集合类型的属性，元素类型为多的一方。<br>需要在mapper的xml文档当中使用resultMap来进行映射，使用collection标签，映射集合的元素<br>&lt;resultMap id="relatedMap" type="net.wanho.domain.Student"
               autoMapping="true"&gt;
        &lt;id column="sno" property="sno"/&gt;
&lt;!--        &lt;result column="sname" property="sname"/&gt;--&gt;
&lt;!--
    property是指   Student当中的多的属性名
    ofType用来定义Student的scoreList集合中元素的类型--&gt;
        &lt;collection property="scoreList" column="sno"  autoMapping="true"
                    ofType="net.wanho.domain.Score"/&gt;
    &lt;/resultMap&gt;
    &lt;select id="selectRelated" resultMap="relatedMap"&gt;
        select s.sno,s.sname,s.ssex,s.sbirthday,s.class ,score.cno,score.degree
        from student s
        left join score on
            s.sno = score.sno
        order by sno
    &lt;/select&gt;
<br><br><br>在mybatis当中，默认是开启一级缓存。提升查询的效率。在短时间间隔范围内，执行两次同样的查询，第二次会从本地缓存中获取，不需要连接数据，发行SQL。一级缓存是基于统一sqlSession对象，跨越sqlsession不能共享缓存。<br>如果两次查询之间有任何的写操作，则会清空缓存。<br>@Test
    public void test01(){
        final TeacherMapper mapper = sqlSession.getMapper(TeacherMapper.class);
        Teacher teacher = mapper.selectByTno("831");

        Teacher temp = new Teacher();
        temp.setTno("113");
        temp.setTname("测试");
        mapper.update(temp);
        System.out.println("=====================");
        Teacher teacher1 = mapper.selectByTno("831");
        System.out.println(teacher==teacher1); //true
    }

    @Test
    public void test02(){
        final TeacherMapper mapper = sqlSession.getMapper(TeacherMapper.class);
        Teacher teacher = mapper.selectByTno("831");


        SqlSession sqlSession  =factory.openSession(true);
        final TeacherMapper mapper1 = sqlSession.getMapper(TeacherMapper.class);
        Teacher teacher1 = mapper1.selectByTno("831");
        System.out.println(teacher==teacher1); //false
    }
<br><br>1、
&lt;settings&gt;
        &lt;setting name="cacheEnabled" value="true"/&gt;
&lt;/settings&gt;
2、
//XxxMapper.xml
&lt;cache/&gt;
3、POJO 类实现 Serializable 接口
4、二级缓存必须在SqlSession关闭或提交之后有效
sqlSession1.close();  // 或者 sqlSession1.commit();
<br>跨越sqlSession对象，基于mapper，使用注解的方式不能直接使用二级缓存。<br>需要手工开启。禁用某个sql的二级缓存，设置useCache=false即可<br><br>使用关联查询的地方，使用多个sql进行查询。<br>如果在某些情况下，只需要主表的数据，不需要从表的数据，可以使用延时加载。<br>设置<br>1：使用单个设置 在collection或者association属性使用   fetchType=lazy<br>2：使用全局设置，在config文件中<br>​	lazyLoadingEnabled=true<br>​	aggressiveLazyLoading=false<br><br><br><br>@Select("select count(0) from user")
    int selectCount();

    @Select("select * from user limit #{offset},#{pageSize}")
    List&lt;User&gt; selectListByPage(@Param("offset") int offset,@Param("pageSize")int pageSize);
<br><br> @Test
    public void test01(){
        //先记录总共的记录条数，
        //1：传进来的pageNum不应该超过范围，特殊情况下有可能出错
        //2： 前端的分页插件需要知道总共多少条数据
        final UserMapper mapper = sqlSession.getMapper(UserMapper.class);
        int total = mapper.selectCount();
        //pageNum客户的请求
        int pageNum = 3;
        int pageSize = 10;
        //需要验证pageNum是否超出范围
        //计算offset
        int offset = (pageNum -1) * pageSize;

        List&lt;User&gt; users = mapper.selectListByPage(offset, pageSize);
        users.forEach(e-&gt; System.out.println(e));
    }
<br><br>存在一个问题：从第一行开始取到需要的数据的最后一行，然后根据页码和每页条数，获取实际的数据。不适合大数据量的情况<br>@Test
    public void test02(){

        final UserMapper mapper = sqlSession.getMapper(UserMapper.class);
        //pageNum客户的请求
        int pageNum = 3;
        int pageSize = 10;
        //需要验证pageNum是否超出范围
        //计算offset
        int offset = (pageNum -1) * pageSize;
        RowBounds rowBounds = new RowBounds(offset,pageSize);
        List&lt;User&gt; users = mapper.selectByRowBounds(rowBounds);
        users.forEach(e-&gt; System.out.println(e));

    }
<br><br>可以自定义插件，也可以使用第三方的插件，直接使用第三方：pageHelper。<br>定义插件，利用mybatis提供的Interceptor，在executor和mapperedStatement之间对sql语句进行拦截。<br><br>&lt;dependency&gt;
     &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
     &lt;artifactId&gt;pagehelper&lt;/artifactId&gt;
     &lt;version&gt;5.1.11&lt;/version&gt;
&lt;/dependency&gt;
<br><br>在config的配置文件中配置plugin<br>&lt;plugins&gt;
        &lt;plugin interceptor="com.github.pagehelper.PageInterceptor"&gt;
&lt;!--            设置数据库--&gt;
            &lt;property name="helperdialect" value="mysql"/&gt;
&lt;!--            处理页码的正常范围
        小于等于0的页码，默认变成第一页数据
        大于最大页码，变成最后一页
--&gt;
            &lt;property name="reasonable" value="true"/&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
<br><br>@Select("select * from user")
 List&lt;User&gt; selectByPageHelper();
<br><br>@Test
    public void test03(){

        final UserMapper mapper = sqlSession.getMapper(UserMapper.class);
        //pageNum客户的请求
        int pageNum =3;
        int pageSize = 10;
        PageHelper.startPage(pageNum,pageSize);
        List&lt;User&gt; users = mapper.selectByPageHelper();
        PageInfo&lt;User&gt; userPageInfo = new PageInfo&lt;&gt;(users);
        System.out.println(userPageInfo);


    }
<br>​       ]]></description><link>教程\2、mybatis课件.html</link><guid isPermaLink="false">教程/2、mybatis课件.md</guid><pubDate>Tue, 26 Dec 2023 09:30:31 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171315849.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171315849.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Spring基本概念]]></title><description><![CDATA[ 
 <br><br><br>Spring框架是一个<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81/114160?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81/114160?fromModule=lemma_inlink" target="_blank">开放源代码</a>的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/J2EE/110838?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/J2EE/110838?fromModule=lemma_inlink" target="_blank">J2EE</a>应用程序框架，由[Rod Johnson](<a rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Rod" target="_blank">https://baike.baidu.com/item/Rod</a> Johnson/1423612?fromModule=lemma_inlink)发起，是针对bean的生命周期进行管理的轻量级容器（lightweight container）。 Spring解决了开发者在J2EE开发中遇到的许多常见的问题，提供了功能强大IOC、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/AOP/1332219?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/AOP/1332219?fromModule=lemma_inlink" target="_blank">AOP</a>及Web MVC等功能。Spring可以单独应用于构筑应用程序，也可以和Struts、Webwork、Tapestry等众多Web框架组合使用，并且可以与 Swing等<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/2331979?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%A1%8C%E9%9D%A2%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F/2331979?fromModule=lemma_inlink" target="_blank">桌面应用程序</a>AP组合。因此， Spring不仅仅能应用于J2EE应用程序之中，也可以应用于桌面应用程序以及小应用程序之中。Spring框架主要由七部分组成，分别是 Spring Core、 Spring AOP、 Spring ORM、 Spring DAO、Spring Context、 Spring Web和 Spring Web MVC。<br><br>1：提供了IOC容器，降低组件之间的耦合度<br>2：提供了AOP技术，可以将一些通用的功能，比如说日志，权限，系统运行的监控，事务等抽象出来，使用AOP来实现，提升开发的效率，降低运维的工作量<br>3：支持声明式的事务，既可以使用xml方式来配置，也可以使用注解，事务的管理非常方便<br>4：测试比较容易，并且提供了很多其他的辅助功能，jdbcTemplate，消息服务等<br>5：兼容性较好，对于主流的框架都提供了支持。hibernate，mybatis，struts，shiro，redis，Quartz<br><br><img style="zoom:80%;" alt="01.spring架构体系" src="\01.spring架构体系.png" referrerpolicy="no-referrer"><br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-context&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>public class HelloWorld {
    public void sayHello(){
        System.out.println("hello spring");
    }
}
<br><br>&lt;bean id="helloWorld" class="net.wanho.HelloWorld"/&gt;
<br><br>public class Sample01 {
    public static void main(String[] args) {
        //传统方式
        //HelloWorld helloWorld = new HelloWorld();
        //        //helloWorld.sayHello();
        ApplicationContext ctx = new ClassPathXmlApplicationContext("bean.xml");
        HelloWorld helloWorld = (HelloWorld)ctx.getBean("helloWorld");
        helloWorld.sayHello();
    }
}
<br><br><br>IOC(Inversion of Control) ：传统方式下，对象的创建的控制权以及管理都是程序员通过代码去实现的。使用了Spring之后，对象的创建以及管理权都由程序员转移给Spring容器去进行管理。Spring容器会根据配置文件去创建bean实例以及管理各个bean之间的依赖关系。对象与对象之间是松耦合。<br><br>基于xml文件方式<br>基于注解的方式：在xml文件当中指定扫描包的位置，通过注解告诉spring容器哪些需要创建<br>基于java代码进行配置  ，主要是使用@Configuration注解进行配置<br><br>通过bean的名称获取<br>通过bean的class类型获取，如果同类型的bean存在多个的话，会出现异常。<br>通过名称和类型同时指定方式<br><br><br>&lt;bean id="helloWorld" class="net.wanho.HelloWorld"/&gt;
<br><br>水果：桃子，梨子，苹果，葡萄<br>加工》罐头》加工工厂<br>静态工厂方法和实例工厂方法<br><br>FactoryBean接口的实现类创建的对象，并不是实现类的类型，而是getObjectType指定的类型，其对象的创建，在getObject方法当中进行处理<br><br>依赖注入（Dependency Injection):实现IOC的一种手段，对于对象的属性进行自动配置。<br>UserService类的脆响，有UserDao类型的dao对象，如果需要调用dao对象的方法，先要给dao进行赋值处理。传统方式下，需要在代码中new一个UserDao对象。spring当中，对象是交给容器去管理，容器当中是有userService对象和UserDao对象，属性的设置也由spring通过注入的方式进行配置。这种过程称为依赖注入。<br><br>Pet类需要定义setter方法<br>&lt;!--    使用setter方法注入属性--&gt;
    &lt;bean id="dog" class="net.wanho.base03.Pet"&gt;
        &lt;property name="type" value="dog"/&gt;
        &lt;property name="color" value="white"/&gt;
    &lt;/bean&gt;
<br><br>需要和构造方法一致<br>&lt;!--    使用构造方法进行注入--&gt;
    &lt;bean id="cat" class="net.wanho.base03.Pet"&gt;
        &lt;constructor-arg name="type" value="cat"/&gt;
        &lt;constructor-arg name="color" value="white"/&gt;
    &lt;/bean&gt;
<br><br>留到注解时说明<br><br>使用ref属性不能使用value<br><br>singleton：单例，每次通过getBean获取的时候，都是同一个对象。ApplicationContext容器在启动的时候默认会创建单例的对象（默认作用）<br>prototype：原型，每次通过getBean获取的时候都会创建新的对象，ApplicationContext容器启动时不会创建此对象，后期也不管理其生命周期。可以在xml文件当中使用scope属性或者@Scope注解进行修改<br>request：在request作用域范围内（web）<br>session：在session作用域范围内（web）<br>application ：在application 作用域范围内（web）<br>websocket：在websocket作用域范围内（web）<br>global session（老版本有的，新版本是没有作用域）<br><br><br><img alt="02.bean生命周期" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-05-2002.bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F.png" referrerpolicy="no-referrer"><br><br><br><br>public class PersonBeanPostProcessor implements BeanPostProcessor {

    @Override
    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {
        if("person".equals(beanName)) {
            System.out.println("person对象即将被修改");
            ((Person)bean).setName("蒋俊");
        }
        return bean;
    }

    @Override
    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
        System.out.println("初始化后方法");
        return null;
    }
}
<br><br><br>spring容器在属性注入的时候，可以启用自动装配的方式，autowire属性。只针对复杂的引用类型（bean），对于简单数据类型不能自动装配<br>no ：默认值，不进行自动装配<br>default：采用默认的自动装配方式，启用配置文件全局的配置，采用beans根节点上default-autowire属性的值<br>byType：根据类型进行匹配，同一个类型有多个对象，会抛出异常<br>byName：根据名称进行匹配<br>constuctor：根据构造方法推断进行匹配<br><br><br>定义组件的常用注解：<br>@Controller：用在表现层的控制器主键上，放在类上<br>@Service：用在BL（Business Logic）层的组件，放在类上<br>@Repository：用在DAO(Data Access Object)层的组件，放在类上<br>@Component：上述之外的一些通用，公用的组件，放在类上<br>@PostContruct：用在组件的初始化方法上<br>@PreDestroy：用在定义销毁前方法<br>@Scope：用来指定bean的作用域<br><br>定义容器的配置文件，需要定义在哪些范围内使用注解 basePackage<br>启用注解<br>定义bean（使用注解）<br>编写测试类<br><br><br>是由spring提供的注解，可以放在属性，构造方法或者Setter方法上。默认使用类型进行装配，如果同一类型存在多个对象的话，则使用名称再次匹配，如果匹配不上，则抛出异常。<br>如果想要匹配指定名称的bean，则可以联合@Qulifier注解一起使用<br>@Controller
public class UserController {

    @Autowired
            @Qualifier("userServiceImpl1")
    UserService userService;

    //@Autowired  //使用构造器注入
    //public UserController(UserService userService) {
    //    this.userService = userService;
    //}

    public UserController() {
        System.out.println("创建controller对象");
    }

    public void findUser(){
        userService.findUser();
    }

    //@Autowired  //使用Setter方法注入
    //public void setUserService(UserService userService) {
    //    this.userService = userService;
    //}
}

<br><br>@Resource注解，是由java提供的扩展注解，注解提供了name和type属性，可以按照名称或者指定类型进行匹配。如果都不指定的情况下，默认使用名称，如果名称匹配不上，则再次使用类型去匹配。<br>@Service  //默认名字：userServiceImpl
public class UserServiceImpl implements UserService {


    @Resource
    UserDao userDao;

    public UserServiceImpl() {
        System.out.println("创建Service对象");
    }

    @Override
    public void findUser() {
        userDao.selectUser();
    }
}
<br><br>@Value注解<br>    @Value("userDao")
    String daoName;
<br><br><br>基于java配置，是完全不需要xml文件，所有的bean配置都是基于注解。@Configuration注解，用于定义容器的入口，作为读取数据的base。<br><br>1：@Bean放在方法上，用于告诉方法，产生一个bean对象，交给spring容器去管理<br>2：相对比较灵活的获取bean，根据参数设置，动态配置对象<br>3：@Bean标记的方法，Spring会调用一次，将配置信息放入到容器当中<br>4：@Bean的name问题，不指定的情况下默认使用方法名，可以使用name或者value属性进行指定。<br>5：@Bean方法创建的bean，默认的作用域是单例，可以使用@Scope进行指定成原型<br>6：@Bean同样可以扩展初始化和销毁前方法，可以使用initMethod和destroyMethod进行指定。<br><br>和xml文件&lt;context:component-scan&gt;作用相同。用来扫描组件。<br>对于已经使用了@Controller，@Service，@Repository，@Component的类都可以直接扫描并创建对象。<br><br>@Import用在类上，用于快速导入类以及接口中指定类。主要用于地方组件的导入。<br>使用方式有三种<br><br>public class UserBean01 {
    public UserBean01() {
        System.out.println("UserBean01");
    }
}


@Configuration
@Import({UserBean01.class})
public class AppConfig {
}
<br><br>导入的对象并不是ImportSelector的对象<br>public class UserBean02 {
    public UserBean02() {
        System.out.println("UserBean02");
    }
}

public class MyImportSelector implements ImportSelector {
    @Override
    public String[] selectImports(AnnotationMetadata importingClassMetadata) {
        return new String[]{"net.wanho.base07.UserBean02"};
    }
}

@Configuration
@Import({UserBean01.class,MyImportSelector.class})
public class AppConfig {
}
<br><br>public class UserBean03 {
    public UserBean03() {
        System.out.println("UserBean03");
    }
}

public class MyImportBeanDefinitionReg implements ImportBeanDefinitionRegistrar {
    @Override
    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata
            , BeanDefinitionRegistry registry
            , BeanNameGenerator importBeanNameGenerator) {

        //&lt;bean id="userBean03" class="net.wanho.base07.userBean03"/&gt;
        BeanDefinition beanDefinition = new RootBeanDefinition(UserBean03.class);
        beanDefinition.setScope("singleton");
        registry.registerBeanDefinition("userBean03",beanDefinition);

    }
}

@Configuration
@Import({UserBean01.class,MyImportSelector.class,MyImportBeanDefinitionReg.class})
public class AppConfig {
}
<br><br><br>AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，通过预编译方式和运行期间动态代理实现程序功能的统一维护的一种技术。AOP是<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/OOP/1152915?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/OOP/1152915?fromModule=lemma_inlink" target="_blank">OOP</a>的延续，是<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/3448966?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/3448966?fromModule=lemma_inlink" target="_blank">软件开发</a>中的一个热点，也是<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Spring?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Spring?fromModule=lemma_inlink" target="_blank">Spring</a>框架中的一个重要内容，是<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/4035031?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/4035031?fromModule=lemma_inlink" target="_blank">函数式编程</a>的一种衍生范型。利用AOP可以对<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91/3159866?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E4%B8%9A%E5%8A%A1%E9%80%BB%E8%BE%91/3159866?fromModule=lemma_inlink" target="_blank">业务逻辑</a>的各个部分进行隔离，从而使得业务逻辑各部分之间的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%80%A6%E5%90%88%E5%BA%A6/2603938?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%80%A6%E5%90%88%E5%BA%A6/2603938?fromModule=lemma_inlink" target="_blank">耦合度</a>降低，提高程序的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%8F%AF%E9%87%8D%E7%94%A8%E6%80%A7/53650612?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%8F%AF%E9%87%8D%E7%94%A8%E6%80%A7/53650612?fromModule=lemma_inlink" target="_blank">可重用性</a>，同时提高了开发的效率。<br>Spring当中，将影响多个模块的通用功能抽取出来，定义成一个新的可重用的模块，称之为切面。目的是减少重复代码，降低耦合度。公用的功能：权限认证，日志，事务处理。<br><br>设计模式：代理<br>动态代理：并不是直接操作目标对象，而是通过代理去调用。分为JDK动态代理和CGLIB代理。<br>JDK动态代理和CGLIB代理的区别：<br>​	JDK动态代理用于面向接口编程<br>​	CGLIB代理：可以对普通的类进行增强<br>首先默认选择jdk动态代理，可以通过配置进行修改，配置的情况下，目标对象实现接口的话，还是使用JDK,否则使用CGLIB<br><br><br>在程序的执行当中，利用反射机制，创建代理类对象，并动态指定代理的目标类。<br>重要的类和接口：Proxy，Invocationhandler<br><br>对于没有实现接口的类，可以使用CGLIB进行代理。<br>CGLIB的原理是继承，通过继承目标类，创建代理子类，在子类当中重写父类的相关方法，实现功能的修改和增强。要求目标类和方法不能是final。Spring当中已经集成了相关的包，不需要另外增加。<br>实现MethodInterceptor接口<br><br>切面 aspect：横切关注点。是通知和切点的组合。包含两个工作：<br>​	1：如何实现通用代码（通知）<br>​	2：如何将通用的代码和具体要代理执行的方法连接起来，需要定义切点。<br>通知advice：通用的功能细节，切面必须完成的工作。切面当中的每一个方法都称之为通知<br>连接点：程序执行期间具体某个点。可以是方法执行前，或者方法执行后，出现异常时。<br>切点：匹配连接点的谓词（断言）。匹配连接点的抽象的条件。<br>目标：被代理的对象。<br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>&lt;context:component-scan base-package="net.wanho.base02"/&gt;
    &lt;context:annotation-config/&gt;
&lt;!--    启用aop注解--&gt;
    &lt;aop:aspectj-autoproxy /&gt;
<br><br>@Component
public class Computer {

    public int add(int a,int b) {
        System.out.println("add方法被调用");
        return a + b;
    }

}
<br><br>//切面类也要交给spring容器管理
@Component
//标记当前的类是一个切面类
@Aspect
public class LogAspect {

    @Before("execution(public int net.wanho.base02.Computer.add(int,int))")
    public void beforeLog(){
        System.out.println("方法即将被调用");
    }
}
<br><br>public class Sample01 {
    public static void main(String[] args) {
        ApplicationContext ctx = new ClassPathXmlApplicationContext("bean.xml");
        Computer computer = ctx.getBean(Computer.class);
        int a =computer.add(10,5);
        System.out.println(a);
    }
}
<br><br><br>指示器通常分为：匹配方法（execution，@annotation），匹配类型（target，this，within，@Target,@Within),<br>​	匹配参数（args，@Args)<br>execution(s): 和字符串相匹配的方法的执行（满足字符串条件）<br>@annotation（x）: 目标方法上需要指定的注解x<br>target（x）：和x相兼容的类的执行，如果X为接口，则实现类的方法可以执行，如果是一个普通的类，则x以及其子类的方法可以执行此通知<br>this(x): x是接口类型，x的实现类的执行<br>within(x): 严格和x匹配<br><br>当使用execution时，表示式是可以使用通配符<br>*：至少匹配一个字符，使用类或者方法名上面<br>..: 可以使用在路径上，和*一起使用，表示某个包以及子包下的所有类，还可以使用在参数上，表示参数不定<br>+：通常用在类型上面，表示当前类型的实现类或者子类<br><br>AOP的通知方法，都可以增加一个JoinPoint类型的参数<br><br><br>前置通知：在方法的执行之前进行的处理<br>后置通知：在方法结束之后进行的处理，无论正常结束还是异常结束，处理都会进行<br>正常结束通知：只有在方法正常结束后才会进行的处理<br>异常结束通知：当方法出现异常之后，会进行的处理<br>环绕通知：在方法的执行前后，正常或者异常情况下都可以执行的通知<br><br>使用@Before注解<br>@Before("execution(* net.wanho.base05..*.*(..))")
    public void before(){
        System.out.println("前置通知...a");
    }
<br><br>@After注解<br> @After("execution(* net.wanho.base05..*.*(..))")
    public void after(){
        System.out.println("后置通知");
    }
<br><br>@AfterRetruning注解，可以获取方法的返回值<br>@AfterReturning(value = "execution(* net.wanho.base05..*.*(..))",returning = "result")
    public void AfterReturning(Object result){
        System.out.println("正常通知, 返回值：" + result );
    }
<br><br>@AfterThrowing ，可以获取异常的相关信息<br>@AfterThrowing(value = "execution(* net.wanho.base05..*.*(..))",throwing = "ex")
    public void afterThrowing(Throwable ex){
        System.out.println("出现异常。。。。" + ex.getMessage());
    }
<br><br>使用@Around注解，需要使用连接点的processed方法手工调用方法。如果使用了环绕通知，并且捕获了异常进行处理，有可能导致事务不起作用。<br>环绕通知必须要有返回值<br> @Around("execution(* net.wanho.base05..*.*(..))")
    public  Object around(ProceedingJoinPoint joinPoint){

        Object result =null;
        System.out.println("前置通知...b");
        try {
            result = joinPoint.proceed();

            System.out.println("方法正常结束----b" + result);

        }  catch (Throwable throwable) {
            System.out.println("方法出现异常---b" + throwable.getMessage());
        } finally {
            System.out.println("方法处理结束---b");
        }
        return result;
    }
<br><br>将切点表达式抽象成方法，方便重复使用<br><br>@Component
@Aspect
public class AOPPointCut {
    @Pointcut("execution(* net.wanho.base05..*.*(..))")
    public void pointcutMethod(){}
}
<br><br>@Component
@Aspect
public class ComputerAop {

    //@Before("execution(* net.wanho.base05..*.*(..))")
    @Before("AOPPointCut.pointcutMethod()")
    public void before(){
        System.out.println("前置通知...a");
    } 

}
<br><br>切面的优先级别默认为类名的顺序（配置的顺序），可以使用@Order注解进行处理，数据越小，级别越高。没有写order注解的，优先级别最低。<br><img style="zoom:80%;" alt="03.切面优先级别" src="\03.切面优先级别.png" referrerpolicy="no-referrer"><br><br>@Component
@Aspect
@Order(1)
public class ZuthcAspect {

    @Before("execution(* net.wanho.base06..*.*(..))")
    public void  authenticate(){
        System.out.println("用户认证通过");
    }


    @After("execution(* net.wanho.base06..*.*(..))")
    public void  After(){
        System.out.println("用户退出");
    }
}

<br><br>@Component
@Aspect
@Order(2)
public class LogAspect {

    @Before("execution(* net.wanho.base06..*.*(..))")
    public void before(){
        System.out.println("即将取钱。。。。before");
    }


    @After("execution(* net.wanho.base06..*.*(..))")
    public void After(){
        System.out.println("即将取钱结束.....after");
    }
}
<br><br>1：连接点方法不能是private（要求是public），否则不能被增强<br>2：方法被内部调用时，不会被增强<br>3：业务类不能是final<br><img style="zoom:80%;" alt="03.内部调用不会被增强" src="\03.内部调用不会被增强.png" referrerpolicy="no-referrer"><br><br>@Component
public class Person {

    //私有方法不会被增强
     private void sayHello(){
        System.out.println("hello java178");
    }

    public static void main(String[] args) {
        ApplicationContext ctx= new AnnotationConfigApplicationContext(AppConfig.class);
        Person bean = ctx.getBean(Person.class);
        bean.sayHello();

    }
}
<br><br>@Component
public class Person {

     public void sayHello(){
        System.out.println("hello java178");
        //内部调用不会被增强
        jump();
    }

    public void jump(){
        System.out.println("jump....");
    }


    public static void main(String[] args) {
        ApplicationContext ctx= new AnnotationConfigApplicationContext(AppConfig.class);
        Person bean = ctx.getBean(Person.class);
        bean.sayHello();

    }
}
<br><br><br>spring-context，aspects，jdbc，tx，mysql<br>&lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;6.0.6&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>driver=com.mysql.cj.jdbc.Driver
url=jdbc:mysql://localhost:3306/school?serverTimezone=UTC&amp;useSSL=false
user=root
password=root
<br><br><br> &lt;context:component-scan base-package="net.wanho"/&gt;
    &lt;context:annotation-config/&gt;
    &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt;

&lt;!--    使用property-placeholder注入properties文件--&gt;
    &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt;
    &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt;
        &lt;property name="driverClassName" value="${driver}"/&gt;
        &lt;property name="url" value="${url}"/&gt;
        &lt;property name="username" value="${user}"/&gt;
        &lt;property name="password" value="${password}"/&gt;
    &lt;/bean&gt;

&lt;!--    使用模板模式--&gt;
    &lt;bean id="jdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
    &lt;/bean&gt;
<br><br><br>@Repository
public class StudentDao {

    @Autowired
    JdbcTemplate jdbcTemplate;

    public void queryStudent(){
        String sql = "select * from student";
        List&lt;Student&gt; list = jdbcTemplate.query(sql,new BeanPropertyRowMapper&lt;&gt;(Student.class));
        list.forEach(e-&gt; System.out.println(e));
    }
}

<br><br>public class Sample {
    public static void main(String[] args) {
        ApplicationContext ctx= new ClassPathXmlApplicationContext("bean.xml");
        StudentDao dao = ctx.getBean(StudentDao.class);
        dao.queryStudent();
    }
}
<br><br><br>spring-context，aspects，jdbc，tx，mysql，mybatis，mybatis-spring<br>&lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;6.0.6&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-tx&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.16&lt;/version&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis&lt;/artifactId&gt;
            &lt;version&gt;3.5.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt;
            &lt;version&gt;2.0.4&lt;/version&gt;
        &lt;/dependency&gt;
<br><br><br><br>&lt;configuration&gt;
    &lt;typeAliases&gt;
        &lt;package name="net.wanho.entity"/&gt;
    &lt;/typeAliases&gt;
    &lt;mappers&gt;
        &lt;package name="net.wanho.dao"/&gt;
    &lt;/mappers&gt;
&lt;/configuration&gt;
<br><br>&lt;context:component-scan base-package="net.wanho"/&gt;
    &lt;context:annotation-config/&gt;
    &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt;

    &lt;util:properties id="db" location="classpath:jdbc.properties"/&gt;
    &lt;bean id="dataSource" class="org.springframework.jdbc.datasource.DriverManagerDataSource"&gt;
        &lt;property name="driverClassName" value="#{db.driver}"/&gt;
        &lt;property name="url" value="#{db.url}"/&gt;
        &lt;property name="username" value="#{db.user}"/&gt;
        &lt;property name="password" value="#{db.password}"/&gt;
    &lt;/bean&gt;

&lt;!--    配置sqlSessionFactory--&gt;
    &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
        &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt;
    &lt;/bean&gt;

&lt;!--    告诉spring，mybatis的dao接口文件在什么地方--&gt;
    &lt;bean id="mapperScanner" class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt;
        &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt;
&lt;!--        指定dao接口文件所在位置--&gt;
        &lt;property name="basePackage" value="net.wanho.dao"/&gt;
    &lt;/bean&gt;
<br><br><br>public interface StudentMapper {
    List&lt;Student&gt; selectAll();
}

<br><br>@Service
public class StudentServiceImpl {

    @Autowired
    StudentMapper studentMapper;

    public List&lt;Student&gt; findAll(){
        return studentMapper.selectAll();
    }
}
<br><br>public class SampleMybaits {
    public static void main(String[] args) {
        //ApplicationContext ctx= new ClassPathXmlApplicationContext("spring-mybatis.xml");
        ApplicationContext ctx= new ClassPathXmlApplicationContext("spring-all.xml");
        StudentServiceImpl studentService = ctx.getBean(StudentServiceImpl.class);
        List&lt;Student&gt; all = studentService.findAll();
        all.forEach(e-&gt; System.out.println(e));
    }
}

<br><br>&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
        &lt;property name="configuration"&gt;
            &lt;bean class="org.apache.ibatis.session.Configuration"&gt;
                &lt;property name="logImpl" value="org.apache.ibatis.logging.stdout.StdOutImpl"/&gt;
                &lt;property name="mapUnderscoreToCamelCase" value="true"/&gt;
            &lt;/bean&gt;
        &lt;/property&gt;
        &lt;property name="plugins"&gt;
            &lt;bean class="com.github.pagehelper.PageInterceptor"&gt;
                &lt;property name="properties"&gt;
                    &lt;value&gt;
                        helperdialect=mysql
                        reasonable=true
                    &lt;/value&gt;
                &lt;/property&gt;
            &lt;/bean&gt;
        &lt;/property&gt;
&lt;!--        配置entity中pojo的别名--&gt;
        &lt;property name="typeAliasesPackage" value="net.wanho.entity"/&gt;
&lt;!--        指定mapper文件所在的位置，此配置方式，mapper.xml文件和接口文件可以不在同一个目录下--&gt;
        &lt;property name="mapperLocations" value="classpath:net/wanho/dao/*.xml"/&gt;
    &lt;/bean&gt;
<br><br><br>事务就是一系列的工作，他们被当作整体的工作单元，要么全部成功，要么全部不起作用（回滚）。<br>事务的特点：原子性，一致性，隔离性，持久性<br>隔离级别：读未提交，读已提交，可重复读，串行化<br><br>主要接口（org.springframework.transaction下）：<br>PlatformTransactionManager：用来提交和回滚事务<br>TransactionStatus：事务的状态，是否需要刷新，是否存在存储点<br>TransactionDefinition：定义了事务的相关属性（规则），<br>spring当中的事务本质上是一个拦截器（利用AOP），通过拦截器来调用事务管理器，进行事务管理<br>实现事务的方式：<br>​	编程式事务：利用PlatformTransactionManager，TransactionStatus，TransactionDefinition对象来进行编程<br>​	声明式事务：xml配置或者使用注解<br><br>&lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
    &lt;/bean&gt;
<br><br>public void save(){


        User user = new User();
        user.setName("java180");
        user.setPassword("111");
        user.setPhone("12345678911");

        //定义事务的TransactionDefinition对象
        TransactionDefinition definition = new DefaultTransactionDefinition();
        TransactionStatus status = transactionManager.getTransaction(definition);
        try {
            userMapper.insertUser(user);

            //模拟程序出异常
            int x = 10/0;

            //
            userRoleMapper.insertUserRole(user.getId(),1);
            transactionManager.commit(status);
        } catch ( Exception ex) {
            transactionManager.rollback(status);
        }


    }
<br><br><br>&lt;tx:advice id="txAdvice" transaction-manager="transactionManager"&gt;
        &lt;tx:attributes&gt;
            &lt;tx:method name="save0*" /&gt;
        &lt;/tx:attributes&gt;
&lt;/tx:advice&gt;
&lt;aop:config&gt;
        &lt;aop:pointcut id="txPointCut" expression="execution(* net.wanho.service.*.*(..))"/&gt;
        &lt;aop:advisor advice-ref="txAdvice" pointcut-ref="txPointCut"/&gt;
&lt;/aop:config&gt;
<br><br>需要开启事务注解，使用@Transactional注解，<br>此注解可以放在方法上，也可以放在类上，放在类上，表示此类的所有方法都需要事务管理。<br>&lt;!--    开启事务注解--&gt;
&lt;!--    如果事务管理器的bean的名字为transactionManager的话，则不需要配置transaction-manager--&gt;
&lt;!--    否则必须指定transaction-manager属性--&gt;
    &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;
<br><br>Spring事务默认只对运行时异常进行回滚，编译时异常不会回滚。如果想要自定义异常，并且事务有效回滚，必须继承RuntimeException或者其子类。如果相对编译时异常进行回滚，可以使用Rollbackfor属性进行设置。<br>try...catch会让事务失效。如果异常被catch，事务不会回滚。<br>解决方案：<br>​	1：在catch代码块当中抛出RuntimeException或者其子类的对象<br>​	2：使用事务TransactionAspectSupport.currentTransactionStatus().setRollback()手工回滚。<br><br>propagation：事务的传播性
isolation：事务的隔离级别，default：数据源的隔离级别
rollback-for：默认是对运行时异常进行回滚，编译时异常也需要回滚的话，可以利用此属性进行处理
no-rollback-for：对某些异常指定不回滚
readonly：只读事务
timeout：超时时间，第一个sql到一个sql执行过后的时间。
<br><br>默认是对运行时异常进行回滚，编译时异常正常情况下是不回滚的。<br>@Transactional(rollbackFor = {BusinessExcepiton.class})
    public void save02(String flag) throws BusinessExcepiton {

        User user = new User();
        user.setName("java180-1");
        user.setPassword("111");
        user.setPhone("12345678911");

        userMapper.insertUser(user);

        if("110".equals(flag)) {
            throw  new BusinessExcepiton("自定义业务异常");
        }

        userRoleMapper.insertUserRole(user.getId(),1);

    }
<br><br>当一个事务被另外一个事务调用的时候，需要指定事务的传播性。例如UserService调用UserRoleService和UserMenuService的时候，UserService当中是有事务的，UserMenuService和UserRoleService的方法也是有事务的。<br>UserService和UserMenuService以及UserRoleService的方法是否使用同一个事务对象，是由传播性来决定的。<br>传播性：<br>REQUIRED(0)：默认的传播性，如果外部有事务在运行，则内部的方法不开启新事务，在原有的事务内部执行。如果外部没有事务，则自己开启事务对象。
REQUIRES_NEW(3)：当前的方法必须开启新事务，如果外部有事务在运行，则将外部事务挂起，运行自己的事务，结束后，再次使用外部事务。
SUPPORTS(1)：支持事务。如果外部有事务，则在事务内部运行，如果外部没有事务，不开启新事务。
NOT_SUPPORTED(4)：不支持事务，如果外部有事务，则将外部事务挂起。
NEVER(5)：当前的方法不应该在事务内运行，如果外部有事务，则抛出异常
MANDATORY(2)：当前的方法必须在事务内运行，如果外部没有事务，则抛出异常
NESTED(6): 类似于REQUIRED，如果外部有事务在运行，则内部的方法不开启新事务，在原有的事务内部执行。如果外部没有事务，则自己开启事务对象。需要数据源的savepoint的支持。
<br>注意事项：仅仅REQUIRED,REQUIRES_NEW,NESTED传播性是可以开启事务对象的，其他都不会开启事务对象<br><br>数据库引擎不支持<br>没有被Spring管理<br>方法不是public<br>间接调用事务<br>没有配置事务管理器<br>传播行为配置的为not_supported<br>异常被处理<br>回滚异常类型不正确]]></description><link>教程\3、Spring课件.html</link><guid isPermaLink="false">教程/3、Spring课件.md</guid><pubDate>Tue, 20 May 2025 08:04:10 GMT</pubDate><enclosure url="\01.spring架构体系.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\01.spring架构体系.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[SpringMVC入门案例]]></title><description><![CDATA[ 
 <br><br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;
            &lt;version&gt;3.1.0&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
 &lt;/dependency&gt;
  &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
 &lt;/dependency&gt;
        
<br><br>public class UserController implements Controller {
    @Override
    public ModelAndView handleRequest(HttpServletRequest request, HttpServletResponse response) throws Exception {
        return new ModelAndView("/user.jsp");
    }
}
<br><br>&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    springMVC success
&lt;/body&gt;
&lt;/html&gt;
<br><br>&lt;servlet&gt;
        &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
    &lt;/servlet&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;springMVC&lt;/servlet-name&gt;
        &lt;url-pattern&gt;/&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;
<br><br>&lt;bean id="/test" class="net.wanho.UserController"/&gt;
<br><br><br>ApplicationContext的实现类：<br>​	AnnotationConfigApplicationContext<br>​	ClassopathXmlApplicationContext<br>​	FileSystemXmlApplicationContext<br>​	WebApplicationContext<br>WebApplicationContext的配置文件的默认命名规则： dispatcherServlet的Servletnname -servlet.xml
(FrameworkServlet和XmlWebApplicationContext当中)<br>想要修改，web.xml当中增加dispatcherServlet的初始化参数即可。<br><br>找不到“/01.springMVC运行流程.png”。<br><br><br><br>置扫描路径以及开启mvc注解<br>&lt;context:component-scan base-package="net.wanho"/&gt;
    &lt;context:annotation-config/&gt;

&lt;!--    启用mvc的注解，使用RequestMappingHandlerAdapter适配器--&gt;
    &lt;mvc:annotation-driven /&gt;
<br><br>@RequestMapping("test")
    public ModelAndView doTest(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/user.jsp");
        return mv;
    }
<br><br>@RequestMapping可以放在类上，也可以放在方法上面。如果放在类上，其下面的所有控制器方法在访问的时候，都需要使用此前缀。命名空间<br><br>用来映射请求的url<br>ant风格，可以设置通配符，在rest风格上，可以设置参数。<br>*：匹配任意个字符，但是只能匹配一层<br>**：匹配任意个字符，但是可以匹配多层<br>？：匹配任意一个字符<br>@RequestMapping("test/*")
    public ModelAndView doTest(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/user.jsp");
        return mv;
    }

    @RequestMapping("add/**")
    public ModelAndView add(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/useradd.jsp");
        return mv;
    }

    @RequestMapping(value = "index/ab?d" )
    public ModelAndView index(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/index.jsp");
        return mv;
    }
<br><br>method属性限制方法能够处理的请求方式，不设置的时候，只要url即可<br>只能处理post方法请求，其他方式不能处理<br> @RequestMapping(value = "index/ab" ,method = RequestMethod.POST)
    public ModelAndView index(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/index.jsp");
        return mv;
    }
<br><br>params：用来限制请求的参数  params={"username"}<br>headers:  限制请求头<br>consumes：限制请求的content-type类型<br>produces：设置response的Content-type类型，经常用来解决JSON字符集问题。<br>@RequestMapping(value = "params",params = {"username"})
    public ModelAndView param(){
        ModelAndView mv = new ModelAndView();
        mv.setViewName("/index.jsp");
        return mv;
    }
<br><br><br><br>@RequestMapping("m1")
    public ModelAndView m1(String username,String password){
        System.out.println("username:" + username + ",password:" + password);
        return new ModelAndView("/param.jsp");
    }
<br><br>命名纠正，当参数名和形式参数名不一致的时候，可以使用此注解来纠正命名。<br>用来指定参数是否必须以及默认值<br> @RequestMapping("m2")
    public ModelAndView m2(@RequestParam("userName") String username
            ,@RequestParam(value = "count",required = false,defaultValue = "0") int count){
        System.out.println("username:" + username + ",count:" + count);
        return new ModelAndView("/param.jsp");
    }
<br><br>使用pojo对象来接收参数。pojo的属性名需要和参数的key一致<br> @RequestMapping("m3")
    public ModelAndView m3(User user){
        System.out.println("username:" + user.getName() + ",age:" + user.getAge());
        return new ModelAndView("/param.jsp");
    }
    
 @RequestMapping("m4")
    public ModelAndView m4(User user,int count){
        System.out.println("username:" + user.getName()
                + ",age:" + user.getAge()
                + ",count:" +count );
        return new ModelAndView("/param.jsp");
    }
<br><br>@RequestMapping("m6")
    public ModelAndView m6(HttpServletRequest request){
        System.out.println(request.getParameter("username"));
        return new ModelAndView("/param.jsp");
    }

<br><br> @RequestMapping("m7/{idx}")
    public ModelAndView m7(@PathVariable("idx") int id){
        System.out.println("id=" + id);
        return new ModelAndView("/param.jsp");
    }
<br><br>解决方案一（较老）<br>@InitBinder + @DateTimeFormat<br>@InitBinder
    protected void init(HttpServletRequest request, ServletRequestDataBinder binder){
        SimpleDateFormat dateFormat= new SimpleDateFormat("yyyy-MM-dd");
        dateFormat.setLenient(false);
        binder.registerCustomEditor(Date.class,new CustomDateEditor(dateFormat,false));
    }
    
     @RequestMapping("m8")
    public ModelAndView m8(@DateTimeFormat(pattern = "yyyy-MM-dd") Date birthday){
        System.out.println("id=" + birthday);
        return new ModelAndView("/param.jsp");
    }
<br>方案二<br>开启mvc注解 + @DateTimeFormat注解<br>&lt;mvc:annotation-driven /&gt;
<br>测试代码<br> @RequestMapping("m8")
    public ModelAndView m8(@DateTimeFormat(pattern = "yyyy-MM-dd") Date birthday){
        System.out.println("id=" + birthday);
        return new ModelAndView("/param.jsp");
    }
<br><br>无论使用ModelAndView，还是Model，ModelMap或者Map接口对象，Spring都会将数据整合到request对象当中<br><br> @RequestMapping("m1")
    public String m1(HttpServletRequest request) {
        request.setAttribute("message","success !");
        return "/result.jsp";
    }
<br><br>@RequestMapping("m2")
    public ModelAndView m2() {
        ModelAndView mv = new ModelAndView("/result.jsp");
        mv.addObject("message","ModelAndView success");
        return mv;
    }
<br><br>@RequestMapping("m3")
    public String m3(Model model, ModelMap modelMap, Map&lt;String,Object&gt; map) {
        model.addAttribute("message","model success");
        modelMap.addAttribute("info","modelmap info");
        map.put("mapInfo","map message");
        return "/result.jsp";
    }
<br><br><br><br>重定向：客户端行为，多次请求，数据不共享<br>转发：服务器端行为，一次请求<br>springMVC当中默认是转发，如果需要重定向的话，则使用redirect:关键字放在逻辑视图名之前，视图解析器默认重定向的视图名即为物理视图名。重定向不能访问WEB-INF下的所有资源。<br>转发也可以指定关键字forword，使用关键字之后，视图解析器会和redirect关键字一样的处理，直接默认为物理视图名。<br><br><br><br>Spring提供了字符过滤器CharacterEncodingFilter.<br>如果CharacterEncodingFilter配置的字符集和jsp的contentType不一致的话，是无法解决乱码问题的。<br>@Override
	protected void doFilterInternal(
			HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)
			throws ServletException, IOException {

		//获取字符集参数
		String encoding = getEncoding();
		//不为null
		if (encoding != null) {
			//forceRequestEncoding为true，或者request没有设置字符集，则使用我们设置的字符集
			if (isForceRequestEncoding() || request.getCharacterEncoding() == null) {
				request.setCharacterEncoding(encoding);
			}
            //forceResponseEncoding:
			if (isForceResponseEncoding()) {
				response.setCharacterEncoding(encoding);
			}
		}
		filterChain.doFilter(request, response);
	}
<br><br><br>&lt;!--    解决方案一：使用默认的处理器--&gt;
&lt;!--    &lt;mvc:default-servlet-handler /&gt;--&gt;
&lt;!--    方案二：使用mvc:resources指定资源文件的映射关系--&gt;
        &lt;mvc:resources mapping="/images/**" location="/images/"&gt;&lt;/mvc:resources&gt;
&lt;!--        方案三--&gt;
&lt;!--    配置DispatcherServlet的时候，仅仅配置动态资源需要走DispatcherServlet，--&gt;
&lt;!--    常见的配置方式 *.do--&gt;
<br><br><br>&lt;dependency&gt;
    &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
    &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
    &lt;version&gt;2.13.5&lt;/version&gt;
&lt;/dependency&gt;
<br><br>&lt;mvc:default-servlet-handler /&gt;
<br><br>&lt;img src="images/fox.jpg" style="width: 200px;height: 200px" /&gt;
    &lt;button id="btnAjax"&gt;ajax&lt;/button&gt;
    &lt;button id="btnAjaxJson"&gt;ajaxJSON&lt;/button&gt;
    &lt;script src="js/jquery.js"&gt;&lt;/script&gt;

    &lt;script&gt;
        $(function () {
            $("#btnAjax").click(function () {
                //URL :  ajax01
                //参数： username，password
                let data = {"username":"admin","password":"123456"};
                $.ajax({
                    url: 'ajax01',
                    data,
                    type:'get',
                    success(data){
                        console.log(data);
                    }
                })
            })

            $("#btnAjaxJson").click(function () {
                //URL :  ajax01
                //参数： username，password
                let data = {"username":"admin","password":"123456"};
                $.ajax({
                    url: 'ajax02',
                    data:JSON.stringify(data),
                    type:'post',
                    contentType:'application/json',
                    success(data){
                        console.log(data);
                    }
                })
            })
        })
    &lt;/script&gt;
<br><br>不能直接使用get请求，设置contentType：application/json<br>使用整体接收，增加@RequestBody注解<br>@Controller
public class AjaxController {

    //@RequestMapping("ajax01")
    //@ResponseBody
    //public String doAjax01(String username,String password){
    //    System.out.println(username + "," + password);
    //    return "success";
    //}

    @RequestMapping("ajax01")
    @ResponseBody
    public String doAjax01(User user){
        System.out.println(user.getUsername() + "," + user.getPassword());
        return "success";
    }

    //@RequestMapping(value = "ajax02",produces = "text/plain;charset=utf-8")
    //@ResponseBody
    //public String doAjax02(@RequestBody User user){
    //    System.out.println(user.getUsername() + "," + user.getPassword());
    //    return "成功接收";
    //}
    @RequestMapping(value = "ajax02",produces = "application/json;charset=utf-8")
    @ResponseBody
    public User doAjax02(@RequestBody User user){
        User user1 = new User();
        user1.setUsername("java180");
        user1.setPassword("123456789");
        return user1;
    }
}
<br><br><br>SpringMVC的文件上传使用MultipartResolver（实现：CommonsMultipartResolver），CommonsMultipartResolver依旧需要apache的commons-fileupload组件<br>增加依赖<br>配置MultipartResolver<br>编写jsp页面<br>编写控制器<br>发布测试<br><br>&lt;dependency&gt;
            &lt;groupId&gt;commons-fileupload&lt;/groupId&gt;
            &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt;
            &lt;version&gt;1.5&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt;
&lt;!--        配置请求默认的字符集--&gt;
        &lt;property name="defaultEncoding" value="utf-8"/&gt;
&lt;!--        设置单个文件的大小--&gt;
        &lt;property name="maxUploadSizePerFile" value="10245760"/&gt;
&lt;!--        总文件大小--&gt;
        &lt;property name="maxUploadSize" value="102457600"/&gt;
&lt;!--        每次最多读入多少到内存--&gt;
        &lt;property name="maxInMemorySize" value="4096"/&gt;
&lt;!--        &lt;property name="uploadTempDir" value="/temp"/&gt;--&gt;
    &lt;/bean&gt;
<br><br>&lt;form action="upload" method="post" enctype="multipart/form-data"&gt;
        &lt;input type="file" name="file01"&gt;
        &lt;input type="submit" value="上传"&gt;
    &lt;/form&gt;
<br><br>@Controller
public class FileController {

    private static String UPLOAD_DIR="/temp";

    @RequestMapping("upload")
    public String doUpload(@RequestParam("file01")MultipartFile file01) throws IOException {
         //判断上传目录是否存在，如果不存在则先创建
        File dirFile = new File(UPLOAD_DIR);
        if (!dirFile.exists()){
            dirFile.mkdirs();
        }

        //获取文件名
        String filename = file01.getOriginalFilename();
        File destFile = new File(UPLOAD_DIR,filename);
        ////获取输入流
        //InputStream in = file01.getInputStream();
        //byte[] b = new byte[4096];
        //

        //OutputStream out = new FileOutputStream(destFile);
        //int len;
        //while((len=in.read(b)) != -1) {
        //    out.write(b,0,len);
        //}
        //in.close();
        //out.close();
        file01.transferTo(destFile);
        return "/upload.jsp";

    }
}
<br><br>不能直接使用ajax<br> //importTemplate
    @GetMapping("importTemplate")
    public void importTemplate(HttpServletRequest request, HttpServletResponse response) {
        ///文件名可以不是传入resource
        response.addHeader("download-filename","userTemporary.xls");
        //要暴露neader
        response.setHeader("Access-Control-Expose-Headers","download-filename");

        try {
            String fileName = "userTemporary.xls";
            System.out.println(request.getSession().getServletContext().getContextPath());
            //文件在target中
            String realPath = request.getSession().getServletContext().getRealPath("/"+fileName);
            FileInputStream is = new FileInputStream(new File(realPath));
            // 3. 获取响应输出流
            response.setContentType("text/plain;charset=UTF-8");
            // 4. 附件下载 attachment 附件 inline 在线打开(默认值)
            response.setHeader("content-disposition", "attachment;fileName=" +"userTemplate.xls");
            // 5. 处理下载流复制
            ServletOutputStream os = response.getOutputStream();
            int len;
            byte[] b = new byte[1024];
            while(true){
                len = is.read(b);
                if(len == -1) break;
                os.write(b, 0, len);
            }
            // 释放资源
            os.close();
            is.close();


        } catch (Exception e) {
            e.printStackTrace();
        }
    }
<br><br>随着终端的多样化，应用也越来越复杂。例如小程序，公众号，App等等，不仅仅原来基于电脑端的web应用，接口的设计愈来愈复杂。<br>在REST应用当中，用户使用相同的url，不同的请求方式来区分请求。在前后端分离的项目当中，前端的开发人员不会对请求的地址产生混淆，形成统一的接口。<br>C--&gt; POST    R--   GET    U----PUT   D---DELETE<br>传统风格的路径
http：//localhost:8080/user/list
http：//localhost:8080/user/getOne?id=1
http://localhost:8080/user/add?id=2&amp;name=zhangsan
http://localhost:8080/user/update?id=2&amp;name=zhangsan
http://localhost:8080/user/deleteOne?id=1


GET  http：//localhost:8080/users
GET  http：//localhost:8080/users/{id}
POST http://localhost:8080/users
PUT  http://localhost:8080/users
DELETE http://localhost:8080/user/users/{id}
<br>@RestController  == @Controller + @ResponseBody : 当前处理器类当中的方法，返回的都是数据，而不是视图<br>@PathVariable：用于获取路径上的参数<br>@GetMapping  @PostMapping  @PutMapping  @DeleteMapping<br>@RestControllerAdvice：用于全局异常处理的控制器通知注解<br><br>SpringMVC的拦截器，主要用来拦截控制器方法的执行，可以用来判断权限等处理。<br>应用场合：AOP，事务，日志，权限<br><br>SpringMVC如何实现拦截器：实现HandlerInterceptor接口或者继承HandlerInterceptorAdapter类（5.3开始的版本不推荐使用，过时）<br>拦截器需要注册到容器当中，可以注册全局拦截器，也可以针对局部进行拦截。<br>user/m1, m2,m3  三个请求的url，拦截user/m1,user/m2 ,其中m3方法不拦截<br>定义控制器<br>定义拦截器<br>配置拦截器<br><br><br>public class HandlerExecutionChain {

	private static final Log logger = LogFactory.getLog(HandlerExecutionChain.class);

	//处理器
	private final Object handler;
	//拦截器list
	private final List&lt;HandlerInterceptor&gt; interceptorList = new ArrayList&lt;&gt;();
	//用来记录preHandle为true的最大索引
	private int interceptorIndex = -1;
<br><br><br>实现原理：拦截器是基于java的反射机制，过滤器是基于函数回调的，主要是依靠filterChain.doFilter()<br>应用场合：拦截器可以用于web项目，也可以用于非web项目，springMVC的执行主体是MVC容器<br>​	过滤器是由servletAPI提供，只能应用于web项目。执行主体由servlet容器调用（目前是tomcat）<br>触发时点：过滤器在进入容器之后，servlet执行之前开始预处理<br>​		 拦截器实在servlet处理之后，处理器方法执行之前进行预处理，渲染结束之后才结束<br>处理的信息：过滤器只能获取request和response进行处理，<br>​		拦截器能够对除了request和response的handler的信息进行处理，比如上下文，handler上注解等信息<br>作用范围：<br>​	过滤器几乎对所有的请求都有静态<br>​	拦截器只对处理器起作用<br><br><br>在控制器当中增加一个处理异常的方法，并使用@ExceptionHandler注解.<br>放在一个普通的Controller当中，只对当前的控制器有效，其他的控制器无效。<br>如果想全局有效，可以定义一个baseController，并在其中定义异常处理的方法，其他的controller继承此baseController。<br>@ExceptionHandler (Exception.class)
public String doErr(Exception ex){
	return "/error. jsp";
}
<br><br>ControllerAdvice放在一个类上，此类中的方法是用来统一处理异常。<br>@ControllerAdvice
public class ExceptionControllerAdvice {
	@ExceptionHandLer(Exception. cLass)
    public String doErr(Exception ex){
        return "/error. jsp";
    }
    
    @ExceptionHandLer(BusinessException.cLass)
    public String doErr1( BusinessException ex){
    	return "/bsError.jsp";
    }

}

<br><br><br>spring-webmvc，spring-jdbc，mysql，mybatis，mybatis-spring，spring-aspects，spring-tx，pageHelper，jackson-databind，co·mmons-fileupload，servlet，druid<br><br>&lt;!--    配置后端上下文--&gt;
    &lt;context-param&gt;
        &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
        &lt;param-value&gt;classpath:application.xml&lt;/param-value&gt;
    &lt;/context-param&gt;
    &lt;listener&gt;
        &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;
    &lt;/listener&gt;

&lt;!--配置web上下文--&gt;
    &lt;servlet&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
            &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;
        &lt;/init-param&gt;
        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
    &lt;/servlet&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;

<br><br>&lt;context:component-scan base-package="net.wanho.controller"/&gt;
    &lt;context:annotation-config/&gt;
&lt;--启用mvc的注解，比如requestMapping--&gt;&lt;/----&gt;
    &lt;mvc:annotation-driven/&gt;

    &lt;bean 
     &lt;--视图解析器--&gt;     class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt;
        &lt;property name="prefix" value="/pages"/&gt;
        &lt;property name="suffix" value=".jsp"/&gt;
    &lt;/bean&gt;
    &lt;bean id="multipartResolver" 
 	&lt;--文件上传--&gt;         class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt;
        &lt;property name="maxUploadSizePerFile" value="10485760"/&gt;
        &lt;property name="maxUploadSize" value="104857600"/&gt;
        &lt;property name="maxInMemorySize" value="4096"/&gt;
        &lt;property name="defaultEncoding" value="UTF-8"/&gt;
    &lt;/bean&gt;
<br><br>&lt;!--    serveice以及mapper的扫描--&gt;
    &lt;context:component-scan base-package="net.wanho"&gt;
        &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt;
    &lt;/context:component-scan&gt;
    &lt;context:annotation-config/&gt;
&lt;!--    开启aop注解--&gt;
    &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt;

&lt;!--    配置数据源--&gt;
    &lt;util:properties id="db" location="classpath:jdbc.properties"/&gt;
    &lt;bean id="dataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt;
        &lt;property name="driverClassName" value="#{db.driver}"/&gt;
        &lt;property name="url" value="#{db.url}"/&gt;
        &lt;property name="username" value="#{db.username}"/&gt;
        &lt;property name="password" value="#{db.password}"/&gt;
        &lt;property name="initialSize" value="#{db.initSize}" /&gt;
        &lt;property name="maxWait" value="#{db.maxWait}" /&gt;
        &lt;property name="maxActive" value="#{db.maxActive}" /&gt;
    &lt;/bean&gt;
&lt;!--    配置sqlSessionFactory--&gt;
    &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
        &lt;property name="typeAliasesPackage" value="net.wanho.entity"/&gt;
        &lt;property name="mapperLocations" value="classpath:mappers/*.xml"/&gt;
        &lt;property name="configuration"&gt;
            &lt;bean class="org.apache.ibatis.session.Configuration"&gt;
                &lt;property name="mapUnderscoreToCamelCase" value="true"/&gt;
                &lt;property name="logImpl" value="org.apache.ibatis.logging.stdout.StdOutImpl"/&gt;
                &lt;property name="cacheEnabled" value="true"/&gt;
              &lt;/bean&gt;
        &lt;/property&gt;
        &lt;property name="plugins"&gt;
            &lt;bean class="com.github.pagehelper.PageInterceptor"&gt;
                &lt;property name="properties"&gt;
                    &lt;props&gt;
                        &lt;prop key="helperDialect"&gt;mysql&lt;/prop&gt;
                        &lt;prop key="reasonable"&gt;true&lt;/prop&gt;
                    &lt;/props&gt;
                &lt;/property&gt;
            &lt;/bean&gt;
        &lt;/property&gt;
    &lt;/bean&gt;

&lt;!--   配置 mapperScanner--&gt;
    &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt;
        &lt;property name="basePackage" value="net.wanho.dao"/&gt;
        &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt;
    &lt;/bean&gt;
&lt;!--    事务管理器--&gt;
    &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt;
        &lt;property name="dataSource" ref="dataSource"/&gt;
    &lt;/bean&gt;
    &lt;!--    开启事务注解--&gt;
    &lt;tx:annotation-driven transaction-manager="transactionManager"/&gt;

<br>]]></description><link>教程\4、SpringMVC.html</link><guid isPermaLink="false">教程/4、SpringMVC.md</guid><pubDate>Tue, 16 Jan 2024 01:10:18 GMT</pubDate></item><item><title><![CDATA[04.创建版本库.方法二.png]]></title><description><![CDATA[ 
 ]]></description><link>教程\04.创建版本库.方法二.png.html</link><guid isPermaLink="false">教程/04.创建版本库.方法二.png.md</guid><pubDate>Thu, 23 Nov 2023 09:00:14 GMT</pubDate></item><item><title><![CDATA[04.上传文件.png]]></title><description><![CDATA[ 
 ]]></description><link>教程\04.上传文件.png.html</link><guid isPermaLink="false">教程/04.上传文件.png.md</guid><pubDate>Thu, 23 Nov 2023 08:55:13 GMT</pubDate></item><item><title><![CDATA[04.消息队列-Publish-Subscribe.png]]></title><description><![CDATA[ 
 ]]></description><link>教程\04.消息队列-Publish-Subscribe.png.html</link><guid isPermaLink="false">教程/04.消息队列-Publish-Subscribe.png.md</guid><pubDate>Sun, 08 Oct 2023 09:34:31 GMT</pubDate></item><item><title><![CDATA[04.TortoiseGit中文语言包.png]]></title><description><![CDATA[ 
 ]]></description><link>教程\04.TortoiseGit中文语言包.png.html</link><guid isPermaLink="false">教程/04.TortoiseGit中文语言包.png.md</guid><pubDate>Thu, 23 Nov 2023 08:55:49 GMT</pubDate></item><item><title><![CDATA[poi]]></title><description><![CDATA[ 
 <br><br>主要用来完成excel的读写操作。<br><br><br><br>WorkBook：代表一个Excel对象接口<br>​	HSSFWorkbook：操作excel2003以前的版本，扩展名为.xls, 导出的行数的65536，超出此行数，系统会抛出异常。<br>​	XSSFWorkbook：操作2007以后的版本，扩展名.xlsx, 导出行数大概是104(1048575)万多一点。如果数据量较大的情况下，有可能会导致OOM. 原因就是所有的行数数据都在内存当中，没有进行存储并清除。<br>​	SXSSFWorkbook：操作2007以后的版本，导出行数和XSSFWorkbook，性能上有所提升，降低OOM的概率。<br><br>用来表示excel当中的sheet，使用index或者名称来定位。<br><br>代表excel当中的某一行<br><br>代表excel当中的某个单元格<br><br>表格样式对象<br><br><br>public static void main(String[] args) throws IOException {
        //创建一个工作薄
        Workbook workbook = new XSSFWorkbook();
        //创建sheet
        Sheet sheet = workbook.createSheet("test");

        //创建一个行
        Row row = sheet.createRow(0);
        //创建单元格
        Cell cell = row.createCell(0);
        //写入数据
        cell.setCellValue("java180-测试");

        //写入文件
        try(FileOutputStream out = new FileOutputStream("base01.xlsx")){
            workbook.write(out);
            workbook.close();

        } catch (IOException ex) {
        }
    }
<br><br>public static void main(String[] args) throws IOException {
        //创建一个工作薄
        Workbook workbook = new XSSFWorkbook();
        //创建sheet
        Sheet sheet = workbook.createSheet("test");

        //创建一个行
        Row row = sheet.createRow(0);
        //创建单元格
        Cell cell = row.createCell(0);
        //写入数据
        cell.setCellValue("java180-测试");

        CellStyle moneyStyle = workbook.createCellStyle();
        DataFormat moneyFormat = workbook.createDataFormat();
        moneyStyle.setDataFormat(moneyFormat.getFormat("###,##0.000"));
        Cell cell1 = row.createCell(1);
        cell1.setCellValue(230002.58);
        cell1.setCellStyle(moneyStyle);


        CellStyle dateStyle = workbook.createCellStyle();
        DataFormat dateFormat = workbook.createDataFormat();
        dateStyle.setDataFormat(moneyFormat.getFormat("yyyy-MM-dd"));

        cell = row.createCell(2);
        cell.setCellValue(new Date());
        cell.setCellStyle(dateStyle);
    

        //写入文件
        try(FileOutputStream out = new FileOutputStream("base02.xlsx")){
            workbook.write(out);
            workbook.close();

        } catch (IOException ex) {
        }
    }
<br><br>基于poi，使用简答的数据的导入导出。使用的注解方式，支持excel模板的处理，还支持word的导出<br><br>@Excel ：放在属性上面，设置表头的列名，也可以用来设置格式<br>]]></description><link>教程\5、excel.html</link><guid isPermaLink="false">教程/5、excel.md</guid><pubDate>Wed, 12 Jul 2023 04:54:23 GMT</pubDate></item><item><title><![CDATA[Vue概述]]></title><description><![CDATA[ 
 <br><br><br>Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与<a data-tooltip-position="top" aria-label="https://vuejs.zcopy.site/v2/guide/single-file-components.html" rel="noopener nofollow" class="external-link" href="https://vuejs.zcopy.site/v2/guide/single-file-components.html" target="_blank">现代化的工具链</a>以及各种<a data-tooltip-position="top" aria-label="https://github.com/vuejs/awesome-vue#libraries--plugins" rel="noopener nofollow" class="external-link" href="https://github.com/vuejs/awesome-vue#libraries--plugins" target="_blank">支持类库</a>结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。<br><br>Model-View-ViewModel的简写，本质上是MVC的改进版。将View的状态和行为抽象化，让我们将视图UI和业务逻辑分开。主要的目的和MVC一样，分离视图和模型。<br>提供双向绑定的js库，核心是MVVM中VM部分，VM部分负责连接View和Model，保证视图和数据的一致性。<br>好处：前端开发高效，便捷。<br>核心思想：数据驱动视图<br><br>数据绑定的最常用的形式就是插值表达式，是一个单向绑定。 <br>语法：{{表达式}}<br>支持加减乘除运算<br>支持逻辑运算符<br>支持三目运算符<br>&lt;body&gt;
    &lt;div id="app"&gt;{{message}}
            &lt;br&gt;{{count + 100}}
            &lt;br&gt;
            {{count&gt;100}}    
            &lt;br&gt;
            {{count&gt;100?'ok':'NO'}}
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                message: 'hello',
                count: 100
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>在vue当中提供一系列的指令用于对数据的操作。都i是以v-xxx形式出现，特殊情况下有简写。<br>指令当中封装一些DOM的行为，根据不同的值，框架会对DOM进行相关的操作<br><br>v-text会覆盖原来dom元素中的值。只会替换原来的值，不会清空这个DOM元素。类似js原生操作中的innerText。<br>当值当中存在html元素的时候，不会进行解析和渲染，按照文本的形式输出<br>&lt;body&gt;
    &lt;div id="app"&gt;{{message}}
           &lt;h3 v-text="info"&gt;happy&lt;/h3&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                message: 'hello',
                count: 100,
                info:'java180&lt;i&gt;中华&lt;/i&gt;'
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>会覆盖原来dom元素中的值。只会替换原来的值，不会清空这个DOM元素。类似js原生操作中的innerHtml。<br>当值当中存在html元素的时候，会进行解析和渲染.<br>&lt;body&gt;
    &lt;div id="app"&gt;{{message}}
           &lt;h3 v-html="info"&gt;happy&lt;/h3&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                message: 'hello',
                count: 100,
                info:'java180&lt;i&gt;中华&lt;/i&gt;'
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>v-bind指定：用于绑定组件的属性<br>1：单向绑定，从Model到View的单向绑定。<br>2：语法v-bind:属性名，可以进行简写  成  :属性名<br>3：v-bind会将它的值当成js的合法表达式。<br>&lt;body&gt;
    &lt;div id="app"&gt;{{message}}
           &lt;h3 v-bind:title="info"&gt;happy&lt;/h3&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                message: 'hello',
                count: 100,
                info:'java180都是小能手'
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>运用在表单元素当中，实现数据的双向绑定。<br>v-mode会忽略掉表单原生的value，checked，selected等属性，使用实例的值当作初始值。<br>&lt;body&gt;
    &lt;div id="app"&gt;{{info}}
        &lt;br&gt;
         &lt;input type="text" v-model="info"&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                info:'java180都是小能手'
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>vue是可以监听DOM事件，触发js的代码<br>1：绑定事件监听器，事件的类型由参数指定   v-on:事件类型="表达式"<br>2：表达式可以是一个方法名，也可以是一个内联语句（不推荐使用），如果没有修饰符，可以简写成@事件类型="表达式"<br>3：触发的事件监听器回调在vue对象的methods中定义<br><br>&lt;body&gt;
    &lt;div id="app"&gt;{{info}}
        &lt;br&gt;
         &lt;input type="text" v-model="info"&gt;
         &lt;br&gt;
         {{sum}}
        &lt;input type="number" v-model="step"&gt;
        &lt;button v-on:click="add"&gt;增加&lt;/button&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                info:'java180都是小能手',
                sum:0,
                step: 3
            },
            methods: {
                add(){
                   this.sum = this.sum + this.step; 
                }
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>在监听键盘事件的时候，可以添加事件修饰符<br>.enter     .tab     .esc    space,left ,right,down....<br>v-on:事件类型.修饰符<br>&lt;body&gt;
    &lt;div id="app"&gt;
        &lt;!-- &lt;input type="text" v-model="info" @keydown="check($event)"&gt; --&gt;
        &lt;input type="text" v-model="info" @keydown.enter="check()"&gt;
        &lt;span style="color: red;"&gt;{{errMsg}}&lt;/span&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                errMsg:'',
                info:''
            },
            methods: {
                // check(event){
                //    if (event.keyCode==13){
                //      if (this.info.length&lt;1 || this.info.length&gt;10) {
                //         this.errMsg = '请输入1到10个字符的字符串'
                //      } else {
                //         this.errMsg=''
                //      }
                //    }
                // }
                check(){
                    if (this.info.length&lt;1 || this.info.length&gt;10) {
                        this.errMsg = '请输入1到10个字符的字符串'
                     } else {
                        this.errMsg=''
                     }
                }
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>vue当中的事件绑定，除了按键修饰符之外，还提供一些事件修饰符号。<br>stop：停止冒泡，调用event.stopPropagation（）<br>prevent: 停止默认事件，event.preventDefault ()<br>capture:调用事件回调函数时，采用捕获的事件流方向。<br>self：当事件从监听器绑定的元素本身触发的时候，才会回调（事件委托有关）<br>once: 事件只触发一次<br>&lt;body&gt;
    &lt;div id="app"&gt;
        &lt;a href="http://www.baidu.com" target="_blank" v-on:click.prevent="clickA" rel="noopener noreferrer"&gt;a连接&lt;/a&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                errMsg:'',
                info:''
            },
            methods: {
                clickA(){
                    //event.preventDefault()  不会终止页面跳转，而是将当前页面保存到页面根目录中。 这
                    alert("点击a连接")
                }
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>循环指令，item in items<br>可以迭代数组，item 是数据源当中每个元素的别名<br>迭代对象，迭代的是属性，item可以是（value，key，index）格式，只写一个默认是value<br>迭代整数：相当于1~n之间的整数迭代<br>迭代字符串：item为字符串当中的每个字符，会去掉开头和结尾的空格符<br>&lt;body&gt;
    &lt;div id="app"&gt;
        &lt;div&gt;
            &lt;input type="text" v-model="editForm.id"&gt;
            &lt;input type="text" v-model="editForm.name"&gt;
            &lt;input type="text" v-model="editForm.city"&gt;
            &lt;input type="text" v-model="editForm.state"&gt;
            &lt;input type="text" v-model="editForm.zip"&gt;
            &lt;button @click="add"&gt;add&lt;/button&gt;
            &lt;button @click="deleteSelect"&gt;add&lt;/button&gt;
        &lt;/div&gt;
        &lt;table&gt;
            &lt;tr v-for="user in users"&gt;
                &lt;td&gt;{{user.id}}&lt;/td&gt;
                &lt;td&gt;{{user.name}}&lt;/td&gt;
                &lt;td&gt;{{user.city}}&lt;/td&gt;
                &lt;td&gt;{{user.state}}&lt;/td&gt;
                &lt;td&gt;{{user.zip}}&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/table&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                editForm:{
                    id: '',
                    name:'',
                    city:'',
                    state:'',
                    zip: ''
                },
                users:[{
                    id:1, name: "Tyler Bennett", city: "New York", state: "NY", zip: "10001"
                },{
                    id:2, name: "John Rappl", city: "Boston", state: "MA", zip: "02107"

                },
                {
                    id:3, name: "Tyler max", city: "Chinese", state: "JS", zip: "210000"
                }
                ]
            },
            methods: {
                add(){
                    let user= this.editForm;
                    this.users.push(user);
                }
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>v-if <br>v-if    v-else<br>v-if   v-else-if   v-else<br>v-if: 来回销毁和创建DOM对象，性能上会受到影响。<br>v-show：不会销毁和创建DOM对象，使用display：none来隐藏元素，性能上有所提升。<br>&lt;body&gt;
    &lt;div id="app"&gt;
       &lt;!-- &lt;div v-if="grade=='A'"&gt;一等奖学金&lt;/div&gt;
       &lt;div id="test" v-else-if="grade=='B'"&gt;二等奖学金&lt;/div&gt;
       &lt;div v-else&gt;没有等奖学金&lt;/div&gt; --&gt;
       &lt;div v-show="grade=='A'"&gt;一等奖学金&lt;/div&gt;
       &lt;div v-show="grade=='B'"&gt;二等奖学金&lt;/div&gt;
       &lt;div v-show="grade !='A' &amp;&amp; grade !='B'"&gt;没有奖学金&lt;/div&gt;
       &lt;button @click="change"&gt;修改&lt;/button&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                grade:'A'
            },methods: {
                change(){
                    this.grade = this.grade=='A'?'B':'A';
                }
            }
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>使用v-bind：style和v-bind：class进行处理<br>&lt;body&gt;
    &lt;div id="app"&gt;
      &lt;div&gt;
        样式处理
      &lt;/div&gt;
      &lt;h3 :style='h3Style'&gt;内联样式&lt;/h3&gt;
      &lt;div :class="borderStyle"&gt;测试样式&lt;/div&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
                h3Style: 'color: red;',
                borderStyle: 'border1'
            },
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>vue的过滤器主要用于文本的格式化以及转换。不改变原有数据的值，只是改变显示形式。<br>主要使用在插值表达式和v-bind属性绑定上<br>放在js表达式的尾部，由管道符（|）来表示<br>私有过滤器和公有过滤器<br><br>在vue对象中，filters属性中添加一个方法。<br>过滤器必须带有一个参数，此参数就是从管道命令中接收过来的数据，也添加多个参数<br>可以创建多个过滤器，也可以同时使用多个过滤器<br>不带参数的过滤器，可以用方法名放在管道符的后面，如果带有参数，则类似于方法调用<br>过滤器必须带有返回值<br>&lt;body&gt;
    &lt;div id="app"&gt;
        &lt;div&gt;
            原来的值:{{message}}
        &lt;/div&gt;
        &lt;div&gt;过滤后的值:{{message | toUpper | concatFilter('java180')}}&lt;/div&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        new  Vue({
            el: "#app",
            data: {
               message:'abcHabcAA11'
            },
            filters: {
                toUpper(value) {
                    return value.toUpperCase();
                },
                concatFilter(value,suffix) {
                    return value + suffix
                }
            },
            
        })
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>使用Vue.filter(过滤器名，回调函数). 注意：一定要在vue对象实例化之前调用<br><br>计算属性是基于响应式缓存。当数据发生变化的时候，会重新计算值。<br><br>使用watch属性可以监听vue对象中数据的变化。<br>监听简单数据类型，只要顶一个function，可以获取原来的值和更新后的值<br>监听复杂数据类型，需要深度监听，使用deep属性和handler方法来进行处理。不能获取更新前的数据<br><br>主要是四个阶段： create，mount，update，destroy<br>beforeCreate：组件创建之前，无法通过vm来访问数据，调用方法。<br>created：组件创建之后，可以通过vm访问data数据，也可以调用method相关的方法，但是$el还未创建<br>beforeMount：挂载数据到实际DOM之前，页面是未经过Vue编译的DOM结构，所有的DOM操作不能起作用<br>mounted: 挂载数据到DOM之后， $el的对象被替换<br>&lt;body&gt;
    &lt;div id="app"&gt;
           &lt;span&gt;{{message}}&lt;/span&gt; 
           &lt;button @click="change"&gt;修改message&lt;/button&gt;
    &lt;/div&gt;    

    &lt;script&gt;
        
        // let person= {name:'zhangsan'}
        // Vue.prototype.newobject=person;
       
       let vm= new  Vue({
            el: "#app",
            data: {
               message:'java180',
            },
            methods: {
                change(){
                    this.message = this.message + "11";
                }
            },
            // beforeCreate () {
            //     console.log(this.message);
            //     console.log(document.getElementById("app"));
            // },
            // created(){
            //     console.log("=============created===============");
            //     console.log("message",this.message);
            //     console.log("$el",this.$el)
            //     console.log(document.getElementById("app").innerHTML);
            // },
            // beforeMount(){
            //     console.log("=============beforeMount===============");
            //     console.log("message",this.message);
            //     console.log("$el",this.$el)
            //     console.log(document.getElementById("app").innerHTML);
            // },
            // mounted(){

            //     console.log("=============mounted===============");
            //     console.log("message",this.message);
            //     console.log("$el",this.$el)
            //     console.log(document.getElementById("app").innerHTML);

            //     // console.log(this.newobject);
            // }

            beforeUpdate () {
                console.log("message",this.message);
                console.log(document.getElementById("app").innerHTML);
            },
            updated () {
                console.log("message",this.message);
                console.log(document.getElementById("app").innerHTML);
            },
            beforeDestroy () {
                console.log("beforeDestory");
            },
            destroyed () {
                console.log("destroyed");
            }
           
        })
        vm.$destroy();

       
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br>组件：实现应用中局部代码（html，css，js)以及部分资源（mp3,icon,mp4）的集合<br>组件化和模块化的区别：<br>模块化：原来大的js文件，处理的功能比较，文件的可读性以及可维护性降低，为了简化js以及复用js，将完成类似功能的特定的js代码分拆到多个小文件当中，并向外提供访问的接口对象。<br>模块化：用户界面比较复杂，为了简化代码，提升UI相关代码的重复利用率，抽取用户界面中的局部代码，放入相关的文件中。<br>分类：非单文件组件（语法），单文件组件（实际开发用）<br><br><br>使用vue.extend（{template:}）<br>let comp= Vue.extend({
            template:'#temp',
            data(){
               return {
                level:'起飞'
               } 
            }
        })
<br><br>注册私有组件，在vue对象的components属性中注册<br>注册公有组件：使用Vue.component("组件名"，组件对象)来进行注册<br>       Vue.component("my-comp",comp)
        Vue.component("ourComp",comp)
       let vm= new  Vue({
            el: "#app",
            data: {
               message:'java180',
            },
            components: {
                comp
            }   
           
        })
<br><br>1：无论哪种方式创建组件，template当中必须有且仅有一个根元素<br>2：组件的名称<br>​	支持Kebab-case风格，多个单词之间用短横线（中横线）连接<br>​	支持驼峰CamelCase命名，使用的时候依旧要使用中横线<br>&lt;my-comp&gt;&lt;/my-comp&gt;
 &lt;our-comp&gt;&lt;/our-comp&gt;
 
Vue.component("my-comp",comp)
Vue.component("ourComp",comp)
<br><br>需要使用函数方式来定义<br>let comp= Vue.extend({
    template:'#temp',
    data(){
        return {
        	level:'起飞'
        } 
    }
})
<br><br><br><br>&lt;body&gt;
    &lt;div id="app"&gt;
      &lt;monday v-show="week==1"&gt;&lt;/monday&gt;
      &lt;thuesday v-show="week==2"&gt;&lt;/thuesday&gt;
      &lt;button @click="changeWeek"&gt;change&lt;/button&gt;
      &lt;hr&gt;
      &lt;component :is="compName"&gt;&lt;/component&gt;

    &lt;/div&gt; 
    &lt;template id="temp1"&gt;
        &lt;div&gt;
            &lt;h3&gt;星期一&lt;/h3&gt;
        &lt;/div&gt;
    &lt;/template&gt;   
    &lt;template id="temp2"&gt;
        &lt;div&gt;
            &lt;h3&gt;星期二&lt;/h3&gt;
        &lt;/div&gt;
    &lt;/template&gt;   


    &lt;script&gt;

        let monday= Vue.extend({
            template:'#temp1',

        })
         let thuesday=Vue.extend({
            template:'#temp2'
         })
       let vm= new  Vue({
            el: "#app",
            data: {
               message:'java180',
               week:1,
               compName:'monday'
            },
            
            components: {
                monday,thuesday
            },
            methods: {
                changeWeek(){
                    this.week = this.week==1?2:1
                    this.compName = this.compName=='monday'? 'thuesday':'monday'

                }
            }
           
           
        })


       
    &lt;/script&gt;
    
&lt;/body&gt;
<br><br><br>官网地址：<a rel="noopener nofollow" class="external-link" href="https://nodejs.org/en" target="_blank">https://nodejs.org/en</a><br><br><br>npm config set registry https://registry.npm.taobao.org
<br><br>npm install -d:g @vue/cli
<br><br><br><br>#先切换盘符
d:
#再输入目录
D:\ftp180\04.code\06.front
<br><br>选择vue2的版本<br>#vue-cli是项目名
vue create vue-cli
<br>进入项目文件夹<br>cd  vue-cli
<br>运行项目<br>npm run serve
<br><br>vue.config.js文件<br><br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;h3  ref="user"&gt;用户&lt;/h3&gt;
        &lt;h3  ref="myinfo"&gt;{{ info }}&lt;/h3&gt;
        &lt;button @click="showInfo"&gt;显示信息&lt;/button&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
//vc  Vue Component
export default {
    name:'School',
    data(){
        return {
            info:'好好学习，天天向下'
        }
    },
    
    methods:{
        showInfo(){
            console.log(this.$refs.myinfo);
            // this.address = "测试修改"
        }
    }
}
&lt;/script&gt;

<br><br>props是只读的，vue底层会检测程序员对props的修改，如果你该了props的值，会在控制台发出警告信息。<br>如果根据业务确实需要修改的信息，请定义在data当中<br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;h3&gt;{{ address }}&lt;/h3&gt;
        &lt;h3&gt;{{ count }}&lt;/h3&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
//vc  Vue Component
export default {
    name:'School',
    //常用简写
    // props:['address','count'],
    //可以指定数据类型
    // props:{
    //     address: String,
    //     count: Number,

    // },
    props:{
        address:{
            type: String,
            required: true,
            default: '默认值'
        },
        count:{
            type:Number,
            default: 10
        }

    },

}

<br><br>&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;img alt="Vue logo" src="./assets/logo.png"&gt;
    &lt;!-- &lt;school address="卡子门校区" count ='50'&gt;&lt;/school&gt; --&gt;
    &lt;school  address="卡子门校区"&gt;&lt;/school&gt;
    &lt;hr&gt;
    &lt;h3&gt;app当中的内容&lt;/h3&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import School from './components/School.vue'
export default {
  name: 'App',
  components: {
    School
  }
}
&lt;/script&gt;
<br><br>scoped 属性表示当前设置的css相关样式，只针对school组件
一般情况下，只有app.vue（入口组件）在定义样式时不使用scoped，其他都会使用scoped属性<br>&lt;!-- scoped 属性表示当前设置的css相关样式，只针对school组件
一般情况下，只有app。vue（入口组件）在定义样式时不使用scoped，其他都会使用scoped属性
--&gt;
&lt;style scoped&gt;
    h3 {
        color:red;
    }
&lt;/style&gt;
<br><br><br><br><br>父组件当中使用provide方法传递值<br>子组件当中，使用inject来接收<br><br><br><br><br><img alt="02.兄弟参数传递" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/02.%E5%85%84%E5%BC%9F%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92.png" referrerpolicy="no-referrer"><br><br><br><br><br>#安装路由
npm install vue-router@3
#卸载路由
npm uninstall vue-router
<br><br>创建一个router文件（一定要放在src下），里面创建一个index.js文件<br>import VueRouter from "vue-router";
import Role from '../components/Role'
import User from '../components/User'

const router = new VueRouter({
    routes:[{
        path: '/user',
        component: User
    },{
        path: '/role',
        component: Role
    }]
})
export default  router
<br><br>修改main，引入vueRouter以及router对象<br>import Vue from 'vue'
import App from './App.vue'
#import对象
import VueRouter from 'vue-router'
import router from './router'

Vue.config.productionTip = false

//将路由组件应用到vue组件当中
Vue.use(VueRouter)
//vm
new Vue({
  render: h =&gt; h(App),
  beforeCreate(){
    Vue.prototype.$bus=this
  },
  router  //增加路由属性
}).$mount('#app')

<br><br>&lt;template&gt;
  &lt;div id="app"&gt;
      &lt;div&gt;
        &lt;router-link to="/user"  class="link"&gt;用户&lt;/router-link&gt;  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
        &lt;router-link to="/role"&gt;角色&lt;/router-link&gt;
      &lt;/div&gt;
      &lt;hr&gt;
      &lt;div&gt;
          &lt;router-view&gt;&lt;/router-view&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;
<br><br>每一个组件都会有$route属性，每个组件特有的，存储访问的url，参数（params,query），以及meta，那么等信息<br>每个应用都会有一个全局$router属性，用于存储应用中的所有路由信息。<br><br>import VueRouter from "vue-router";
//修改成懒加载形式
// import Role from '../components/Role'
// import User from '../components/User'

const router = new VueRouter({
    routes:[{
        path: '/user',
        component: ()=&gt;import('../components/User')
    },{
        path: '/role',
        component: ()=&gt;import('../components/Role'),
        
    }]
})
export default  router
<br><br>路由定义，使用children属性来定义<br><br>import VueRouter from "vue-router";
//修改成懒加载形式
// import Role from '../components/Role'
// import User from '../components/User'

const router = new VueRouter({
    routes:[{
        path: '/user',
        component: ()=&gt;import('../components/User')
    },{
        path: '/role',
        component: ()=&gt;import('../components/Role'),
        children:[
            {
                path:'pg',  //子路由不可以以“/”开头
                component:()=&gt;import('../components/Programmer')
            },
            {
                path:'db',
                component:()=&gt;import('../components/DbManager'),
               
            }
        ]
    }]
})
export default  router
<br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;router-link to="/role/db" class="link"&gt;数据库管理员&lt;/router-link&gt;
        &lt;router-link to="/role/pg" class="link"&gt;开发人员&lt;/router-link&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    mounted(){
        console.log(this);
    }
}
&lt;/script&gt;
<br><br>使用模板字符串或者对象方式方式传递时，如果使用query方式传递数据<br>&lt;template&gt;
    &lt;div&gt;
        &lt;!-- &lt;router-link v-for="manager in managers"  class="link"
           :to="`/role/db/detail?id=${manager.id}&amp;name=${manager.name}&amp;sex=${manager.sex} `" 
            :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt; --&gt;

            &lt;router-link v-for="manager in managers"  class="link"
                :to="{
                        path:'/role/db/detail',
                        query: {
                            id: manager.id,
                            name: manager.name,
                            sex:manager.sex
                        }
                }" 
                :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data(){
        return {
            managers:[{id:'1001',name:'小明',sex:'女'},
                     {id:'1002',name:'小白',sex:'女'}]
        }
    }
}
&lt;/script&gt;
<br><br>在路由中使用name属性进行命名<br><br> children:[{
     path:'detail',
     name: 'roleDetail',
     component:()=&gt;import('../components/Details.vue'),
 }]
<br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;!-- &lt;router-link v-for="manager in managers"  class="link"
           :to="`/role/db/detail?id=${manager.id}&amp;name=${manager.name}&amp;sex=${manager.sex} `" 
            :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt; --&gt;

            &lt;router-link v-for="manager in managers"  class="link"
                :to="{
                        //path:'/role/db/detail',
                        name: 'roleDetail'
                        query: {
                            id: manager.id,
                            name: manager.name,
                            sex:manager.sex
                        }
                }" 
                :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data(){
        return {
            managers:[{id:'1001',name:'小明',sex:'女'},
                     {id:'1002',name:'小白',sex:'女'}]
        }
    }
}
&lt;/script&gt;
<br><br>在使用REST风格的时候，使用params来传递参数，在path上，使用:参数名,传参数时，使用params属性<br>必须使用命名路由方式，不能使用path属性<br><br>import VueRouter from "vue-router";
//修改成懒加载形式
// import Role from '../components/Role'
// import User from '../components/User'

const router = new VueRouter({
    mode:'history', //默认是hash模式，可以改成history
    routes:[{
        path: '/user',
        component: ()=&gt;import('../components/User')
    },{
        path: '/role',
        component: ()=&gt;import('../components/Role'),
        children:[
            {
                path:'pg',  //子路由不可以以“/”开头
                component:()=&gt;import('../components/Programmer')
            },
            {
                path:'db',
                component:()=&gt;import('../components/DbManager'),
                children:[{
                    path:'detail/:id/:name/:sex',
                    name: 'roleDetail',
                    component:()=&gt;import('../components/Details.vue'),
                }]
            }
        ]
    }]
})
export default  router
<br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;!-- &lt;router-link v-for="manager in managers"  class="link"
           :to="`/role/db/detail?id=${manager.id}&amp;name=${manager.name}&amp;sex=${manager.sex} `" 
            :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt; --&gt;

            &lt;router-link v-for="manager in managers"  class="link" :replace="true"
                :to="{
                        // path:'/role/db/detail',
                        name: 'roleDetail',
                        params: {
                            id: manager.id,
                            name: manager.name,
                            sex:manager.sex
                        }
                }" 
                :key="manager.id"&gt;{{manager.id}}&lt;/router-link&gt;
        &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data(){
        return {
            managers:[{id:'1001',name:'小明',sex:'女'},
                     {id:'1002',name:'小白',sex:'女'}]
        }
    }
}
&lt;/script&gt;
<br><br>调用vm或者vc对象的$router对象的方法<br>push，replace，go，back等方法进行路由跳转。<br>&lt;template&gt;
  &lt;div id="app"&gt;
      &lt;div&gt;
        &lt;button @click="toUser" class="link"&gt;用户&lt;/button&gt;
        &lt;button @click="toRole" class="link"&gt;角色&lt;/button&gt;
      &lt;/div&gt;
      &lt;hr&gt;
      &lt;div&gt;
          &lt;router-view&gt;&lt;/router-view&gt;
      &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;

export default {
  name: 'App',
  
  components: {

  },
  methods:{
    toUser(){
      this.$router.push({
        path: '/user',
        query: {
          id:'test'
        }
      })
    },
    toRole(){
      this.$router.push({
        path: '/role'
      })
    }
  },
  mounted(){
    console.log(this.$router);
  }
}
&lt;/script&gt;
<br><br>vue本身不支持发送Ajax请求，必须要使用其他的组件（插件），目前使用比较多的axios<br>axios是基于promise的HTTP请求客户端，用来发送请求。<br><br>npm install axios
<br><br>vue.config.js文件当中增加devServer相关配置<br>/api开头的请求都是发送到后端的ajax请求，其他前端的url跳转<br>const { defineConfig } = require('@vue/cli-service')
module.exports = defineConfig({
  transpileDependencies: true,
  //禁用ESLINT检查
  lintOnSave: false  ,
  //api开头的请求都是后端的ajax请求
  devServer:{
    // port: 8080 //当前前端的服务器端口号，不该默认是8080
    https:false,
    proxy:{
      '/api':{
        // 前端:http://localhost:8080/api/test==&gt;后端：http://localhost:9000/test
        target: 'http://localhost:9000',
        changeOrigin: true, //允许跨域
        pathRewrite:{
          '^/api':''  //请求到后端路径修改，去掉/api
        }
      }
    }
  }
})
<br><br>ajaxTest(){
                //怎么发送ajax
                // Promise 提供两个方法，then一个catch
                // then: 调用后端正常返回后的回调方法
                // catch: 如果后端不正常返回，则调用该方法。回调参数是异常对象。
                axios.get('/api/test.do')
                .then((response)=&gt;{console.log(response);  })
                .catch((error)=&gt;{console.log(error);  })

            },
<br><br>ajaxPost(){
                // axios.post('/api/testPost.do',{id:'1001',name:'李白'})
                // .then((response)=&gt;{console.log(response);  })
                // .catch((error)=&gt;{console.log(error);  })  

                axios({
                    url:'/api/testPost.do',
                    method:'post', 	//default is 'post'
                    data:{id:'1001',name:'张三'}  //default is {} 	//body data

                }) .then((response)=&gt;{console.log(response);  })
                 .catch((error)=&gt;{console.log(error);  })  
            }
<br><br><br>创建util/request.js文件<br>import axios  from "axios"
const service = axios.create({
    // baseURL: "http://localhost:9000",
    baseURL:'',
    timeout: 3000
})

service.interceptors.request.use(function (config) {
    // 在发送请求之前做些什么
    //给所有的请求增加一个请求头信息， Authentication
    config.headers['Authentication']="java180"
    return config;
  }, function (error) {
    // 对请求错误做些什么
    return Promise.reject(error);
  })

  // 添加响应拦截器
  service.interceptors.response.use(function (response) {
    console.log("response.data",response.data);
    return response;
  }, function (error) {
    // 超出 2xx 范围的状态码都会触发该函数。
    // 对响应错误做点什么
    return Promise.reject(error);
  });

  export default service
<br><br>在使用的vue组件中先引入request对象，然后进行调用<br> request({
                    url:'/api/testInterceptor',
                    method:'POST',
                    data: data

                }).then((response)=&gt;{console.log(response);  })
<br><br>Vuex是用来管理Vue.js当中的状态。比较适合中大型项目。<br><br>能够在vuex当中集中管理共享数据，易于开发和管理<br>存储在vuex当中的数据时响应式的，能够实时保持和页面之间的同步<br><br><img style="zoom:80%;" alt="03.vuex的组件" src="\03.vuex的组件.png" referrerpolicy="no-referrer"><br><br>npm install vuex@3
<br><br><br><br>在src目录下创建一个store目录，并在其内部创建index.js<br>注意：由于在创建Vuex.Store对象之前需要让vue先使用Vuex对象，此处需要引入Vue，并且调用Vue.use(Vuex)<br>import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)
const actions= {
    add(context,value) {
        //调用axios，进行ajax操作
        //调用mutations当中的ADD方法
        context.commit('ADD',value)
    }

}

const mutations={
    ADD(state,value) {
        state.sum += value;
    },

    SUB(state,value) {
        state.sum -= value;
    }
    
}

const state={
    sum:0
}

export default new Vuex.Store({ 	
    state, 
    actions, 
    mutations 
})


<br><br>import Vue from 'vue'
import App from './App.vue'
import store from './store'


Vue.config.productionTip = false


//vm
new Vue({
  render: h =&gt; h(App),
  beforeCreate(){
    Vue.prototype.$bus=this
  },
  store
  
}).$mount('#app')

<br><br>&lt;template&gt;
    &lt;div&gt;
        &lt;h3&gt;合计:{{ $store.state.sum }}&lt;/h3&gt;
        &lt;div&gt;
            &lt;input type="number" v-model="step"&gt;
            &lt;button @click="add"&gt;+&lt;/button&gt; 
            &lt;button @click="subtract"&gt;-&lt;/button&gt;

        &lt;/div&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data () { 
        return { 
            step: 2 
        }
    },
    methods:{
        add() {
            //调用actions当中的方法
           this.$store.dispatch('add', parseInt(this.step));

        },
        subtract(){
            //调用mutations当中的方法
            this.$store.commit('SUB', parseInt(this.step));
        }
    }

}
&lt;/script&gt;
<br><br>state：用来存储共享数据<br>mutations: 定义一系列的方法，用来改变state中的数据，不用来调用后端的api，所有的方法都带有上store参数，value作为传入的值。<br>actions: 定义一系列方法，用来调用mutations当中的方法，带有一个上下文参数。可以用来调用后端的API<br>getters： 类似于组件当中的计算列<br>modules：模块化<br><br>mapState，mapGetters需要放在计算属性中<br>mapMutations和mapActions放在methods当中<br>

<br><br>]]></description><link>教程\6、Vue基础.html</link><guid isPermaLink="false">教程/6、Vue基础.md</guid><pubDate>Tue, 20 Feb 2024 09:39:17 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/ydh1cnn6/pic/master/02.%E5%85%84%E5%BC%9F%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/02.%E5%85%84%E5%BC%9F%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[06.string.png]]></title><description><![CDATA[ 
 <br><br><br>ast/asset/reportUrlImport/{fileId}<br>1、根据fileId查询文件对象，获取文件路径，读取文件<br>2、读取excel，sheet1页、头行数为1，使用excelReader对象读取excel<br>3、通过输入流，写入到文件系统的指定文件路径中<br>真正的插入在AssetReportUrlExcelDataListener，会执行invoke方法<br>4、插入。如果cId不知道在哪儿进行的初始化已经存在，则删除。继续封装对象并插入assetReportUrlService<br>有一个看不懂的List&lt;Future&gt; re ,不知道re是什么，在哪儿初始化<br>5、插入后。<br>1）如果re不为空，则记录处理结果（成功则succ++，失败则插入handerResult）。<br>2）关闭多线程，在Dap_Sys_File_Extr表中查询传人的文件Id，如果没查到该文件，则插入<br>从数据库查看是否要开启线程（数据库写的为true），并没有进行判断<br>day_sys_param表，记录了一些系统参入，类似与常量类，比如模板文件路径、页面的url、导入资产时是否开启线程等，很杂。<br><br>前端和上面几乎一样，通过if语句判断发送不同请求<br>ast/asset/addbloodimport/{fileId} NestController<br>1、查询文件，根据文件路径创建文件对象<br>2、从第0页开始，头行数为1，读取excel文件，<br>真正的插入在AddBloodListener中，会执行invoke方法<br>在生产库表（数据量很大，测试库380万数据，1.2G)中查看生产元数据（分别按导入数据中的源字段英文名和目标字段英文名查）<br>根据源数据Id和目标数据Id，在血缘表中查找出血缘关系对象列表，如果没有，则创建血缘关系对象并插入到血缘关系<br><br>前端和上面几乎一样，通过if语句判断发送不同请求<br>ast/assetAuthApply/userAuthImport/{fileId}<br>1、读取excel，包含资产序号、部门编号、用户编号、操作类型（资产编号：非空 操作类型：新增、删除）<br>3、根据id查询出对应资产，过滤掉资产权限不是3、4、5级；行内编号用户编号同时为空；用户编号不为空但实际不存在。一切验证完毕后添加到list<br>4、在doAfterAll中处理，删除，则根据资产编号和用户Id，物理删除用户资产权限信息，返回message<br><br>/ast/asset/getMonthPubilshAsset<br>1、获取本月开始和结束的时间，查询本月的资产<br>2、设置响应头，设置文件名，写入文件<br><br>/sys/assetNoThemeLog/export<br>1、获取本月开始和结束时间，查询本月的Dap_asset_No_Theme_Log(用户勾选跳转魔术师，但没有分组的资产）<br>2、<br><br>/ast/assetVisit/exportVisitData<br>1、查询上个月的资产访问次数表，<br>2、设置响应头，设置文件名，写入文件<br><br><br>点击部门触发<br>sys/user/userList,就从用户表中查的数据，做了一下分页和其它操作，重点暂时应该不会在这儿·<br>1、使用TypeCastUtil.populate(targetEntity,sourceMap)将Map中的参数转换为实体类，将对象传入sql进行查询，获得所有该部门的用户<br>2、获取当前部门的父部门，拼接当前用户机构的层级结构<br>需要注意，点击部门后则无法通过再次点击取消选中状态（不取消则部门号一直都在，无法正常搜索用户），需要使用工具点击‘取消选择’才能继续使用<br><br>Controller不在userController中，而是在baseController中，<br>1、设置密码为默认密码，使用Md5加密后再用SHA加密，<br>2、设置用户的其他信息，比如错误登录次数设置为0，锁定状态设置为01，设置创建时间、创建人、更新时间，用户状态默认值为01<br>3、添加用户（允许属性为null）<br>在BaseService和BaseController中,在修改、添加和删除的前后都有before和after<br><br>Controller不在userController中，而是在baseController中，<br>1、获取原来的用户信息，保留原来的密码，<br>2、对所有字段进行修改（避免原来有数字，现在赋值为空）<br><br><br><br>sql过程，对角色表每条数据进行分析，如果存在用户角色表中角色id相同且用户Id等于传入用户id，则该角色就是用户关联的角色（同时要求角色状态为01）。<br><br>sql过程，对角色表每条数据进行分析，如果不存在用户角色表中角色id相同且用户Id等于传入用户id，则该角色就是用户关联的角色（同时要求角色状态为01）。<br><br>sys/branch/tree/list,（在jar包里，com.eds.hummer:hummer-branch-service-1.0.0-release）<br>查询所有机构状态码 = 01的机构<br>涉及到了树形组件，经过一遍分析，使用的是基于jquery的zTree组件，采用的不是全局注册或者局部使用方式，而是直接将zTree的图片样式等放入component/custom/tree中，直接调用的。<br>CZtree组件中，包含了工具（刷新全部、展开全部、收缩全部、取消选择）<br>经过分析认为部门转树是在前端实现的，但没找到在哪儿实现，已知请求应该是在CZtree中发送，在userMgr-&gt;_onInited()的nodes已经实现了转树（转树操作很可能与setting中的data的simpleData之类的有关系，疑点1('#ztree-1111-aaaa'),setting,this.data)）没有调用，且data.length=0 疑点2，this.$emit('on-inited',data,null,type),data.length=2077,但去调用的方法_onInited前已经转树完成<br><br><br><br><br><br><br><br><br><br><br><br><br>]]></description><link>教程\06.string.png.html</link><guid isPermaLink="false">教程/06.string.png.md</guid><pubDate>Tue, 21 Nov 2023 06:47:01 GMT</pubDate></item><item><title><![CDATA[Redis基础]]></title><description><![CDATA[ 
 <br><br><br>Redis（Remote Dictionary Server）是一个开源的中间件，可以作为数据库，缓存，消息中间件，流引擎。以key/value的形式存储数据，是一个内存型的中间件。key都是以String的形式存储，value值包含多种数据类型， <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/strings/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/strings/" target="_blank">strings</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/hashes/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/hashes/" target="_blank">hashes</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/lists/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/lists/" target="_blank">lists</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/sets/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/sets/" target="_blank">sets</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/sorted-sets/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/sorted-sets/" target="_blank">sorted sets</a> （zSet）with range queries, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/bitmaps/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/bitmaps/" target="_blank">bitmaps</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/hyperloglogs/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/hyperloglogs/" target="_blank">hyperloglogs</a>, <a data-tooltip-position="top" aria-label="https://redis.io/docs/data-types/geospatial/" rel="noopener nofollow" class="external-link" href="https://redis.io/docs/data-types/geospatial/" target="_blank">geospatial indexes</a>, 支持分布式存储，LUA脚本，提供缓存清除策略、事务和不同级别的持久化方式。<br>Redis也是NoSQL数据库的主要产品（redis，mongodb，memcache等）。redis的结构相对简单，操作大部分是原子操作。redis的key最大允许512M<br><br>基于内存：绝大部分的请求都是基于内存操作，快速。<br>单线程：Redis的操作都是单线程，可以避免上下文切换，多线程需要考虑锁，单线程不要，可以节省资源<br>使用多路复用I/O模型，非阻塞IO<br>数据结构相对比较简单<br><br>window的版本：<br>​	点击msi文件安装即可。<br>​	安装文件夹当中，redis-server.exe用来启动服务，redis-cli.exe启动客户端。<br><br><br>redis当中一共有16个数据库，序号是从0~15，默认是0号数据库，使用select  index切换数据库。<br><br><br>常规的key-value缓存应用<br>应用场合：验证码，访问流量<br>set  保存一个string类型的数值  set  key   value  ex  秒（px  毫秒）<br>get   获取一个值<br>del   删除一个key<br>incr  对应key的value（数值类型）增加1<br>incrby  设置key的value值每次增加一个数  incrby  key  5<br>decr  每次减少1<br>decrby  每次减少指定的值<br>strlen： 获取长度<br>append： 追加<br>exists：判断key是否存在，为0则不存在，1则存在<br>setnx：设置值，如果key存在，则不能设置，不存在则可以设置 <br>expire：全局操作，对所有key都起作用，设置key的有效事件<br><img style="zoom:50%;" alt="01.string操作" src="images\01.string操作.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="02.lists" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171310250.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="03.set操作" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171311456.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="05.sortedSet" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171311896.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="04.hash操作" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171311820.png" referrerpolicy="no-referrer"><br><br><img alt="06.bitmap" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171311836.png" referrerpolicy="no-referrer"><br><br>redis可以作为缓存，可以设置key存活的时间。string类型可以使用set命令设置时指定时间。<br><br>expire  秒<br>pexpire  毫秒<br><br>ttl ，pttl获取存活时间<br>ttl的单位是秒，pttl的单位是毫秒<br> -1  ：永久保存<br>正数： 存活的时间<br>-2：表示数据已经过期<br><br>将有限的存活时间变成了永久保存<br>重新设置值，不设置过期时间，会由短期存储变成长期存储<br><br>使用命令来设置密码<br>#服务器重新启动，则会无效
config set  requirepass 密码
config set  requirepass 123

#设置结束后不需要重新启动服务器，一旦启动就无效
auth  密码
<br>使用配置文件来进行处理<br>windows版本修改redis.windows.conf配置文件<br>linux版本:redis.conf<br>释放requirepass属性，并且设置密码<br>启动的时候带着配置文件启动<br><br>flushdb： 清空本数据库<br>flushall：清空所有数据库中的数据<br>del：删除指定的key<br>exists：判断某个key是否存在<br>move：将数据从原来的数据库移动到另外一个指定索引的数据  move  key  dbIndex。存在同样key的情况下会移动失败<br>keys:  用来查找符合条件的key值<br>​            keys  *  查找所有的key（当前的数据库）<br>​	'*' : 匹配0~n个字符<br> 	？匹配单个字符<br>​	[]: 匹配中间任意一个字符，可以使用中横线（-）指定范围<br>​	'\*':用于转义字符✳，如果匹配?，则使用?<br><br>Redis是一个内存型的数据库，当redis服务器重启的时候，数据就会丢失。redis提供持久化方式，将数据或者指令保存到磁盘的文件当中。持久化方式分成两种：RDB(默认)和AOF方式<br><br>RDB是默认的存储方式，采用快照的形式，在指定的时间间隔内将内存中的数据存储到文件中。实际操作时fork一个子进程，先将数据写入临时文件，写入成功后，再替换之前的文件，并且使用二进制进行压缩。在间隔期间，根据key的变化情况决定是否持久化数据。<br>#15分钟至少有一次数据变化
save 900 1
#5分钟内至少有10此数据变化
save 300 10
#1分钟内有10000次数据变化
save 60 10000
<br>特点：<br>​	优点：默认，文件压缩，方便恢复数据<br>​	缺点：容易丢失数据<br>弥补措施：调用bgsave或者save来进行手工存储<br>​	bgsave和save都会将内存中的数据保存到文件，成功时返回ok<br>​	save：在保存期间会阻塞用户的请求，服务器的性能消耗比较小<br>​	bgsave：不会阻塞用户的请求，服务器的压力比较大<br><br>AOF不是默认，需要手工开启。将redis的操作日志（指令）以追加的形式写入文件. 可以选择操作一条记录一条，也可以选择每秒钟持久化一次方式。如果选择每次操作都进行处理的话，对性能的影响比较大。<br>会将操作指令存到缓冲区，当缓冲区满了或者时间到了，一次性追到到持久化文件当中。当服务器重启的时候，会首先读取appendonly文件。<br>#默认不启用aof持久化方式，想要开启，将no变成yes
appendonly no

#默认的持久化文件名
appendfilename "appendonly.aof"

#每一次操作都执行持久化处理
# appendfsync always
#每秒钟执行一次持久化处理
appendfsync everysec
#不进行持久化
# appendfsync no
<br>特点：<br>​	优点： 基本不会丢数据<br>​	缺点： 持久化的频率较高，会影响性能，由于会产生多个文件，对于数据的恢复没有rdb方式效率高。<br><br>redis的事务，开始事务后，将所有的指令入队，调用exec提交事务，一起执行。取消事务使用discard指令。<br>如果中间出现执行错误，并不会直接取消，当前这条出错，后续会继续执行。<br>如果指令是错误的，则会取消事务。<br>multi：开启redis的事务<br>exec：提交事务<br>discard：取消事务<br>watch：监听某个key，如果有操作，类似于版本号+1，事务中如果版本号被修改，则事务无法提交。<br>unwatch<br><br><br>Redis是内存数据，当占用的内存超出最大限制（maxmemory），需要使用淘汰策略，让redis淘汰掉一些数据，留给后续的数据写操作，或者进行异常处理。<br>#从设置过期时间的这些key当中查找最近最少使用的，淘汰掉
# volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.
#从设置过期时间的这些key当中查找，淘汰掉一段时间内，使用最少的
# volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.
# 从设置过期时间的这些key当中，随机淘汰掉
# volatile-random -&gt; Remove a random key among the ones with an expire set.
# 从设置过期时间的这些key当中，最快过期的数据淘汰掉
# volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)
#从所有key当中，查找最近最少使用的，淘汰掉
# allkeys-lru -&gt; Evict any key using approximated LRU.
#从所有key当中，淘汰掉一段时间内，使用最少的
# allkeys-lfu -&gt; Evict any key using approximated LFU.
#从所有key当中，随机淘汰掉
# allkeys-random -&gt; Remove a random key, any key.
#不进行处理，直接抛出error（默认值）
# noeviction -&gt; Don't evict anything, just return an error on write operations.
<br><br>定时删除：<br>​	当key设置一个过期时间，同时设置一个创建一个定时器，当时间到达的时候，由定时器立刻执行删除操作。<br>​	优点：节省内存，立刻删除，基本没有废数据<br>​	缺点：CPU的压力比较大，放了很多定时器后。<br>惰性删除：<br>​	数据到了过期时间后，并不删除，不做任何处理。等到下次访问时<br>​		数据过期：删除并返回不存在<br>​		未过期：返回数据<br>​	优点：节省CPU<br>​	缺点：占用内存，必须下次访问才可能被删除<br>定期删除：<br>​	周期性轮询redis库中数据的时效性，采用随机抽查的策略，利用过期数据的占比来控制删除的频率。<br><br><br>用于使用一个不存在的key频繁访问缓存和数据库，由于此key的数据既不在缓存当中，也不在数据库当中，请求--》缓存--缓存失败--》数据库--查询失败。当高并发或者有人恶意攻击的时候，就将所有的压力都交给数据库服务器，由可能导致数据库崩溃。整个系统都挂了。<br>发生的场景<br>1：数据原来是存在的，由于某些原因（程序员的问题，误删除，淘汰机制），缓存和数据库当中的数据已经删除，前置的应用程序当中还有。<br>2：恶意攻击<br>如何解决<br>缓存空值：分析业务，如果是正常业务发生缓存穿透问题的话，可以将对应key/value（null）缓存到redis当中，设置较短的过期时间。如果是恶意攻击，此策略不行，缓存大量的空值，导致缓存服务器空间不足。<br>业务逻辑前置校验：在业务请求的入口，根据业务规则，进行数据的合法性校验。提前阻止非法请求。<br>布隆过滤器：对于入口的查询参数，以hash的形式存储，hash方法是多种，在控制层进行校验，不符合的则丢弃。<br>​	<br><br>缓存雪崩：在某一个时间段，缓存集中过期，比如双十一，双十二，六一八，产生一批缓存集中过期的状况。在某个时点上，高并发访问，会将压力都转移给传统的数据。也有可能是缓存服务器宕机或者断网，导致查询的压力都集中到传统数据库上。<br>发生的场景<br>1：大量的热点key过期<br>2：缓存服务器故障<br>3：系统上线，缓存服务器没有数据<br>如何解决<br>给每项数据设置一些随机的过期时间，让过期时间均匀分布。<br>热点数据不过期，通过后端异步更新缓存。（使用缓存和数据库不要求严格一致的场景）<br>redis集群（针对缓存故障的情况）<br>当发生雪崩的时候，进行服务的限流（控制并发量），服务的熔断和降级处理<br>当正式部署的时候，由于缓存服务器没有数据，也可能导致雪崩。采用数据预热的方式，将一部分数据通过程序刷入缓存服务器。<br><br>高并发集中对某一个key的数据访问，某个时点key突然失效了，持续的高并发穿破缓存服务器，直击传统数据库。瞬间可能压垮传统数据库。<br>1）设置热点数据不过期<br>2）用队列限流<br>3）使用分布式锁<br>查：如何解决redis和传统数据库的数据一致性问题<br><br>知识点：Jedis连接池，CountDownLatch<br><br><br>主从（master-slave）<br>哨兵机制（Sentinel）<br>集群(cluster)<br>主从<br>主从：实现读写分离，主服务器主要用来进行写操作，从服务器进行读操作，从服务器不能进行读写操作。<br>当主服务器挂了以后，可以通过指令将从服务器变成主服务器<br>先开启服务器，默认端口为6379<br>再使用下述命令，开启6380服务器，并作为6379的从服务器<br>redis-server --port 6380 --slaveof 127.0.0.1 6379

#关掉主服务器，从服务器翻身做主人
#从服务器的客户端
slaveof no one

<br>哨兵机制<br>主从方式需要人工干预，无法直接从从机变成主机，也不能进行任何故障转移。<br>哨兵不做任何的业务处理，只是用来管理整个主从服务器集群。哨兵的节点一般要求奇数台，最少三台机器<br>哨兵的作用：<br>监控：Sentinel会不断检查主服务器和从服务器是否正常工作。<br>通知：当某一个redis节点出现问题后，sentinel会发送通知给系统管理员或者其他计算机程序<br>自动故障转移：当主服务器出现故障后，sentinel会从从服务器当中，选举（多数通过原则）一个从机，并且升级成主机，并且告知其他的从服务器，主服务器已经发生变更。<br>配置提供者：sentinel充当客户端服务发现的来源。当sentinel接收到客户端请求的时候，会提供主服务器的地址，如果发生故障转移，sentinel会报告新地址。]]></description><link>教程\7、Redis基础.html</link><guid isPermaLink="false">教程/7、Redis基础.md</guid><pubDate>Fri, 18 Aug 2023 04:56:29 GMT</pubDate><enclosure url="images\01.string操作.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="images\01.string操作.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[权限管理]]></title><description><![CDATA[ 
 <br><br><br>基本上所有的系统当中都会涉及到权限的管理（数据的安全问题），需要对访问系统的主体（用户，系统，机器）进行认证和授权。每个相关主体只能访问被授权的资源。<br>权限管理系统：<br>​	主体认证--确定是系统的合法用户<br>​	授权： 使得用户能够匹配和访问到相应的资源<br><br>用户名/密码<br>指纹刷卡机（刷脸）<br>动态验证码<br>硬件刷卡系统<br><br>基于角色<br>基于资源<br>基于权限对象<br><br>用户表<br>角色表<br>角色用户表<br>权限表<br>角色权限表<br><br><br>shiro是apache旗下的开源项目，将系统当中安全认证流程抽取出来，开发成一个中间件，实现用户认证，授权，加密以及会话管理等，组成一个通用的安全框架。<br>Shiro可以用在web项目，也可以用在非web项目，可以单独运行，也可以整合spring，springboot等。<br>SSM + Shiro<br>Springboot + Spring security<br><img alt="shiro" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171308938.jpg" referrerpolicy="no-referrer"><br>Subject：主体，外部应用程序都是通过和Subject进行交互，类似于用户的概念，可能是通过浏览器发送请求的用户，也可能是一个运行的程序。是shiro的核心接口，定义了很多认证的方法，核心就是login<br>Security Manager：安全管理器，是shiro的核心部分，对Subject进行认证，授权以及会话管理。<br>Authenticator：认证器，主要是用于对用户主体身份进行认证的。ModularRealmAuthenticator基本上可以实现大部分的功能，也可以自定义认证器。<br>Authorizer：授权器，用户可以通过认证后，可以获取授权信息，访问相关资源时，shiro会确认是否有相应的权限。<br>SessionManager和SessionDao：用来管理用户会话的<br>Realm：领域，类似于数组源，用户如何认证以及如何授权的资源信息都Realm当中<br><br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;
    &lt;artifactId&gt;shiro-core&lt;/artifactId&gt;
    &lt;version&gt;1.8.0&lt;/version&gt;
&lt;/dependency&gt;
<br><br>[users]
zhangsan=123
xiaoming=111
<br><br>public class Sample01 {
    public static void main(String[] args) {
        String file = "classpath:shiro.ini";
        //subject.login==&gt;SecurityManager==&gt;Authenticator=&gt;realm
        IniRealm iniRealm = new IniRealm(file);
        SecurityManager defaultSecurityManager = new DefaultSecurityManager(iniRealm);
        SecurityUtils.setSecurityManager(defaultSecurityManager);

        Subject subject = SecurityUtils.getSubject();

        UsernamePasswordToken token = new UsernamePasswordToken("zhangsan111","123");
        try{
            subject.login(token);
        } catch (AuthenticationException ex) {

        }

        System.out.println(subject.isAuthenticated());

    }
}
<br><br>定义一个server模仿查询数据库，并在realm中进行调用<br><br>@Data
@NoArgsConstructor
@AllArgsConstructor
public class MockUser {
    String id;
    String username;
    String password;

}
<br><br>public class MockService {
    public static Map&lt;String,MockUser&gt; map = new HashMap&lt;&gt;();

    static {
        map.put("1001",new MockUser("1001","admin1","111"));
        map.put("1002",new MockUser("1002","admin2","122"));
        map.put("1003",new MockUser("1003","admim3","333"));
        map.put("1004",new MockUser("1004","admin4","444"));
        map.put("1005",new MockUser("1005","admin5","666"));
        map.put("1006",new MockUser("1006","admin6","777"));
        map.put("1007",new MockUser("1007","admin7","999"));
    }

    public MockUser findUser(String id) {
        return map.get(id);
    }


}

<br><br>public class MyRealm extends AuthorizingRealm {

    MockService mockService = new MockService();

    MockRole mockRole = new MockRole();

    /**
     * 处理授权（获取授权信息）
     * @param principals
     * @return
     */
    @Override
    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {
        return null
    }

    /**
     * 获取用户相关信息(认证信息)
     * @param token
     * @return
     * @throws AuthenticationException
     */
    @Override
    protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {
        //通过token可以获取用户id，也可以获取用户输入的密码（未加密）
        String id = (String)token.getPrincipal();
        //根据用户id到数据库查询用户信息
        MockUser user = mockService.findUser(id);
        if (user==null) {
            //throw new UnknownAccountException();
            return  null;
        }
        //获取数据库当中密码
        String password = user.getPassword();
        //创建AuthenticationInfo对象
        return new SimpleAuthenticationInfo(user,password,"myRealm");
    }
}
<br><br>public static void main(String[] args) {
        String file = "classpath:shiro.ini";
        //subject.login==&gt;SecurityManager==&gt;Authenticator=&gt;realm
        MyRealm myRealm = new MyRealm();
        SecurityManager defaultSecurityManager = new DefaultSecurityManager(myRealm);
        SecurityUtils.setSecurityManager(defaultSecurityManager);

        Subject subject = SecurityUtils.getSubject();

        UsernamePasswordToken token = new UsernamePasswordToken("1002","122");
        try{
            subject.login(token);
        } catch (AuthenticationException ex) {
            ex.printStackTrace();
        }

        System.out.println(subject.isAuthenticated());

    }
<br><br>定义mockRoleService模拟数据库获取角色信息<br><br>public class MockRoleService {
    public static Map&lt;String, List&lt;String&gt;&gt; roles = new HashMap&lt;&gt;();
    static  {
        List&lt;String&gt; list = new ArrayList&lt;&gt;();
        list.add("admin");
        list.add("market");
        roles.put("1001",list);

        list = new ArrayList&lt;&gt;();
        list.add("hr");
        roles.put("1002",list);
    }

    public List&lt;String&gt; findRoles(String id) {
        return roles.get(id);
    }
}
<br><br>@Override
    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {
        MockUser user = (MockUser)principals.getPrimaryPrincipal();
        //到数据库获取角色或者权限信息
        List&lt;String&gt; roles = mockRole.findRoles(user.getId());

        SimpleAuthorizationInfo  info = new SimpleAuthorizationInfo();
        //获取用户的角色以及授权信息
        if ( roles !=null &amp;&amp; roles.size()&gt;0) {
            info.setRoles(roles.stream().collect(Collectors.toSet()));
        }

        //假账
        if ("1001".equals(user.getId())) {
            info.addStringPermission("user::add");
            info.addStringPermission("user::del");
        } else {
            info.addStringPermission("user::review");
        }

        return info;
    }
<br><br> public static void main(String[] args) {
        String file = "classpath:shiro.ini";
        //subject.login==&gt;SecurityManager==&gt;Authenticator=&gt;realm
        MyRealm myRealm = new MyRealm();
        SecurityManager defaultSecurityManager = new DefaultSecurityManager(myRealm);
        SecurityUtils.setSecurityManager(defaultSecurityManager);

        Subject subject = SecurityUtils.getSubject();

        UsernamePasswordToken token = new UsernamePasswordToken("1002","122");
        try{
            subject.login(token);
        } catch (AuthenticationException ex) {
            ex.printStackTrace();
        }

        System.out.println(subject.isAuthenticated());

        System.out.println("=====");

		//测试授权信息
        System.out.println(subject.hasRole("admin"));
        System.out.println(subject.isPermitted("user::review"));
        //subject.logout();
        //System.out.println(subject.isAuthenticated());

    }
<br><br>@Test
    public void test(){
        String origin = "111";
        String s1 = new Md5Hash(origin,null,1).toHex();
        System.out.println(s1);

        String s2 = new Md5Hash(origin,null,2).toHex();
        System.out.println(s2);
    }
<br><br><br>创建maven项目，并增加webapp相关信息，将pom中增加war<br>并增加springmvc相关依赖和配置<br><br>&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework&lt;/groupId&gt;
            &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt;
            &lt;version&gt;5.3.18&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
            &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;
            &lt;version&gt;3.1.0&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt;
            &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt;
            &lt;version&gt;1.8.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;version&gt;1.18.16&lt;/version&gt;
            &lt;scope&gt;compile&lt;/scope&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;
<br><br>public class MyRealm extends AuthorizingRealm {

    MockService mockService = new MockService();

    MockRoleService mockRole = new MockRoleService();

    /**
     * 处理授权（获取授权信息）
     * @param principals
     * @return
     */
    @Override
    protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) {
        MockUser user = (MockUser)principals.getPrimaryPrincipal();
        //到数据库获取角色或者权限信息
        List&lt;String&gt; roles = mockRole.findRoles(user.getId());

        SimpleAuthorizationInfo  info = new SimpleAuthorizationInfo();
        //获取用户的角色以及授权信息
        if ( roles !=null &amp;&amp; roles.size()&gt;0) {
            info.setRoles(roles.stream().collect(Collectors.toSet()));
        }

        //假账
        if ("1001".equals(user.getId())) {
            info.addStringPermission("user::add");
            info.addStringPermission("user::del");
        } else {
            info.addStringPermission("user::review");
        }

        return info;
    }

    /**
     * 获取用户相关信息(认证信息)
     * @param token
     * @return
     * @throws AuthenticationException
     */
    @Override
    protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException {
        //通过token可以获取用户id，也可以获取用户输入的密码（未加密）
        String id = (String)token.getPrincipal();
        //根据用户id到数据库查询用户信息
        MockUser user = mockService.findUser(id);
        if (user==null) {
            //throw new UnknownAccountException();
            return  null;
        }
        //获取数据库当中密码
        String password = user.getPassword();
        //创建AuthenticationInfo对象
        return new SimpleAuthenticationInfo(user,password,"myRealm");
    }
}
<br><br>&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd"
         version="3.1" metadata-complete="true"&gt;
    &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt;
    
    &lt;servlet&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt;
            &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;
        &lt;/init-param&gt;
        &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;
    &lt;/servlet&gt;
    &lt;servlet-mapping&gt;
        &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt;
        &lt;url-pattern&gt;*.do&lt;/url-pattern&gt;
    &lt;/servlet-mapping&gt;

    &lt;filter&gt;
        &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt;
        &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;
&lt;!--        将shiro的过滤器的生命周期交给容器管理--&gt;
        &lt;init-param&gt;
            &lt;param-name&gt;targetFilterLifecycle&lt;/param-name&gt;
            &lt;param-value&gt;true&lt;/param-value&gt;
        &lt;/init-param&gt;
    &lt;/filter&gt;
    &lt;filter-mapping&gt;
        &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt;
        &lt;url-pattern&gt;/*&lt;/url-pattern&gt;
    &lt;/filter-mapping&gt;
&lt;/web-app&gt;
<br><br>&lt;bean id="myRealm" class="net.wanho.shiro.MyRealm"&gt;&lt;/bean&gt;
    &lt;!--    securityManager--&gt;
    &lt;bean id="securityManager" class="org.apache.shiro.web.mgt.DefaultWebSecurityManager"&gt;
        &lt;property name="realm" ref="myRealm"/&gt;
    &lt;/bean&gt;

    &lt;!--    shiroFilter--&gt;
    &lt;bean id="shiroFilter" class="org.apache.shiro.spring.web.ShiroFilterFactoryBean"&gt;
        &lt;property name="securityManager" ref="securityManager"/&gt;
        &lt;!--        如果没有认证想要访问部分限制资源的话，强制跳回到指定的url--&gt;
        &lt;property name="loginUrl" value="/index.jsp"/&gt;
        &lt;!--        当用户没有对应的权限（premission和roles），会跳转到指定value的请求url--&gt;
        &lt;property name="unauthorizedUrl" value="/refuse.jsp"/&gt;
        &lt;property name="filterChainDefinitions"&gt;
            &lt;value&gt;
                /index.jsp=anon
                /refuse.jsp=anon
                /success.jsp=authc
                /admin.jsp=roles[admin]
                /hr.jsp=roles[hr]
            &lt;/value&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
<br><br>index，refuse，success，admin以及hr等页面<br><br>配置密码加密器，并设置到realm当中<br>&lt;bean id="hashedCredentialsMatcher" class="org.apache.shiro.authc.credential.HashedCredentialsMatcher"&gt;
&lt;!--       true:16进制转换，false：base编码--&gt;
        &lt;property name="storedCredentialsHexEncoded" value="true"/&gt;
        &lt;property name="hashAlgorithmName" value="md5"/&gt;
        &lt;property name="hashIterations" value="1"/&gt;
    &lt;/bean&gt;
&lt;!--    自定义realm--&gt;
    &lt;bean id="myRealm" class="net.wanho.shiro.MyRealm"&gt;
            &lt;property name="credentialsMatcher" ref="hashedCredentialsMatcher"/&gt;
    &lt;/bean&gt;
<br><br><br>public class MyFilter implements Filter {

    String filterName;



    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        System.out.println("myFilter is working,name=" + this.filterName);
        filterChain.doFilter(servletRequest,servletResponse);
    }

    @Override
    public void init(FilterConfig filterConfig) throws ServletException {

    }

    @Override
    public void destroy() {

    }

    public String getFilterName() {
        return filterName;
    }

    public void setFilterName(String filterName) {
        this.filterName = filterName;
    }
}
<br><br>&lt;bean id="myFilter" class="net.wanho.filters.MyFilter"&gt;
        &lt;property name="filterName" value="test Filter"/&gt;
    &lt;/bean&gt;
<br><br>&lt;bean id="shiroFilter" class="org.apache.shiro.spring.web.ShiroFilterFactoryBean"&gt;
        &lt;property name="securityManager" ref="securityManager"/&gt;
        &lt;!--        如果没有认证想要访问部分限制资源的话，强制跳回到指定的url--&gt;
        &lt;property name="loginUrl" value="/index.jsp"/&gt;
        &lt;!--        当用户没有对应的权限（premission和roles），会跳转到指定value的请求url--&gt;
        &lt;property name="unauthorizedUrl" value="/refuse.jsp"/&gt;
        &lt;property name="filterChainDefinitions"&gt;
            &lt;value&gt;
                /index.jsp=anon
                /refuse.jsp=anon
                /success.jsp=authc
                /admin.jsp=roles[admin]
                /hr.jsp=roles[hr]
                /filter.jsp=authc,myFilter
                &lt;!--                /**=authc--&gt;
            &lt;/value&gt;
        &lt;/property&gt;
    &lt;/bean&gt;
<br><br>&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;
&lt;%@ taglib prefix="shiro" uri="http://shiro.apache.org/tags" %&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;Title&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

    &lt;shiro:guest&gt;
    欢迎访问，请&lt;a href="index.jsp"&gt;登录&lt;/a&gt;系统
    &lt;/shiro:guest&gt;

    &lt;shiro:authenticated&gt;
        欢迎xxx登录系统
    &lt;/shiro:authenticated&gt;


    &lt;shiro:hasRole name="admin"&gt;
        &lt;button&gt;admin&lt;/button&gt;
    &lt;/shiro:hasRole&gt;

    &lt;shiro:hasPermission name="user::add"&gt;
        &lt;button&gt;增加&lt;/button&gt;
    &lt;/shiro:hasPermission&gt;
    &lt;shiro:hasPermission name="user::del"&gt;
        &lt;button&gt;删除&lt;/button&gt;
    &lt;/shiro:hasPermission&gt;
    
    

    &lt;shiro:hasPermission name="user::review"&gt;
        &lt;button&gt;详情&lt;/button&gt;
    &lt;/shiro:hasPermission&gt;


&lt;/body&gt;
&lt;/html&gt;

]]></description><link>教程\8、shiro.html</link><guid isPermaLink="false">教程/8、shiro.md</guid><pubDate>Thu, 17 Aug 2023 05:08:49 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171308938.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171308938.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[项目环境搭建]]></title><description><![CDATA[ 
 <br><br><br>解压后直接smart-java导入工程<br>※ 修改maven路径<br><br>在终端适用 npm  install 安装对应js库<br>适用npm  run dev 启动程序<br>端口号配置：vue.config.js文件中<br>排除ELINT检测：vue.config.js<br> //lintOnSave: process.env.NODE_ENV === 'development',
    lintOnSave: false,
<br><br>.env.development==&gt;开发环境<br>.env.production==&gt;产品环境<br>.env.staging ==&gt;测试环境<br>Sa
Asd<br><br>根据分析：<br>后端返回的json数据中需要包含：code，msg，data(key-token)<br><br><br># just a flag
ENV = 'development'

# base api
#VUE_APP_BASE_API = '/dev-api'
# update by mamp
#VUE_APP_BASE_API是后端服务器的host地址，如果项目是有上下文，请加上上下文信息  #http://localhost:8080/smart-java
VUE_APP_BASE_API = 'http://localhost:8080'
<br><br>import request from '@/utils/request'

export function login(data) {
  return request({
    // url: '/vue-admin-template/user/login',
     url:'/common/login',
    method: 'post',
    data
  })
}

export function getInfo(token) {
  return request({
    // url: '/vue-admin-template/user/info',
     url:'common/info',
    method: 'get',
    params: { token }
  })
}

export function getCodeImg(){
  return request({
    url:'common/captchaImage',
    method: 'get',
  })
}

export function logout() {
  return request({
    // url: '/vue-admin-template/user/logout',
    url:'common/logout',
    method: 'post'
  })
}

<br><br>   if (res.code !== 20000 &amp;&amp; res.code != 200 ) {
      Message({
        message: res.msg || 'Error',
        type: 'error',
        duration: 5 * 1000
      })
<br><br><br>package net.wanho.common.core.domain;



import org.springframework.http.HttpStatus;
import org.springframework.util.ObjectUtils;

import java.util.HashMap;
import java.util.Map;

/**
 * 操作消息提醒
 * 
 * @author ruoyi
 */
public class AjaxResult
{
    int code;
    String msg;
    Map&lt;String,Object&gt; data;
    /**
     * 初始化一个新创建的 AjaxResult 对象，使其表示一个空消息。
     */
    private AjaxResult()
    {
    }

    /**
     * 返回成功消息
     * 
     * @return 成功消息
     */
    public static AjaxResult success()
    {
        return AjaxResult.success("操作成功");
    }
    /**
     * 返回成功数据
     * 
     * @return 成功消息
     */
    public static AjaxResult success(String  message)
    {
        return AjaxResult.success(200,"操作成功");
    }


    public static AjaxResult success(int code,String  message)
    {
        AjaxResult ajaxResult = new AjaxResult();
        ajaxResult.code = code;
        ajaxResult.msg = message;
        return ajaxResult;
    }



    /**
     * 返回错误消息
     * 
     * @return
     */
    public static AjaxResult error()
    {
        return AjaxResult.error("操作失败");
    }

    /**
     * 返回错误消息
     * 
     * @param msg 返回内容
     * @return 警告消息
     */
    public static AjaxResult error(String msg)
    {

        return AjaxResult.error(500, msg);
    }

    /**
     * 返回错误消息
     *
     * @return 警告消息
     */
    public static AjaxResult error(int code,String message)
    {
        AjaxResult ajaxResult = new AjaxResult();
        ajaxResult.code = code;
        ajaxResult.msg = message;
        return ajaxResult;
    }


    /**
     * 方便链式调用
     *
     * @param key 键
     * @param value 值
     * @return 数据对象
     */
    public AjaxResult put(String key, Object value)
    {
        if (ObjectUtils.isEmpty(this.data) ){
            this.data = new HashMap&lt;&gt;();
        }
        this.data.put(key, value);
        return this;
    }

    public int getCode() {
        return code;
    }

    public void setCode(int code) {
        this.code = code;
    }

    public String getMsg() {
        return msg;
    }

    public void setMsg(String msg) {
        this.msg = msg;
    }

    public Map&lt;String, Object&gt; getData() {
        return data;
    }

    public void setData(Map&lt;String, Object&gt; data) {
        this.data = data;
    }
}

<br><br>@RestController
@RequestMapping("common")
@CrossOrigin
public class LoginController {


    @PostMapping("login")
    public AjaxResult doLogin(LoginBody  loginBody){
        AjaxResult ajaxResult = AjaxResult.success().put("token","admin");
        return ajaxResult;
    }


    @GetMapping("info")
    public AjaxResult getInfo(String  token){

        AjaxResult ajaxResult = AjaxResult.success()
                    .put("name","admin")
                    .put("avatar","form");
        return ajaxResult;
    }

}
<br><br><br>请求的URL   '/system/dict/type/list',<br>  method: 'get',<br>  params: query<br><br><br><br><br>字典类型的id<br><br><br>查询数据，excel ，下载<br>前后端不分离的情况下，适用a元素，直接点击就可以下载<br>前后端分离的情况下，不能直接适用ajax，可以做一个假的的a元素，让其href指向下载的路径<br><br>验证码涉及的流程：<br>​	用户一旦进入登录页面，就要获取验证码<br>​	验证码一般可以刷新（点击相关的验证码图片<br>​	用户登录的时候，带着用户名，密码，以及验证码进行登录，登录失败的时候，还需要刷新验证码<br>适用工具：hutool工具包，redis<br>  创建验证码---》写入redis--》带入验证码，<br>​	验证码是否输入<br>​	验证码是否和redis当中的相同（redis是有的，值是否相等，另外是过期了）<br>依赖<br>  hutool，spring-data-redis,  jedis<br>获取验证码<br>登录验证<br><br>由于调用的方法众多，散落在各个Controller，考虑AOP技术<br>由于操作类型比较多，无数的package以及方法上都可能需要适用，可以考虑Annotation指示器（切点指示器），自定义注解@OpertationLog<br>由于正常结束和异常结束都需要写日志，考虑环绕通知，和正常结束和异常结束，由于考虑到事务问题，采用正常结束和异常结束<br>定义BusinessType类型枚举<br>定义操作类型<br>定义注解@OpertationLog<br>IP地址转换器<br>写AOP<br>多线程<br>淘宝<br><a rel="noopener nofollow" class="external-link" href="https://ip.taobao.com/outGetIpInfo?ip=58.49.198.195&amp;accessKey=alibaba-inc" target="_blank">https://ip.taobao.com/outGetIpInfo?ip=58.49.198.195&amp;accessKey=alibaba-inc</a><br>太平洋<br><a rel="noopener nofollow" class="external-link" href="https://whois.pconline.com.cn/ipJson.jsp?ip=127.0.0.1&amp;json=true" target="_blank">https://whois.pconline.com.cn/ipJson.jsp?ip=127.0.0.1&amp;json=true</a><br>ApplicationContextAware接口<br>凡是实现了此接口的类，加载的时候，Spring容器会自动注入ApplicationContext<br>项目启动时，刷数据进缓存<br>ApplicatonListener<br>service，读取所有的字典数据，将字典数据写入缓存<br><br>JSON Web Token：基于JSON网络传输令牌。无状态的信息。最终生成一个base64URL编码的字符串<br>xxx.yyy.zzz<br><br>Header（头部）： alg：算法，typ：指定jwt还是jws分类<br>payload（载荷）：<br>​	 iss ：发行者<br>​	 exp：有效时间<br>​	 sub：主体，JWT面向的用户 <br>​	 aud：受众，接收JWT的一方<br>​	iat： 签发时间，一般情况下，会用当前时间作为签发时间<br>​	生效时间：在什么时候开始生效<br>Signature（签名）<br>​	对header和payload部分进行编码<br>​	私钥<br><br><br><br>shiro-spring，redis，spring-data-redis，jjwt<br><br><br>web.xml<br>编写mapper<br>定义realm<br>spring-shiro配置<br>重新修改LoginConroller<br><br><br>]]></description><link>教程\9、项目文档.html</link><guid isPermaLink="false">教程/9、项目文档.md</guid><pubDate>Fri, 24 Nov 2023 08:46:02 GMT</pubDate></item><item><title><![CDATA[09.设置公钥01.setting.png]]></title><description><![CDATA[ 
 ]]></description><link>教程\09.设置公钥01.setting.png.html</link><guid isPermaLink="false">教程/09.设置公钥01.setting.png.md</guid><pubDate>Tue, 21 Nov 2023 08:13:12 GMT</pubDate></item><item><title><![CDATA[线程池]]></title><description><![CDATA[ 
 <br><br>高并发项目当中，可能会频繁地创建和销毁线程，对象都是放在堆内存当中的，gc会消耗系统的资源。<br>STW(stop the world)，频繁的gc会影响到用户体验。可以使用线程池，根据实际的业务分析，可以预先创建好一部分线程对象放入池中，有任务来的时候，就使用池子当中空闲的线程来执行任务，如果池子当中所有的线程都有任务在执行，可以选择创建一定量的线程，或者放入队列当中，等到池子中的线程空闲后进行处理。<br>java当中提供四个标准的线程池，阿里的code检查会提示不建议使用。<br><br>特点：线程池当中只有一个线程在干活，所有的后续都需要放到队列<br>​             适合于先到先处理有顺序需求的业务<br>public static void main(String[] args) {
        //单一线程池，池子当中只有一个线程

        /*
         * new ThreadPoolExecutor(1, 1,  0L, TimeUnit.MILLISECONDS,
         *                                     new LinkedBlockingQueue&lt;Runnable&gt;())
         * 核心线程池数：1
         * 最大线程池数：1
         * 线程一直放在池当中，不会被移出
         * LinkedBlockingQueue：无界队列
         */
        ExecutorService executorService = Executors.newSingleThreadExecutor();

        for(int i=1;i&lt;=5;i++) {
            executorService.execute(
                    ()-&gt; System.out.println(Thread.currentThread().getName() + "正在处理任务")
            );
        }

    }
<br><br>线程的数量是固定的，执行顺序不定<br>适用于：正常的平峰的业务，有一定的并发量，相对来说比较稳定<br>/**
         * 创建一定数量的线程，放入池子当中
         * 如果所有线程都在忙的话，则放入队列
         * ThreadPoolExecutor(nThreads, nThreads,
         *                                       0L, TimeUnit.MILLISECONDS,
         *                                       new LinkedBlockingQueue&lt;Runnable&gt;())
         */
        ExecutorService executorService = Executors.newFixedThreadPool(3);

        for(int i=1;i&lt;=50;i++) {
            final  int a = i;
            executorService.execute(
                    ()-&gt; System.out.println(Thread.currentThread().getName() + "正在处理任务" + a)
                
            );
        }

<br><br>创建线程池的时候，并不创建任何线程，不限制线程的数据，但是线程如果空闲1分钟，则从池子当中移除。<br>适用：短时瞬间高峰业务<br>public static void main(String[] args) {


        /**
         * SynchronousQueue:类似于空集合，不保存任何数据,请求过来以后，直接提交给线程池
         *
         * new ThreadPoolExecutor(0, Integer.MAX_VALUE,
         *                                       60L, TimeUnit.SECONDS,
         *                                       new SynchronousQueue&lt;Runnable&gt;());
         */
        ExecutorService executorService = Executors.newCachedThreadPool();

        for(int i=1;i&lt;=50;i++) {
            final  int a = i;
            executorService.execute(
                    ()-&gt; System.out.println(Thread.currentThread().getName() + "正在处理任务" + a)
            );
        }



    }
<br><br>某一个任务需要按照指定的频率或者延迟固定的时间后执行，这一类任务称为定时任务。<br>可以适用定时线程池进行完成<br> public static void main(String[] args) {


        /**
         * SynchronousQueue:类似于空集合，不保存任何数据,请求过来以后，直接提交给线程池
         *
         * new ThreadPoolExecutor(0, Integer.MAX_VALUE,
         *                                       60L, TimeUnit.SECONDS,
         *                                       new SynchronousQueue&lt;Runnable&gt;());
         */
        ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);

        //按照固定的频率进行任务处理，当前任务的启动到下一次任务的启动时间为固定的频率，不考虑任务执行多久
        //executorService.scheduleAtFixedRate(()-&gt; System.out.println(Thread.currentThread().getName() + "正在执行"),
        //                    3,2, TimeUnit.SECONDS);

        //当前任务的执行结束后，到下一次任务开始前的时间是固定的
        //executorService.scheduleWithFixedDelay(()-&gt; {
        //                System.out.println(Thread.currentThread().getName() + "正在执行 " + LocalDateTime.now()) ;
        //            try {
        //                Thread.sleep(1000);
        //            } catch (InterruptedException e) {
        //                e.printStackTrace();
        //            }
        //        },
        //        3,2, TimeUnit.SECONDS);

        //不会多次执行，但是可以设置延迟
        executorService.schedule(()-&gt; {
                                    System.out.println(Thread.currentThread().getName() + "正在执行 " + LocalDateTime.now()) ;
                                    try {
                                        Thread.sleep(1000);
                                    } catch (InterruptedException e) {
                                        e.printStackTrace();
                                    }
                                },2,TimeUnit.SECONDS);

    }
<br><br> public static void main(String[] args) {

        //int corePoolSize :核心线程数量，线程池启动的时候，会创建核心线程
        //int maximumPoolSize： 最大线程数据(包含核心线程数量)
        //long keepAliveTime：存活时间（空闲多久后会被移出池子）
        //TimeUnit unit, 时间单元
        //BlockingQueue&lt;Runnable&gt; workQueue 阻塞队列
        //  SynchronousQueue ，将任务交给线程，无需另外控制,队列类似于空集合
        //  ArrayBlockingQueue ：有界队列，指定有限的容量
        //     当 有新请求过来时，先确认核心线程是否有空闲，如果有，则直接执行任务
        //     如果没有，则判断队列是否满，未满放入队列，
        //      满了则判断是否达到最大线程数，未到创建线程执行任务，到了则执行拒绝策略
        //  LinkedBlockingQueue： 无界队列,队列的长度足够长，能否放入足够多的对象，
        //          基本满足系统对并发数据量的需求，最大线程数基本上不起效
        //ThreadFactory threadFactory：创建线程工厂
        //RejectedExecutionHandler 拒绝策略，java提供了四种拒绝策略
        //  AbortPolicy： （默认）不处理，抛出异常
        //  DiscardPolicy: 抛弃新请求
        //  DiscardOldestPolicy: 最早入队，还是还未被处理的请求，被抛弃
        //  CallerRunsPolicy: 交给线程的调用者
        //  可以根据业务规则，自定义拒绝策略，实现RejectedExecutionHandler接口

        ThreadPoolExecutor executor = new ThreadPoolExecutor(3, 5
                , 0L, TimeUnit.SECONDS
                , new ArrayBlockingQueue&lt;&gt;(5)
                , Executors.defaultThreadFactory()
                , new ThreadPoolExecutor.CallerRunsPolicy());

        for(int i=0;i&lt;=50;i++) {
            int a = i;
            executor.execute(()-&gt; System.out.println(Thread.currentThread().getName() + a) );
        }

    }
]]></description><link>教程\10、线程池.html</link><guid isPermaLink="false">教程/10、线程池.md</guid><pubDate>Thu, 10 Aug 2023 01:37:15 GMT</pubDate></item><item><title><![CDATA[Linux概述]]></title><description><![CDATA[ 
 <br><br><br>操作系统是实现控制和管理计算机软硬件资源的系统软件。它可以有效地组织多个程序的运行，方便用户操作。常见的操作系统：windows,mac,linux,OS/2,以及各种嵌入式操作系统。目前操作系统的分类：批处理操作系统，分时操作系统，实时操作系统，网络操作系统和分布式操作系统。<br>操作系统的性能指标：吞吐量，资源利用率，公平性，实时性，可靠性以及安全性。<br>操作系统功能：<br>​	存储管理：内存分配，地址映射，内存的保护以及扩充<br>​	进程管理：进程调度，进程控制，进程之间的通信<br>​	文件管理：文件存储空间管理、文件操作、目录、读写权限等<br>​	设备管理：缓冲设备、设备分配、设备驱动<br>​	用户接口：图形用户接口，命令行接口<br><br>Linux，全称GNU/Linux，是一种免费使用和自由传播的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872?fromModule=lemma_inlink" target="_blank">类UNIX</a>操作系统，其内核由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429?fromModule=lemma_inlink" target="_blank">林纳斯·本纳第克特·托瓦兹</a>（Linus Benedict Torvalds）于1991年10月5日首次发布，它主要受到<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Minix/7106045?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Minix/7106045?fromModule=lemma_inlink" target="_blank">Minix</a>和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" target="_blank">Unix</a>思想的启发，是一个基于<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink" target="_blank">POSIX</a>的多用户、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764?fromModule=lemma_inlink" target="_blank">多任务</a>、支持<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404?fromModule=lemma_inlink" target="_blank">多线程</a>和多<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/CPU/120556?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/CPU/120556?fromModule=lemma_inlink" target="_blank">CPU</a>的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" target="_blank">操作系统</a>。它支持<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/32%E4%BD%8D/5812218?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/32%E4%BD%8D/5812218?fromModule=lemma_inlink" target="_blank">32位</a>和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/64%E4%BD%8D/2262282?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/64%E4%BD%8D/2262282?fromModule=lemma_inlink" target="_blank">64位</a>硬件，能运行主要的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" target="_blank">Unix</a>工具软件、应用程序和网络协议。<br>在国内用的比较多的版本：Ubuntu，Centos，RedHat<br><br>linux系统以文件为基础，系统子目录当中的文件主要是保证系统的正常运行。<br>/，/home  /usr  /var  /bin /sbin /etc  /dev  /lib<br>/ : linux系统的根目录（主目录） <br>/home ：用户目录，linux当中每增加一个用户，都会在此目录下相应地增加一个文件，文件名和用户名相同（root除外），给每个用户自己的空间<br>/root： root用户的目录<br>/usr：通常用来安装各种软件的地方<br>/var：通常用来放置一些变化的文件<br>/var/log： 存放系统的日志文件<br>/bin  /sbin: 用于存放linux的系统命令和工具<br>/etc: 系统配置文件所在的位置<br>/dev：存放linux当中的所有设备文件<br>/lib，/lib64:  存放操作系统的库文件<br>/mnt:  外部设备的挂载点<br>/opt：目录是一种用于安装第三方软件的约定目录<br>/run:一个运行时临时文件系统，用于存储在系统运行期间创建的临时文件<br>/proc:目录下的文件和子目录代表系统中运行的实际进程和系统内核的状态<br>/srv:用于存放特定服务相关的数据、配置文件和其他资源。<br><img alt="目录结构" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171303158.jpg" referrerpolicy="no-referrer"><br>Linux系统是区分大小写，Linux文件没有扩展名<br><br><br>tab补全：linux当中的命令比较多，无法记全的情况下，可以使用tab键进行提示。当只有一个匹配命令时，tab键可以帮助不全，当有个匹配，双按tab，会提示命令。<br>当命令的参数或者option信息不清楚，可以使用man命令或者help进行帮助查看。<br>​	 man  命令（man ls）<br>​	命令 --help<br><br><br>主目录和工作目录：每一个用户都有自己的主目录，这个是管理员在创建用户的时候指定的。用户在自己的home目录当中可以进行各种操作，用户对自己的主目录拥有最大的权限。<br>工作目录：指当前所在的位置，进入linux之后，用户始终都会有一个工作目录。可以使用cd命令切换工作目录。<br>​		可以使用pwd命令查看当前所在的工作目录的完整路径。<br><br>几个特殊路径：<br>​	cd  / :进入根目录<br>​	cd ~: 进入当前用户的主目录<br>​	cd .. :返回到上一级目录<br>​	cd -: 返回上一次所在目录<br>绝对路径： 从文件的根目录开始的路径，始终以 /开头<br>相对路径：从当前的工作目录开始的路径，要和工作目录结合起来，才能确定所在的位置。<br>ls：列举指定目录中的文件和目录<br>mkdir：创建新目录<br>rmdir：删除指定的目录（必须是空目录，如果不是空，可以先删除此目录中的对象，再删除，还可以使用rm命令）<br><br>touch：创建空文件
cp：复制文件。可将文件复制到不同的目录，也可将指定目录中的文件复制到其他位置
mv：将文件或目录移动至一个新的位置
rm:   删除文件或目录
ln ： 创建链接（类似与windows的快捷方式）
whereis：查找文件。可以查找文件的源、二进制文件或手册
which: 查找二进制文件
find：查找文件
location：查找文件
grep ：所有文本<br><br>用touch命令可以创建一个没有任何内容的空文件。<br>touch file01
<br><br>类似与DOS命令中的copy
语法：cp 选项  源文件或目录   目标文件或目录
可以将文件复制到不同的目录，也可以将指定目录中的文件复制到其他位置。
常用参数
-a：相当与-dpr参数
-d：保留链接
-f：强制复制，覆盖目标文件
-i：覆盖时询问用户
-p：保留修改时间和访问权限
-r，-R：递归复制（目录到目录）
-l：创建链接
-v：显示过程<br>#当前文件夹下复制一个文件
cp 3.txt 4.txt 
#将当前目录下的txt复制到根目录下
cp *.txt / 
#将data目录（文件）复制到2目录下 
cp -r data data1/  
#将hello文件复制到/opt目录下
cp -p hello.java /opt/hello.java
<br><br>将文件或目录移到一个新的位子。也可以用来修改文件名称
mv  选项   源文件或目标  目标文件或目录
常用参数：
-i：交互方式操作，如果mv操作将导致对已存在文件的覆盖，此时系统询问是否重写，要求用户回答y或n
-f：禁止交互操作。覆盖时不会提示。<br>mv -i  hello.java  hello1.java
<br><br>​	rm [选项] 文件
​	常用参数：
​	-i : 为了避免误删除文件，可以使用此项，进行用户确认删除
​	-f:  强制删除，使用该选项后将不提示所删除的文件
​	-v:  显示文件的删除速度
​	-r:  删除某个目录以及其中所有的文件和子目录。<br>#删除文件
rm aa
#删除目录
rm -rf a
<br>在Linux中可以创建链接文件，当使用rm删除链接文件时，只是删除该链接文件，实际的文件仍旧继续存在。<br><br>​	Linux中的链接类似于windows的快捷方式，分两种：软连接和硬链接。
​	创建软链接，只是在指定的位置上生成一个镜像，不会占用磁盘空间。
​     	语法： ln  -s   目标文件  链接文件名
​	创建硬链接，将在指定的位置上生成一个和源文件大小相同的文件。
​      	语法：    ln   目标文件  链接文件名
​	无论是软链接还是硬链接，链接文件和目录文件都将保持同步变化。
​	不能创建目录的硬链接。<br>#创建软链接
ln -s hello  hellolink
#查找文件
find -name hello
<br><br>whereis用来查找程序的源、二进制文件或手册。
whereis 选项 文件名
常用选项
-b：搜索文件的二进制部分
-m：搜索文件的手册部分
-s：搜索文件的源部分。<br>不带选项，查找二进制文件和手册的位置<br>whereis ls
<br><br>which 选项 文件名
常用选项
-n：指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。
-p：与-n参数相同，但此处包含文件路径
-w：指定输出时栏位的宽度
-V：显示版本信息<br>which  -V ls
<br><br>可以按照文件名、文件类型、用户等去查找。
find  路径  选项  [-print] [-exec –ok command] {};
常用选项
-name filename :查找名为filename的文件
-perm：按执行权限来查找
-user username：按照文件的所属用户来查找
-group  groupname：按照组来查找
-size n[c] 查长度为n块（n字节）的文件。<br>#根据文件名查找
find /home -name 123.sh
#根据文件大小查找 (+大于 -小于)
find /home -size +20000
#根据文件所有者查找：查找所有者为jp的文件
find /home -user jp
<br><br>locate：从已经创建好的一个索引数据库中查找。比find命令的查找速度更快。
locate 选项  文件名
-b, --basename -- 仅匹配路径名的基本名称
-c, --count -- 只输出找到的数量
-d, -- 数据库路径 -- 使用 DB PATH 指定的数据库，而不是默认数据库 /var/lib/mlocate/mlocate.db
-q, -- 安静模式，不会显示任何错误讯息。
一般不使用参数。<br>locate 与 find 不同: find 是去硬盘找，locate 只在 /var/lib/slocate 资料库中找。
locate 的速度比 find 快，它并不是真的查找，而是查数据库，一般文件数据库在 /var/lib/slocate/slocate.db 中，所以 locate 的查找并不是实时的，而是以数据库的更新为准，一般是系统自己维护，也可以手工升级数据库 ，命令为：updatedb<br>常见问题：
无法执行 stat () `/var/lib/mlocate/mlocate.db': 没有那个文件或目录
解决方案：
执行：updatedb命令<br>[root@centos601 桌面]# locate /etc/sh
locate: can not stat () `/var/lib/mlocate/mlocate.db': 没有那个文件或目录
[root@centos601 桌面]# update locate
bash: update: command not found
[root@centos601 桌面]# updatedb
[root@centos601 桌面]# locate /etc/sh
/etc/shadow
/etc/shadow-
/etc/shells
<br><br>对查找目标中的具体内容进行查找，是一个强大的文本搜索工具。它是一个管道命令，和其它命令结合使用。
工作方式：在一个或多个文件中搜索字符串模板，可以使用正则表达式进行搜索。<br>在linux或unix系统中，|就是管道命令，把上一个命令的结果交给管道命令（|）后面的命令处理<br>#查找/etc/hosts中包含localhost4的内容
cat /etc/hosts | grep localhost4
<br><br><br>cat：将文件中的内容输出到设备上，若是多个文件，则按顺序输出。
cat   选项  文件名
常用选项<br>
<br>-n：由1开始对所有输出的行数编号
<br>-b：和-n相似，只是对于空白行不进行编号
<br>-s：若遇到连续两行以上的空白行，就替换成一行空白行输出。
若准备将多个文件合并为一个文件，则使用以下方式
Cat  选项  文件名1  文件名2…… &gt; 新文件
<br>#将/etc/hosts文件中的内容输出到/opt/a文件中
cat /etc/hosts &gt; /opt/a
#查看/opt/a文件的内容
cat /opt/a
<br><br>more分屏显示 ，可以和其它命令结合使用，也可以单独使用。在 more 这个程序的运行过程中，你有几个按键可以按的：<br>
<br>空白键 (space)：代表向下翻一页；
<br>Enter         ：代表向下翻『一行』；
<br>/字串         ：代表在这个显示的内容当中，向下搜寻『字串』这个关键字；
<br>:f            ：立刻显示出档名以及目前显示的行数；
<br>q             ：代表立刻离开 more ，不再显示该文件内容。
<br>b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。
<br>more /etc/profile
cat day522 | more
<br><br>less分屏显示 ，可以和其它命令结合使用，也可以单独使用。less运行时可以输入的命令有：<br>
<br>空白键    ：向下翻动一页；
<br>[page down]：向下翻动一页；
<br>[page up]  ：向上翻动一页；
<br>/字串     ：向下搜寻『字串』的功能；
<br>?字串     ：向上搜寻『字串』的功能；
<br>n         ：重复前一个搜寻 (与 / 或 ? 有关！)
<br>N         ：反向的重复前一个搜寻 (与 / 或 ? 有关！)
<br>q         ：离开 less 这个程序；
<br>more /etc/profile
<br><br>语法：head [-n number] 文件 <br>head -n 3 /etc/profile
<br><br>语法：tail [-n number] 文件 ，常用来读取日志文件<br>​      -f : 循环读取  tail  -f  文件名<br>​     -n ：数字  读取最后几行<br>tail -n 10 /etc/profile
#循环读取
ping 192.168.66.211 &gt; ping.log &amp;
tail -f ping.log
<br><br>在Linux中，用户和组的相关信息保存在对应的文件中，一共有三个文件，分别是passwd、shadow和group<br>
<br>
passwd文件

<br>用户信息文件  /etc/目录下。	
<br>系统中的每一个合法用户账号对应于该文件中的一行记录。
<br>每一行由7个部分组成：注册名:口令：用户标识号：组标识号：备注：用户主目录：命令解释程序

<br>注册名：登陆账户，不能重复，区分大小写。
<br>口令：登陆系统的口令。若第一个字符是“*”，表示禁止该账号登陆。
<br>用户标志号：Linux中唯一的用户标识
<br>组标志号：当行用户的默认工作组标记
<br>备注：保存一些用户的信息
<br>用户主目录：个人用户的主目录，该用户登陆后，将该目录作为用户的工作目录
<br>命令解释程序：当前用户登陆系统时运行的程序名称，通常是一个shell程序的全路径名。




<br>
shadow文件

<br>保存用户的口令。/etc/目录下
<br>该文件不能被普通用户读取，只有超级用户root才有权读取。


<br>
group文件

<br>保存在/etc/group当中
<br>每一行数据内容 用户组名称：用户组密码：用户组标识号：用户列表


<br><br>
<br>添加组：groupadd
groupadd  policeman 
<br>查看组：通过vi或cat命令
vi  /etc/group
cat /etc/group
<br>删除组：groupdel
groupdel policeman
<br>将现有用户增加到组中
usermod  -g  组名  用户名
<br>从组中删除用户
gpasswd -d 用户名 组名
<br>查看当前用户所在组：groups
<br><br>
<br>创建用户：useradd
useradd 用户名：创建一个新的用户
useradd 用户名 -g 组名	：添加用户，并加入到某个组当中
useradd –m –g 组名 用户名：创建一个新的用户并创建家目录，指定组
<br>修改用户：usermod
usermod -g 组名 用户名 ：修改用户信息
<br>创建密码：password
passwd 用户名 ：为用户创建密码
<br>删除用户：userdel
userdel 用户名	：删除用户名
userdel -r 用户名	：删除用户以及用户主目录

<br>su   用户名称 切换用户


<br><br>修改 /etc/sudoers文件，给对应的用户增加root权限，用户在执行命令式，使用sudo 命令 即可执行管理员的所有权限。<br>## Allow root to run any commands anywhere 
root	ALL=(ALL) 	ALL
#给huangyy增加root权限
huangyy ALL=(ALL) 	ALL
<br><br>Linux的文件类型大致可以分为5种：
普通文件：用于存储数据、程序等信息的文件。文本文件和二进制文件。
目录文件：由文件系统中的一个目录项组成的文件。用户进行只能对其进行读取，不能进行修改
设备文件：用于与IO设备提供连接的文件，可以分为字符设备文件和块设备文件。每一种I/O设备对应于一个设备文件，存放于/dev/目录中。
链接文件：通过链接文件中指向文件的指针来实现对文件的访问。
管道文件：用于进程间传递数据。Linux对管道的操作与对普通文件的操作相同。<br>drwx r-xr-x  test :  第一组 rwx表示test文件的用户所有者(vagrant,vagrant所在的组vgroup（v1,v2,v3,vagrant）)的权限<br>​							r-x(黑色) : 文件所有者的同组其他用户的权限（v1,v3,v2）<br>​                                     r-x: vgroup组以外的其他用户的权限							<br><img alt="权限1" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171301840.png" referrerpolicy="no-referrer"><br>操作权限分为三种：
R：读取权限  （４），如果是目录，用户可以浏览目录
W ：写权限　（２），如果是目录，用户可以删除、移动目录内的文件
X: ：执行权限（１），如果是目录，则表示可进入此目录，如果是bash命令，则表示可以执行<br><img style="zoom:50%;" alt="权限2" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171301021.png" referrerpolicy="no-referrer"><br><br>使用chmod命令可以修改文件的权限。通过权限字母和操作符表达式的方法来设置权限
语法：chmod [用户类型] [+|-|=] [权限字符] 文件名
u=用户权限  g=组权限  o=不同组其他
+：添加权限；-：取消权限 =：赋予给定权限并取消其他所有权限。
权限字符：可以使用r、w、x组合，也可以使用s
使用数字来设置权限
chmod [数字组合] 文件名
用3位八进制数来表示文件的3类用户的权限组合
例如751：表示用户权限为rwx，当前用户组权限：r-x  其他用户组权限为--x<br>#赋予abc权限rwxr-xr-x
chmod 755 abc
#同上
chmod u=rwx,g=rx,o=rx abc
#给abc增加组写权限
chmod go+w abc
#给abc去除用户执行权限，增加当前组写权限
chmod u-x,g+w abc
#给所有用户添加读的权限
chmod a+r abc
<br><br>使用chown命令可以修改文件的所有者和组，只有root用户可以更改用户的所有者。只有root用户或文件所有者可以更改文件的组，如果是文件所有者但不是root用户，则只能将组改为当前用户所在组。
语法：chown 所有者:组 文件<br>#修改文件所有者为xiaohuang
chown xiaohuang  hello.java
<br><br>在Linux中，每个执行的程序都称为一个进程。每一个进程都分配一个ID号。每一个进程，都会对应一个父进程。而这个父进程可以复制多个子进程。
每个进程都可能以两种方式存在的，前台与后台。所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于在屏幕上无法看到的进程，通常使用后台方式执行。一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才结束。<br><br>ps命令是用来查看系统中，有哪些正在执行，以及它们执行的状况。可以不加任何参数。
显示详细的进程信息(终端上的所有进程，包括其它用户)：ps -a
以用户的格式显示进程信息：ps -u
显示后台进程运行参数：px –x
查看更全面信息   ps -aux<br>USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root        485  0.0  0.0      0     0 ?        S    Nov02   0:00 [ext4-dio-unwrit]
root        593  0.0  0.0  11248  1372 ?        S&lt;s  Nov02   0:00 /sbin/udevd -d
root       1800  0.1  0.4 260836  8524 ?        Sl   Nov02   0:20 /usr/sbin/vmtoolsd
root       2044  0.0  0.0  27596   832 ?        S&lt;sl Nov02   0:00 auditd
rpc        2179  0.0  0.0  18980   876 ?        Ss   Nov02   0:00 rpcbind
dbus       2199  0.0  0.1  32556  2088 ?        Ssl  Nov02   0:00 dbus-daemon --system
root       2213  0.0  0.2  84960  4864 ?        Ss   Nov02   0:00 NetworkManager --pid-file=/var/run/NetworkManager/NetworkManager.pid
root       2220  0.0  0.1  58120  2608 ?        S    Nov02   0:00 /usr/sbin/modem-manager
rpcuser    2237  0.0  0.0  23352  1380 ?        Ss   Nov02   0:00 rpc.statd
<br>USER：用户
PID: 进程的ID
PPID:父进程的ID
%CPU:进程占用的CPU百分比
%MEM：进程占用的内存百分比
VSZ:使用的虚拟内存量（KB)
RSS：该进程占用的固定内存量（KB)
STAT:进程的状态。
TTY:该进程在哪个终端上运行，若与终端无关，则显示？ 若为pst/0等，则表示由网络连接主机进程。
TIME:使用CPU的时间<br>其中STAT常见的值如下：<br><br><br>对于前台进程，在推出程序后该进程将自动结束。在前台进程运行过程中，也可按快捷键Ctrl + C 退出。
对于后台进程，需要使用kill命令来终止。<br>信号量：15，9，默认为15 ，告诉进程需要终止，并不一定立刻终止，如果是9，表示强制终止进程<br>#终止pid为4217的进程
kill -9  4217
<br><br>查看系统当前正在执行的进程的相关信息，包括进程id，内存的使用率，CPU的占有率等（动态，实时）<br>load average: 0.00, 0.01, 0.04，分别表示最近一分钟，五分钟，以及十五分钟的负载状况。<br>是否load average大于1就是系统负载比较高。不一定。要看CPU的核数和线程数，如果是单核cpu，值等于1就是满负荷，如果是四核，八核，负载大于1说明负载不算太高。<br>-c: 显示完整的进程命令
-s:  保密模式
-p PID 指定进程显示
-n &lt;次数&gt; 执行循环显示次数
-H 显示线程数
<br><br>可以将命令的最后加上“&amp;”，使得程序放到后台运行。<br>基本用于需要一直运行的服务类进程，比如说tomcat，nginx，mysql<br><br>centos7中采用以下命令对防火墙进行处理。<br>
<br>查看防火墙状态：firewall-cmd --state
<br>停止防火墙： systemctl stop firewalld.service
<br>启动防火墙： systemctl start firewalld.service
<br>重启防火墙： systemctl restart firewalld.service
<br>永久关闭防火墙：systemctl disable firewalld.service
<br>永久关闭后重启：systemctl enable firewalld.service
<br>查看开机防火墙：systemctl is-enabled firewalld.service
<br>端口操作：<br>
<br>开启端口：firewall-cmd --zone=public --remove-port=80/tcp --permanent
<br>刷新：firewall-cmd --reload
<br>查看端口状态：firewall-cmd --zone=public --query-port=80/tcp 

<br>yes表示端口开放，no表示端口不开放


<br>关闭端口：firewall-cmd --zone=public --remove-port=80/tcp --permanent
<br>[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
no
[root@centos701 etc]# firewall-cmd --zone=public --add-port=80/tcp --permanent
success
[root@centos701 etc]# firewall-cmd --reload
success
[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
yes  
[root@centos701 etc]# firewall-cmd --zone=public --remove-port=80/tcp --permanent
success
[root@centos701 etc]# firewall-cmd --reload
success
[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
no


<br><br>logout：注销系统
login：回到登录界面
shutdown –h now	：立刻关机
shutdown +5	：5分钟后关机
shutdown 10:30：在10：30关机
shutdown –r now	：立刻关闭系统并重启
reboot	：重新启动系统
init 0为关机，init 1为重启
halt立即关机
poweroff  立即关机<br><br>vi编辑器是Linux下最有名的编辑器，也是我们学习linux必须掌握的工具，在unix下也可以进行程序的开发。
开发步骤：
vi  文件名
输入i，进入插入模式，
输入Esc键
输入冒号:,再输入wq，保存并退出，如果不保存退出，则输入q!<br>基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 <br><img style="zoom: 50%;" alt="vim工作模式" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171300547.png" referrerpolicy="no-referrer"><br><br>用户刚刚启动 vi/vim，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。以下是常用的几个命令：<br>yy复制、dd删除、pp粘贴<br>
<br>i, I字符 ：切换到输入模式，以输入字符。i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』
<br>a, A字符 ：进入输入模式(Insert mode)，a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』
<br>o, O字符 ：进入输入模式(Insert mode)，这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！
<br>r, R：进入取代模式(Replace mode)，r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止
<br>x字符 ：删除当前光标所在处的字符。
<br>:字符 ：切换到底线命令模式，以在最底一行输入命令。
<br>若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。<br><br>在命令模式下按下i就进入了输入模式。在输入模式中，可以使用以下按键：<br>
<br>字符按键以及Shift组合，输入字符大小写转换
<br>ENTER：回车键，换行
<br>BACK SPACE：退格键，删除光标前一个字符
<br>DEL：删除键，删除光标后一个字符
<br>方向键：在文本中移动光标
<br>HOME/END：移动光标到行首/行尾
<br>Page Up/Page Down：上/下翻页
<br>Insert：切换光标为输入/替换模式，光标将变成竖线/下划线
<br>ESC：退出输入模式，切换到命令模式
<br><br>在命令模式下按下:（英文冒号）就进入了底线命令模式。底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。按ESC键可随时退出底线命令模式。
在底线命令模式中，基本的命令有（已经省略了冒号）：<br>
<br>q 退出程序，如果文件内容被修改了，会出现错误，要求使用“!”强制退出。
<br>q! ：强制退出vim，并且不保存文件
<br>w： 保存文件
<br>wq：将修改过的文件存储，并且离开vim
<br>set nu:在文件中每行加入行号
<br>set nonu：取消行号
<br>输入数字：直接输入数字再按enter，就可以将光标定位到改行行首。
<br>/字符串：利用/字符串来查找特定的内容，如果查找不是想要的的，可以按“n”键盘继续查找。
<br>?字符串：同/字符串
<br><br>命令模式下：<br>​	x：删除当前字符<br>​	3x: 删除当前光标开始的3个字符，如果想要删除n个字符，将3替换成n<br>​	X：删除当前光标的前一个字符<br>​	dd: 删除当前行<br>​	dj：删除上一行<br>​	dk：删除下一行<br>​	3d：删除当前行开始往后的3行<br>底线模式下<br>​	:5, 10d: 将5~10的数据删除掉<br>​	:5,$d: 将5行以后的数据全部删除掉<br><br>行拷贝：<br>​	yy：拷贝当前行<br>​	nyy：拷贝当前行开始的n行，5yy，从当前行开始拷贝5行的数据<br>​	p：再当前光标后粘贴<br>​	shift +p：在当前行前面进行粘贴<br>​	:1,5 co 20: 将1~5行copy放到20行之后<br>部分拷贝<br>​	yw：拷贝一个单词<br>​	2yl：拷贝当前光标开始的2个字符<br>​	3yh：拷贝当前光标前面的3个字符（不包括光标的相关字符）<br><br>tar：将指定目录中的所有文件和目录全部进行备份
gzip和gunzip：压缩和解压缩文件
Zip和unzip：压缩文件和解压文件<br><br>tar 是用来建立，还原备份文件的工具程序，它可以加入，解开备份文件内的文件。<br>-A或--catenate 新增文件到已存在的备份文件。
-c或--create 建立新的备份文件。
-C&lt;目的目录&gt;或--directory=&lt;目的目录&gt; 切换到指定的目录。
-f&lt;备份文件&gt;或--file=&lt;备份文件&gt; 指定备份文件。
-v或--verbose 显示指令执行过程。
-x或--extract或--get 从备份文件中还原文件。
-z或--gzip或--ungzip 通过gzip指令处理备份文件。
-Z或--compress或--uncompress 通过compress指令处理备份文件。
--delete 从备份文件中删除指定的文件。
--exclude=&lt;范本样式&gt; 排除符合范本样式的文件。<br>实际使用时经常联合多个选项一起使用，例如<br>-zcvf 创建一个压缩文件<br>
-zxvf   还原并解压缩文件  <br>#归档文件，将tmp文件夹打包成tmp.tgz
tar -zcvf tmp.tgz tmp
#归档文件，排除tmp目录中的w文件，压缩文件名为tmp.tgz,压缩打包放入tmp
tar --exclude=tmp/w  -zcvf tmp.tgz tmp

#创建tmp01目录，并将tmp.tgz解压缩到tmp01目录中。
mkdir tmp01
tar -zxvf tmp.tgz -C tmp01

#将tmp打包成u1.tar
tar -cf u1.tar tmp
#将tmp01打包成u2.tar
tar -cf u2.tar tmp01
#将u1.tar的内容追加到u2.tar当中（u2当中包含tmp和tmp01）
tar -A u1.tar -vf  u2.tar

<br><br>gzip<br>gzip命令用于压缩文件。gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出".gz"的扩展名。常用选项如下：<br>
<br>-d或--decompress或----uncompress 　解开压缩文件。
<br>-f或--force 　强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。
<br>-l或--list 　列出压缩文件的相关信息。
<br>-v或--verbose 　显示指令执行过程。
<br>-V或--version 　显示版本信息。
<br>gunzip命令<br>gunzip命令用于解压文件。gunzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为".gz"。事实上gunzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。常用选项如下：<br>
<br>-c或--stdout或--to-stdout 　把解压后的文件输出到标准输出设备。
<br>-f或-force 　强行解开压缩文件，不理会文件名称或硬连接是否存在以及该文件是否为符号连接。
<br>-l或--list 　列出压缩文件的相关信息。
<br>-v或--verbose 　显示指令执行过程。
<br>#压缩hello.java文件
gzip -vf hello.java
#将hello.java.gz解压缩
gunzip -vf hello.java.gz
<br><br>linux 下提供了 zip 和 unzip 程序，zip 是压缩程序，unzip 是解压程序。<br>zip命令的常用选项<br>
<br>-g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。
<br>-q 不显示指令执行过程。
<br>-r 递归处理，将指定目录下的所有文件和子目录一并处理。
<br>-S 包含系统和隐藏文件。
<br>-v 显示指令执行过程或显示版本信息。
<br>unzip常用的选项<br>#将所有的jpg文件压缩成一个z.zip文件
zip z.zip *.jpg
#解压文件
unzip all.zip
<br><br>将jdk的linux安装文件放入到linux的某个目录下<br>解压<br>tar -zxvf  jdkxxx.tar.gz 
<br>设置环境变量<br>在/etc/profile的最后增加以下内容<br>JAVA_HOME=/usr/jdk1.8.0_261
CLASSPATH=.:$JAVA_HOME/lib
PATH=$PATH:$JAVA_HOME/bin

export JAVA_HOME CLASSPATH  PATH
<br>重新加载配置文件<br>source /etc/profile
<br>进行测试<br>java或者java命令就可以测试]]></description><link>教程\11、Linux课件.html</link><guid isPermaLink="false">教程/11、Linux课件.md</guid><pubDate>Tue, 12 Sep 2023 09:08:51 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171303158.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171303158.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[什么是Vagrant]]></title><description><![CDATA[ 
 <br><br>Vagrant是一个工具，用于创建和部署虚拟化环境，它可以和VirtualBox以及vmware一起整合使用。<br>以VirtualBox为例，VirtualBox会开发一个创建虚拟机的接口，Vagrant会利用此接口来创建虚拟机，并且通过vagrant来管理、配置以及安装虚拟机。<br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://developer.hashicorp.com/vagrant/downloads" target="_blank">https://developer.hashicorp.com/vagrant/downloads</a><br><br>vagrant是没有图形界面的，安装后也没有桌面快捷方式。Vagrant安装程序，会将安装路径自动加入Path环境变量当中。可以命令行通过命令来操作vagrant。可以使用vagrant version来检查是否成功安装<br><br>虚拟机（Virtual Machine）指通过软件模拟的具有完整硬件<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD/10394740?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD/10394740?fromModule=lemma_inlink" target="_blank">系统功能</a>的、运行在一个完全隔离环境中的完整<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7210959?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7210959?fromModule=lemma_inlink" target="_blank">计算机系统</a>。在实体计算机中能够完成的工作在虚拟机中都能够实现。在计算机中创建虚拟机时，需要将实体机的部分硬盘和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%86%85%E5%AD%98%E5%AE%B9%E9%87%8F/3361934?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%86%85%E5%AD%98%E5%AE%B9%E9%87%8F/3361934?fromModule=lemma_inlink" target="_blank">内存容量</a>作为虚拟机的硬盘和内存容量。每个虚拟机都有独立的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/CMOS/428167?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/CMOS/428167?fromModule=lemma_inlink" target="_blank">CMOS</a>、硬盘和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" target="_blank">操作系统</a>，可以像使用实体机一样对虚拟机进行操作。<br>VirtualBox 是一款开源<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BD%AF%E4%BB%B6/9003764?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BD%AF%E4%BB%B6/9003764?fromModule=lemma_inlink" target="_blank">虚拟机软件</a>。VirtualBox 是由德国 <a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Innotek/4492496?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Innotek/4492496?fromModule=lemma_inlink" target="_blank">Innotek</a> 公司开发，由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Sun/69463?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Sun/69463?fromModule=lemma_inlink" target="_blank">Sun</a> Microsystems公司出品的软件，使用<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Qt/451743?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Qt/451743?fromModule=lemma_inlink" target="_blank">Qt</a>编写，在 Sun 被 <a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Oracle/301207?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Oracle/301207?fromModule=lemma_inlink" target="_blank">Oracle</a> 收购后正式更名成 Oracle VM VirtualBox。Innotek 以 GNU General Public License (<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/GPL/2357903?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/GPL/2357903?fromModule=lemma_inlink" target="_blank">GPL</a>) 释出 VirtualBox，并提供<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457?fromModule=lemma_inlink" target="_blank">二进制</a>版本及 OSE 版本的代码。使用者可以在VirtualBox上安装并且执行<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Solaris/3517?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Solaris/3517?fromModule=lemma_inlink" target="_blank">Solaris</a>、Windows、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/DOS/32025?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/DOS/32025?fromModule=lemma_inlink" target="_blank">DOS</a>、Linux、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/OS%2F2/1958699?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/OS%2F2/1958699?fromModule=lemma_inlink" target="_blank">OS/2</a> Warp、BSD等系统作为客户端操作系统。已由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8/430115?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8/430115?fromModule=lemma_inlink" target="_blank">甲骨文公司</a>进行开发，是甲骨文公司xVM虚拟化平台技术的一部分。<br><br><br>通过vagrant创建虚拟机需要先导入镜像文件，也就是各种box。默认的存放目录就在用户目录下的.vagrant.d目录下，对于windows系统来说，c:/user/用户名/.vagrant.d<br>如果都放入cpan，导致c盘空间紧张，可以通过环境变量VAGRANT_HOME来设置存放的位置。<br><br><img alt="01.环境变量" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171259658.png" referrerpolicy="no-referrer"><br><br><br>vagrant的官网下载：<a rel="noopener nofollow" class="external-link" href="https://developer.hashicorp.com" target="_blank">https://developer.hashicorp.com</a><br>centos的镜像：<a rel="noopener nofollow" class="external-link" href="https://cloud.centos.org/centos/" target="_blank">https://cloud.centos.org/centos/</a><br><br>vagrant box list<br><br>vagrant  box add  文件所在位置 --name box名<br>vagrant box add D:\ftp178\01.soft\CentOS-7.box --name centos7
<br>文件所在位置 : 通过此位置指定一个box镜像文件<br>centos7：给box镜像起的名字，安装虚拟机的时候需要使用此名字，尽量简单好记<br><br>vagrant box remove box名字<br>vagrant box remove centos7
<br><br>vagrant init： 初始化一个虚拟机配置文件vagrantfile，需要先创建目录，在对应的目录下运行此命令。<br>​	vagrant init  box名，如果忘记指定box名，则可以vagrantfile当中进行修改<br>vagrant up：启动虚拟机，无论虚拟机是关闭，还是暂停状态，都可以使用此命令来恢复虚拟机的运行<br>vagrant ssh：进入虚拟机，进行操作<br>vagrant suspend：挂起虚拟机<br>vagrant reload：重启虚拟机，重新加载vagrantfile当中的配置信息<br>vagrant halt：关闭虚拟机<br>vagrant status：查看虚拟机的状态<br>vagrant destroy：删除虚拟机，销毁当前的虚拟机]]></description><link>教程\11、Vagrant课件.html</link><guid isPermaLink="false">教程/11、Vagrant课件.md</guid><pubDate>Thu, 17 Aug 2023 05:20:21 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171259658.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171259658.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[一、Quartz基础]]></title><description><![CDATA[ 
 <br><br>typora-root-url: E:\课件_总\00-  教学笔记\Quartz\图例<br><br>实现定时任务简单的有四种方式:Timer，ScheduledThreadPool线程池，quartz(常用)以及springtask,XXL-JOB<br><br>Quartz是一个完全由Java编写的开源作业调度框架，是OpenSymphony开源组织在Job scheduling领域又一个开源项目。Quartz允许开发人员根据时间间隔来调度作业。它实现了作业和触发器的多对多的关系，还能把多个作业与不同的触发器关联。它可以与J2EE与J2SE应用程序相结合也可以单独使用。<br>Quartz是开源且丰富特性的“任务调度库”，能够集成任何的java应用。Quartz能够创建可简单可复杂的调度，以执行上百、上万个任务。Quartz调库框架包含许多企业级的特性，如JTA事务，集群的支持。<br>官网地址：<a rel="noopener nofollow" class="external-link" href="http://www.quartz-scheduler.org/" target="_blank">http://www.quartz-scheduler.org/</a><br><br>嵌入另一个独立运行的程序
可以在应用服务器（或Servlet容器）内被实例化，并且参与事务。
可以作为独立的运行程序（其自己的java虚拟机内），可以通过RMI使用
可以被实例化，作为独立的项目集群（负载均衡或故障转移功能），用于作业的执行<br><br>Builder模式
Factory模式
组件模式
链式模式<br><br><br>
<br>任务job：job就是你想要实现的任务类，每一个Job必须实现org.quartz.Job接口，且只需要实现接口定义的execute()方法。
<br>触发器Trigger：触发器代表一个调度参数的配置，配置调用的时间，比如你想每天定时下午5点发送邮件，制定触发的条件。Trigger主要包含SimpeTrigger和CronTrigger两种。
<br>调度器Scheduler：是一个计划调度器容器，容器里面可以盛放众多的JobDetail和trigger，它会将任务job以及触发器Trigger整合起来，负责基于Trigger设定的事件来执行Job。
<br><br><img alt="01.体系架构" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240219133926721.png" referrerpolicy="no-referrer"><br><br>
<br>Scheduler：用于与调度程序交互的主程序接口。Scheduler调度程序-任务执行计划表，只有安排进执行计划的任务Job（通过scheduler.schedulejob方法安排进执行计划），当它预先定义的执行事件到了的时候（任务触发trigger），该任务才会执行。
<br>Job ：预先定义的，希望在将来的某个事件能被调度执行的任务类。
<br>JobDetail：使用JobDetail来定义定时任务的实例，JobDetail通过JobBuilder来创建
<br>JobDataMap：可以包含不限量（序列化的）数据对象，在job实例执行的时候，可以使用其中的数据JobDataMap是一个Map接口的实现，额外增加了一些便于存取基本类型的数据方法。
<br>Trigger触发器：用来触发执行Job的。当调度一个Job时，创建一个触发器对象，并调整它的属性来满足Job执行的条件。它表明任务的执行时点，比如说什么时间执行，间隔如何等。
<br>JobBuilder：用于定义一个任务实例，也可以定义关于此任务的详细信息，例如：任务名，组别等。这个声明的实例将会作为一个实际执行的任务。
<br>TriggerBuilder：触发器的创建器，用于创建触发器实例。
<br>JobListener，TriggerListener，SchedulerListener监听器，用于对组件的监听。
<br><br><br>
<br>
1.创建一个maven工程

<br>
2.增加依赖
&lt;dependency&gt;
    &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;
    &lt;artifactId&gt;quartz&lt;/artifactId&gt;
    &lt;version&gt;2.3.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt;
    &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt;
    &lt;version&gt;2.3.2&lt;/version&gt;
&lt;/dependency&gt;


<br>
3.定义任务
注意：定义任务的Job实现类必须是公开的（public）
public class HelloQuartzJob implements Job{
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("hello," + LocalTime.now().toString());
    }
}


<br>
4.定义一个主类，来定时执行此任务
public static void main(String[] args) throws SchedulerException {
	//1：调度器，从工厂中获取调度的实例
	Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

	//2：任务实例（JobDetail）
	JobDetail job = JobBuilder
			.newJob(HelloQuartzJob.class)
			.withIdentity("helloQuartzJob","group1") //任务名称，任务组的名字
			.build();
	//3：触发器（Trigger）
	Trigger trigger = TriggerBuilder.newTrigger()
			.withIdentity("trigger1","group1") //触发器的名字，触发器组的名字
			.startNow()  //马上启动触发器
			.withSchedule(SimpleScheduleBuilder.simpleSchedule()
					.withIntervalInSeconds(5)
					.withRepeatCount(5))  //重复执行6次，从0开始
			.build();

	//让调度器关联任务和触发器，保证按照触发器定义的条件执行任务
	scheduler.scheduleJob(job,trigger);
	//启动
	scheduler.start();
}


<br><br>
<br>
job:工作任务调度的接口，任务类需要实现该接口。该接口中定义的execute方法，类似于JDK提供的TimeTask类中的run方法，用来编写业务逻辑。

<br>Job实例在Quartz中的生命周期：每次调度器执行Job时，它在调用execute方法前会创建一个新的Job实例，当调用完成后，关联的job对象会被释放，释放的实例会被垃圾收集器收集。


<br>
JobDetail：JobDetai为job实例提供了许多属性设置，以及jobDataMap成员属性，它用来存储特定Job实例的状态信息，调度器需要借助jobDetail对象来添加Job实例。
JobDetail的重要属性：name，group，jobClass，jobDataMap
//2：任务实例（JobDetail）
JobDetail job = JobBuilder
		.newJob(HelloQuartzJob.class)
		.withIdentity("helloQuartzJob","group1") //任务名称，任务组的名字
		.requestRecovery()
		.build();
System.out.println(job.getKey().getName());
System.out.println(job.getKey().getGroup());
System.out.println(job.getJobClass().getName());


<br><br>
<br>
当Scheduler调用一个Job，就会将jobExecutionContext对象传递给job的execute()方法。
Job能通过JobExecutionContext对象访问到Quartz运行时候的环境以及job本身的明细数据。
public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
	//获取运行时数据
	System.out.println(jobExecutionContext.getJobDetail().getKey().getName());
	System.out.println(jobExecutionContext.getJobDetail().getKey().getGroup());
	System.out.println("hello," + LocalTime.now().toString());
}


<br><br>在进行任务调度时，JobDataMap存储在JobExecutionContext中，非常方便获取。
jobDataMap可以用来装载任何可序列化的数据对象，当Job实例对象呗执行时，这些参数对象会传递给它。
jobDataMap实现了JDK的Map接口，并且添加了非常方便的方法用来存取基本数据类型。<br>
<br>
在创建JobDetail和Trigger中传递参数
可以通过JobExecutionContext对象获取到JobDataMap对象
public static void main(String[] args) throws SchedulerException {

	Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

	JobDetail job = JobBuilder.newJob(ParamJob.class)
			.withIdentity("paramjob","group2")
			.usingJobData("username","xiaoming") //传参数
			.usingJobData("age",5)//传参数
			.build();

	Trigger trigger = TriggerBuilder.newTrigger()
			.withIdentity("triggle2","group2")
			.usingJobData("message","triggle message")//传参数
			.startNow()
			.withSchedule(SimpleScheduleBuilder.simpleSchedule()
					.withIntervalInSeconds(1)
					.repeatForever())
			.build();
	scheduler.scheduleJob(job,trigger);
	scheduler.start();
}


<br>
Job类中读取数据

<br>通过JobDataMap获取数据

public class ParamJob implements Job {
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {

        JobDataMap jobDataMapmap = jobExecutionContext.getJobDetail().getJobDataMap();
        System.out.println("===name:" + jobDataMapmap.getString("username") + ",age:" + jobDataMapmap.getInt("age") + "======" );

        JobDataMap triggleMap = jobExecutionContext.getTrigger().getJobDataMap();
        System.out.println("message:" + triggleMap.getString("message"));
        System.out.println("当前任务执行事件：" + jobExecutionContext.getFireTime());
        System.out.println("下次任务执行事件："  + jobExecutionContext.getNextFireTime());
        System.out.println("hello," + LocalTime.now().toString());
    }
}


<br>
使用属性方式获取数据
在job类中定义属性，并提供公开的Setter方法。
注意，如果trigger和jobdetail中存在同名参数，trigger中的参数会覆盖掉jobdetail中的
public class ParamJob implements Job {
    String username;
    int age;
    String message;
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
		
        System.out.println("===name:" +username+ ",age:" + age + "======" );
        System.out.println("message:" + message);
        System.out.println("hello," + LocalTime.now().toString());
    }

    public void setUsername(String username) {
        this.username = username;
    }
    public void setAge(int age) {
        this.age = age;
    }
    public void setMessage(String message) {
        this.message = message;
    }
}




<br><br>有状态的job可以理解为多次job调用期间可以持有一些状态信息，这些状态信息存储在jobDataMap中，默认的Job是无状态的Job，即每次调用时都会创建一个新的jobDataMap。<br>可以使用@PersistJobDataAfterExecution注解，它告诉 Quartz 在 execute() 方法成功完成后（不抛出异常）更新 JobDetail 的 JobDataMap 的存储副本，以便下次执行相同的作业（ JobDetail) 接收更新的值而不是原始存储的值。<br>最好是和@DisallowConcurrentExecution注解一起使用。<br>@PersistJobDataAfterExecution //没有它，每次执行age都相同，有了它会增加
public class ParamJob implements Job {
    String username;
    int age;
    String message;
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {


        System.out.println("===name:" +username+ ",age:" + age + "======" );
        age++;
		//将值回写入map
        jobExecutionContext.getJobDetail().getJobDataMap().put("age",age);
        System.out.println("message:" + message);

        System.out.println("hello," + LocalTime.now().toString());
    }


    public void setUsername(String username) {
        this.username = username;
    }


    public void setAge(int age) {
        this.age = age;
    }
    public void setMessage(String message) {
        this.message = message;
    }
}

<br><br><img alt="image-20210704165002603" src="\C:\\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210704165002603.png" referrerpolicy="no-referrer"><br>Quartz有一些不同的触发器类型，不过用得最多的是SimpleTriggle和CronTriggle<br>jobKey：表示job实例的标志，触发器被触发时，该指定的job实例会被执行。<br>startTime：表示触发器的事件表，第一次开始被触发的事件，它的数据类型是java.util.Date<br>endTime：表示触发器终止被触发的事件，它的数据类型是java.util.Date<br>public class TriggerJob implements Job{
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {

        System.out.println("=================");
        Trigger trigger = jobExecutionContext.getTrigger();
        System.out.println("开始事件:" + trigger.getStartTime());
        System.out.println("结束事件:" + trigger.getEndTime());
    }
}
<br>在trigger中不再使用startNow()，而是设置开始和结束事件<br>public static void main(String[] args) throws SchedulerException {
	//1：调度器，从工厂中获取调度的实例
	Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

	//2：任务实例（JobDetail）
	JobDetail job = JobBuilder
			.newJob(TriggerJob.class)
			.withIdentity("helloQuartzJob","group1") //任务名称，任务组的名字
			.build();
	//3：触发器（Trigger）
	Date startDate = new Date();
	startDate.setTime(startDate.getTime() + 1000);
	Date endDate = new Date();
	endDate.setTime(endDate.getTime() + 10000);
	Trigger trigger = TriggerBuilder.newTrigger()
			.withIdentity("trigger1","group1") //触发器的名字，触发器组的名字
			.startAt(startDate)
			.endAt(endDate)
			.withSchedule(SimpleScheduleBuilder.simpleSchedule()
					.withIntervalInSeconds(5))
			.build();

	//让调度器关联任务和触发器，保证按照触发器定义的条件执行任务
	scheduler.scheduleJob(job,trigger);
	//启动
	scheduler.start();

}
<br><br>SimpleTrigger对于设置和使用是最为简单的一种QuartzTrigger
它是为那种需要在特定的日期/时间启动，且以一个可能的间隔时间重复执行n此的job所设计。<br>注意：<br>
<br>SimpleTrigger的属性有：开始时间，结束时间，重复次数和重复的时间间隔。
<br>重复次数属性的值可以为0，正整数或常量SimpleTrigger.REPEAT_INDEFINITELY
<br>重复的时间间隔属性必须为正整数，以毫秒作为时间单位，当重复的时间间隔为0时，意味着与Trigger同时触发执行。
<br>如果有指定结束时间属性，则结束时间属性优先于重复次数，这样的好处是：当我们需要创建每隔10秒钟触发一次直到指定时间结束的trigger时，不需要去计算从开始到结束重复的次数
<br><br>​	如果需要一个基于类似日历的概念而不是根据 SimpleTrigger 的确切指定间隔重复的作业触发计划<br>​	使用 CronTrigger，您可以指定触发时间表，例如“每个星期五中午”或“每个工作日和上午 9:30”，甚至“每周一、周三上午 9:00 至上午 10:00 之间每 5 分钟一次”和一月份的星期五”。<br>​	与 SimpleTrigger 一样，CronTrigger 有一个startTime指定计划何时生效，以及一个（可选）endTime指定计划何时停止。<br><br>Cron表达式用于配置 CronTrigger 的实例。Cron-Expressions 是实际上由七个子表达式组成的字符串，它们描述了计划的各个细节。这些子表达式用空格分隔。<br>
<br>
Seconds：秒

<br>
Minutes：分钟

<br>
Hours：小时

<br>
Day-of-Month：每月的某天

<br>
Month：月份

<br>
Day-of-Week：星期几

<br>
Year (optional field) 年份（可选字段）
取值：

单个子表达式可以包含范围和/或列表。例如，前面（读作“WED”）示例中的星期几字段可以替换为“MON-FRI”、“MON,WED,FRI”，甚至“MON-WED,SAT”。


<br>练习：<br>"0 0 10,14,16 * * ?"   每天上午10点，下午2点，4点触发
"0 0/30 9-17 * * ?"  早上9点到晚上5点之间每半小时，从0分开始每隔30分钟触发一次
"0 0 12 ? * WED"  每周三中午12点触发
"0 30 10-13 ？* WED,FRI"   每周三和周五的 10:30、11:30、12:30 和 13:30 触发
"0 15 10 15 * ?" 每月15日上午10：15触发
"0 15 10 L * ?" 每月最后一天上午10：15触发
"0 15 10 ？ * 6L" 每月最后一个星期五上午10：15触发
<br>可以利用在线的Cron表达式工具：<a rel="noopener nofollow" class="external-link" href="https://www.bejson.com/othertools/cron/" target="_blank">https://www.bejson.com/othertools/cron/</a><br><br>
<br>
JOB代码
public class CronTriggerJob implements Job{
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {

        System.out.println("=================");
        System.out.println("hello," + LocalTime.now().toString());
    }
}



<br>
测试代码
public static void main(String[] args) throws SchedulerException {
	//1：调度器，从工厂中获取调度的实例
	Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();

	//2：任务实例（JobDetail）
	JobDetail job = JobBuilder
			.newJob(CronTriggerJob.class)
			.withIdentity("helloQuartzJob","group1") //任务名称，任务组的名字
			.build();
	//3：触发器（Trigger）
	Date startDate = new Date();
	startDate.setTime(startDate.getTime() + 1000);
	Date endDate = new Date();
	endDate.setTime(endDate.getTime() + 10000);
	Trigger trigger = TriggerBuilder.newTrigger()
			.withIdentity("trigger1","group1") //触发器的名字，触发器组的名字
			.startAt(startDate)
			.endAt(endDate)
			.withSchedule(CronScheduleBuilder.cronSchedule("0/1 *  19 * * ?"))
			.build();

	//让调度器关联任务和触发器，保证按照触发器定义的条件执行任务
	scheduler.scheduleJob(job,trigger);
	//启动
	scheduler.start();
}


<br><br>所有的Scheduler实例是由SchedulerFactory创建<br>SchedulerFactory的创建方式<br>
<br>
StdSchedulerFactory：默认的SchedulerFactory

<br>使用一组参数来创建和初始化Quartz调度器
<br>配置参数一般存储在quartz.properties中
<br>通过调用getScheduler()方法就能创建和初始化调度器对象

StdSchedulerFactory factory = new StdSchedulerFactory();
Scheduler scheduler= factory.getScheduler();


<br>常用方法

<br>scheduleJob(job,trigger)：返回值为Date类型，任务的开始事件
<br>start()：开启
<br>standby():挂起，暂停操作，可调用start再次开启
<br>shutdown(boolean)：关闭任务调度，为true，等任务执行之后再关闭，false（默认）则直接关闭。




<br>
DirectSchedulerFactory：对SchedulerFactory的直接实现，通过它可以直接构建Scheduler，thredPool等
DirectSchedulerFactory factory = DirectSchedulerFactory.getInstance();
Scheduler scheduler = factory.getScheduler();


<br><br>默认文件所在位置：org.quartz包下<br>#用来区分特定的调度器实例，可以按照业务用途来给调度器起名字	
org.quartz.scheduler.instanceName: DefaultQuartzScheduler
#instanceId，这个值必须在所有的调度器实例中是唯一的，尤其是集群环境中，作为集群的唯一key。如果想要Quartz帮助你生成这个值，可以设置为AUTO
#org.quartz.scheduler.instanceId=AUTO
org.quartz.scheduler.rmi.export: false
org.quartz.scheduler.rmi.proxy: false
org.quartz.scheduler.wrapJobExecutionInUserTransaction: false
#一个实现org.quartz.spi.threadPool接口的类，以下为自带的线程池类
org.quartz.threadPool.class: org.quartz.simpl.SimpleThreadPool
#处理job的线程个数，至少为1，多数情况下最好不要超过100
org.quartz.threadPool.threadCount: 10
#线程的优先级别，最小为1，最大为10
org.quartz.threadPool.threadPriority: 5
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread: true

org.quartz.jobStore.misfireThreshold: 60000

org.quartz.jobStore.class: org.quartz.simpl.RAMJobStore
<br><br>Quartz监听器用于当任务调动中你所关注的事情发生时，能够及时获得这一事件的通知，类似于任务执行过程中的邮件、短信类的梯形。Quartz监听器主要有JobListener、TriggerListener、SchedulerListtener三种，顾名思义，分别表示任务、触发器、调度器对应的监听器。监听器分为两种：全局监听器和非全局监听器。
全局监听器能够接收到所有的job/trigger的事件通知，而非全局监听器只能接收到在其上注册的Job或Trigger的事件，不在其上注册的Job或Trigger则不会进行监听。<br><br>JobListeners接收与作业相关的事件。<br>
<br>
getName方法：用于获取该JobListener的名称

<br>
jobToBeExecuted方法：Scheduler在JobDetail中将要被执行时调用这个方法。

<br>
jobExecutionVetoed方法：Scheduler在JobDetail即将被执行，但是又被TriggerListener否决时调用该方法。

<br>
jobWasExecuted方法：Scheduler在jobDetail被执行之后调用这个方法

<br>
创建监听器
public class MyJobListener implements JobListener {
    @Override
    public String getName() {
        return MyJobListener.class.getName();
    }

    @Override
    public void jobToBeExecuted(JobExecutionContext jobExecutionContext) {
        System.out.println("Job即将要被执行" );
    }

    @Override
    public void jobExecutionVetoed(JobExecutionContext jobExecutionContext) {
        System.out.println("Job即将要被执行，但又被否决" );

    }

    @Override
    public void jobWasExecuted(JobExecutionContext jobExecutionContext, JobExecutionException e) {
        System.out.println("Job已经执行结束" );
    }
}



<br>
注册测试

<br>public class Myjob implements Job {
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("hello:" + LocalTime.now().toString());
    }
    public static void main(String[] args) throws SchedulerException {


        Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();
        JobDetail job = JobBuilder.newJob(Myjob.class)
                .withIdentity("myjob","group1")
                .build();
        Trigger trigger = TriggerBuilder.newTrigger()
                .withIdentity("trigger","group1")
                .startNow()
                .withSchedule(SimpleScheduleBuilder.simpleSchedule()
                        .withIntervalInSeconds(1)
                        .withRepeatCount(3))
                .build();
        scheduler.scheduleJob(job,trigger);
         //注册全局的Job监听器
//        scheduler.getListenerManager().addJobListener(new MyJobListener(), EverythingMatcher.allJobs());
        //注册局部的Job监听器
        scheduler.getListenerManager().addJobListener(new MyJobListener(), KeyMatcher.keyEquals(JobKey.jobKey("myjob","group1")));

        scheduler.start();

    }
}
<br><br>TriggerListeners接收与触发器相关的事件<br>
<br>
方法说明

<br>getName：用于获取该JobListener的名称
<br>triggerFired：当与监听器相关联的trigger被触发，Job上的execute()方法将被执行时，Scheduler就会调用此方法
<br>vetoJobExecution：在Trigger触发后，Job将要被执行时由Scheduler调用此方法。TriggerListener给了一个选择否决Job的权利。如果这个方法返回true，这个Job将不会为此次Trigger触发。
<br>triggerMisfired：在Trigger错过触发时调用。避免在这个方法中执行持续时间长的逻辑处理，印在在出现许多错过触发的Trigger时，长逻辑会导致骨牌效应。
<br>triggerComplete：Trigger被触发并且完成Job的执行，Scheduler调用此方法


<br>
创建监听器
//监听器
public class MyTriggerListener implements TriggerListener {
    @Override
    public String getName() {
        return this.getClass().getName();
    }

    @Override
    public void triggerFired(Trigger trigger, JobExecutionContext jobExecutionContext) {
        System.out.println("任务即将被执行");
    }

    @Override
    public boolean vetoJobExecution(Trigger trigger, JobExecutionContext jobExecutionContext) {
        System.out.println("行驶否决权：" + trigger.getKey().getName());
        return false;
    }

    @Override
    public void triggerMisfired(Trigger trigger) {
        System.out.println("触发器错过执行：" + trigger.getKey().getName());
    }

    @Override
    public void triggerComplete(Trigger trigger, JobExecutionContext jobExecutionContext, Trigger.CompletedExecutionInstruction completedExecutionInstruction) {
        System.out.println("触发器执行完毕：" + trigger.getKey().getName());
    }
}


<br>
注册测试
public class Myjob implements Job {
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("hello:" + LocalTime.now().toString());
    }
    public static void main(String[] args) throws SchedulerException {


        Scheduler scheduler = StdSchedulerFactory.getDefaultScheduler();
        JobDetail job = JobBuilder.newJob(Myjob.class)
                .withIdentity("myjob","group1")
                .build();
        Trigger trigger = TriggerBuilder.newTrigger()
                .withIdentity("trigger","group1")
                .startNow()
                .withSchedule(SimpleScheduleBuilder.simpleSchedule()
                        .withIntervalInSeconds(1)
                        .withRepeatCount(3))
                .build();
        scheduler.scheduleJob(job,trigger);
        //注册全局
//        scheduler.getListenerManager().addTriggerListener(new MyTriggerListener(),EverythingMatcher.allTriggers());
        //注册局部
        scheduler.getListenerManager().addTriggerListener(new MyTriggerListener()
                ,KeyMatcher.keyEquals(TriggerKey.triggerKey("trigger","group1")));
        scheduler.start();

    }
}



<br><br><br>&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>
<br>
实现Job接口

<br>
继承QuartzJobBean
//=============实现Job接口==============
public class SimpleHelloJob implements Job {
    @Autowired
    BusinessService jobService;
    @Override
    public void execute(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("hello," + LocalTime.now().toString()
                + "," + jobExecutionContext.getJobDetail());
        jobService.doSomething();
    }
}

//=============继承QuartzJobBean===========
public class SimpleQuartzBean extends QuartzJobBean {

    @Autowired
    BusinessService businessService;
    @Override
    protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("==QuartzJobBean==" + jobExecutionContext.getJobDetail());
        businessService.doSomething();
    }
}


<br><br>@Configuration
public class QuartzConfig {
    @Bean
    public JobDetail myJobDetail(){
        JobDetail jobDetail = JobBuilder.newJob(SimpleQuartzBean.class)
                .withIdentity("myJob1","myJobGroup1")
                //JobDataMap可以给任务execute传递参数
                .usingJobData("job_param","job_param1")
                .storeDurably()
                .build();
        return jobDetail;
    }
    @Bean
    public Trigger myTrigger(){
        Trigger trigger = TriggerBuilder.newTrigger()
                .forJob(myJobDetail())
                .withIdentity("myTrigger1","myTriggerGroup1")
                .usingJobData("job_trigger_param","job_trigger_param1")
                .startNow()
                .withSchedule(CronScheduleBuilder.cronSchedule("0/2 * * * * ? 2021"))
                .build();
        return trigger;
    }
}
<br><br>
<br>RAMJobStore ：RAM也就是内存，默认情况下Quartz会将任务调度存在内存中，这种方式性能是最好的，因为内存的速度是最快的。不好的地方就是数据缺乏持久性，但程序崩溃或者重新发布的时候，所有运行信息都会丢失
<br>JDBC作业存储：存到数据库之后，可以做单点也可以做集群，当任务多了之后，可以统一进行管理。关闭或者重启服务器，运行的信息都不会丢失。缺点就是运行速度快慢取决于连接数据库的快慢。
<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;!--       一定要使用springboot的start依赖，
		否则需要自己配置SchedulerFactoryBean等  
		添加此依赖后，会启动自动配置  QuartzAutoConfiguration
--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;!--        mybatis以及mysql相关 ： 一定要添加--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;version&gt;6.0.6&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;2.1.4&lt;/version&gt;
&lt;/dependency&gt;
<br><br>sql语句位置：jar包位置<br><img alt="image-20240219134118015" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/02sql%E8%AF%AD%E5%8F%A5%E4%BD%8D%E7%BD%AE" referrerpolicy="no-referrer"><br><br>server:
  port: 8080
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/quartz?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
  quartz:
    job-store-type: jdbc  #设置保存到JDBC中※※※※※※※※※※※

mybatis:
  type-aliases-package: wanho.boot14.job.entity,wanho.boot14.job.vo
  mapper-locations: classpath:mapper/*.xml
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
pagehelper:
  helper-dialect: mysql
<br><br>名字不要修改（默认查找名字）<br>#在集群中每个实例都必须有一个唯一的instanceId，但是应该有一个相同的instanceName
org.quartz.scheduler.instanceName=bootScheduler
org.quartz.scheduler.instanceId=AUTO
#是否跳过Quartz版本更新检查。如果检查并且找到更新，
# 则会在Quartz的日志中报告它。生产部署要禁止
org.quartz.scheduler.skipUpdateCheck=false

#线程池的配置
#SimpleThreadPool这个线程池只是简单地在它的池中保持固定数量的线程，
# 不增长也不缩小。但是它非常健壮且经过良好的测试，差不多每个Quartz用户都使用这个池
org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool
#最大线程数，意味着最多有多少个job可以同时执行
org.quartz.threadPool.threadCount=20
#线程优先级
org.quartz.threadPool.threadPriority=5
#线程上下文类加载器是否继承自初始线程的加载器
org.quartz.threadPool.threadsInheritContextClassLoaderOfInitializingThread=true

#集群配置
org.quartz.jobStore.isClustered=false
#org.quartz.jobStore.clusterCheckinInterval=15000
#org.quartz.jobStore.maxMisfiresToHandleAtATime=1
#org.quartz.jobStore.txIsolationLevelSerializable=true

#由quartz管理自己的事务
#org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX
org.quartz.jobStore.acquireTriggersWithinLock=true
#超过这个时间还未触发的trigger，就被认为发生了misfire，默认60s。
# job成功触发叫fire，misfire就是未成功触发。
org.quartz.jobStore.misfireThreshold=12000
#JDBC代理类
org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate
#数据库表前缀QRTZ_
org.quartz.jobStore.tablePrefix=qrtz_
<br><br>public class PrintJob extends QuartzJobBean {
    @Override
    protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException {
        System.out.println("hello.quartz..........");
    }
}

<br><br>@RestController
public class JobController {
    @Autowired
    private Scheduler scheduler;

    @RequestMapping(value = "/index", method = RequestMethod.GET)
    public void index() throws SchedulerException {
        //cron表达式
        CronScheduleBuilder cronScheduleBuilder = CronScheduleBuilder.cronSchedule("0/8 * * * * ?");
        //根据name 和group获取当前trgger 的身份
        TriggerKey triggerKey = TriggerKey.triggerKey("cj", "123");
        CronTrigger triggerOld = null;
        try {
            //获取 触发器的信息
            triggerOld = (CronTrigger) scheduler.getTrigger(triggerKey);
        } catch (SchedulerException e) {
            e.printStackTrace();
        }
        if (triggerOld == null) {
            //将job加入到jobDetail中
            JobDetail jobDetail = JobBuilder.newJob(PrintJob.class).withIdentity("cj", "123").build();
            Trigger trigger = TriggerBuilder.newTrigger().withIdentity("cj","123").withSchedule(cronScheduleBuilder).build();
            //执行任务
            scheduler.scheduleJob(jobDetail, trigger);
        } else {
            System.out.println("当前job已存在--------------------------------------------");
        }
    }


    //未测试
    @PostMapping("/removeJob")
    public void removeJob(String jobName,String jobGroupName,String triggerGroupName) {
        TriggerKey triggerKey = TriggerKey.triggerKey(
                jobName, triggerGroupName);
        JobKey jobKey = JobKey.jobKey(jobName, jobGroupName);
        try {

            Trigger trigger = (Trigger) scheduler.getTrigger(triggerKey);
            if (trigger == null) {
                return;
            }
            scheduler.pauseTrigger(triggerKey);;// 停止触发器
            scheduler.unscheduleJob(triggerKey);// 移除触发器
            scheduler.deleteJob(jobKey);// 删除任务
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }

}
<br><br><br>Spring中使用Spring task的方式，可以参考https://www.cnblogs.com/qlqwjy/p/9960706.html<br>Springboot2.0使用Task的方式：<br>
<br>
创建Task类
@Component
public class HelloTask {
    //fixedRate： 上一次 启动时间点之后 X秒执行一次
    //fixedDelay： 上一次 结束时间点之后 每X秒执行一次
    //initialDelay： 第一次延迟 X秒执行，之后按照fixedRate的规则每X秒执行
    @Scheduled(cron = "0/2 * * * * ?")
    public void hello(){
        System.out.println("Hello," + LocalTime.now().toString());
    }
}


<br>
修改主类，增加注解@EnableScheduling
@SpringBootApplication
@EnableScheduling
public class SpringtaskApplication {
    public static void main(String[] args) {
        SpringApplication.run(SpringtaskApplication.class, args);
    }

}


<br><br><br>SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for `job_details`
-- ----------------------------
DROP TABLE IF EXISTS `job_details`;
CREATE TABLE `job_details` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '编号',
  `bean_name` varchar(30) NOT NULL DEFAULT '0' COMMENT 'bean名称',
  `class_name` varchar(100) NOT NULL COMMENT '全类名',
  `method_name` varchar(30) NOT NULL COMMENT '方法名',
  `method_params` varchar(50) DEFAULT NULL COMMENT '方法参数',
  `cron_expression` varchar(20) NOT NULL COMMENT 'cron表达式',
  `remark` varchar(100) DEFAULT NULL COMMENT '备注',
  `create_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `is_deleted` tinyint(1) NOT NULL DEFAULT '0' COMMENT '逻辑删除(1:已删除，0:未删除)',
  PRIMARY KEY (`id`) USING BTREE
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC COMMENT='借款信息表';


<br><br><br>需要实现org.springframework.context.ApplicationContextAware接口<br>@Component
public class SpringContextUtils implements ApplicationContextAware {
    public  static ApplicationContext applicationContext;
    @Override
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
        this.applicationContext = applicationContext;
    }

    public static  Object getBean(String name) {
        return applicationContext.getBean(name);
    }

    public static  &lt;T&gt; T getBean(Class&lt;T&gt; type) {
        return applicationContext.getBean(type);
    }

    public static boolean containsBean(String name) {
        return applicationContext.containsBean(name);
    }
    public static boolean isSingleTon(String name) {
        return applicationContext.isSingleton(name);
    }
}

<br><br>@Configuration
public class JobConfiguration {
    @Bean("taskScheduler")
    public TaskScheduler taskScheduler(){
        ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler();
        taskScheduler.setRemoveOnCancelPolicy(true);
        taskScheduler.setThreadNamePrefix("schedulerThreadPool-");
        taskScheduler.setPoolSize(5);
        return taskScheduler;
    }
}
<br><br>import org.springframework.lang.Nullable;
import java.util.concurrent.ScheduledFuture;

public class ScheduledTask {
    @Nullable
    volatile ScheduledFuture&lt;?&gt; future;

    public void cancel() {
        ScheduledFuture&lt;?&gt; future = this.future;
        if (future != null) {
            future.cancel(true);
        }
    }
}
<br><br>import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.scheduling.TaskScheduler;
import org.springframework.scheduling.annotation.SchedulingConfigurer;
import org.springframework.scheduling.config.CronTask;
import org.springframework.scheduling.config.ScheduledTaskRegistrar;
import org.springframework.stereotype.Component;

import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

@Component
public class MySchedulerConfigurer implements SchedulingConfigurer {
    //存储定义任务，用于取消处理
    private final Map&lt;Runnable,ScheduledTask&gt; map = new ConcurrentHashMap&lt;&gt;();
    @Autowired
    TaskScheduler taskScheduler;
    @Override
    public void configureTasks(ScheduledTaskRegistrar registrar) {
        registrar.setScheduler(taskScheduler);

    }

    /**
     * 增加Job  Runnable
     * @param task
     * @param cronExpression
     */
    public void addCronTask(Runnable task,String cronExpression){
        CronTask cronTask = new CronTask(task,cronExpression);
        //重复的情况下如何处理
        this.map.put(task,scheduledCronTask(cronTask));
    }

    /**
     * 取消JOB任务
     * @param runnable
     */
    public void cancalCronTask(Runnable runnable) {
        //从列表当中移除
        ScheduledTask task = this.map.remove(runnable);
        if (task != null) {
            task.cancel();
        }
    }

    //组件定时任务对象
    private ScheduledTask scheduledCronTask(CronTask task){
        ScheduledTask scheduledTask = new ScheduledTask();
        scheduledTask.future = this.taskScheduler.schedule(task.getRunnable(),task.getTrigger());
        return scheduledTask;
    }
}


<br><br>//如何能从容器中获得对应的Job的Bean对象
// 通过SpringContextUtils获取bean的名称
package com.hyy.springtask2;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.util.StringUtils;

import java.lang.reflect.Method;
import java.util.Objects;

public class JobRunnable implements Runnable {
    private static final Logger logger = LoggerFactory.getLogger(JobRunnable.class);
    private String beanName;
    private String methodName;
    private String params;

    public JobRunnable(String beanName, String methodName) {
        this(beanName, methodName, null);
    }

    public JobRunnable(String beanName, String methodName, String params) {
        this.beanName = beanName;
        this.methodName = methodName;
        this.params = params;
    }

    @Override
    public void run() {
        logger.info("定时任务开始执行 - bean：{}，方法：{}，参数：{}", beanName, methodName, params);
        long startTime = System.currentTimeMillis();
        try {
            Object target = SpringContextUtils.getBean(beanName);
            Method method = null;
            
            if (StringUtils.isEmpty(params)) {
                method = target.getClass().getDeclaredMethod(methodName);
                method.setAccessible(true);
                method.invoke(target);
            } else {
                method = target.getClass().getDeclaredMethod(methodName, String.class);
                method.setAccessible(true);
                method.invoke(target, params);
            }

        } catch (Exception ex) {
            logger.error(String.format("定时任务执行异常 - bean：%s，方法：%s，参数：%s "
                    , beanName, methodName, params), ex);
        }
        long times = System.currentTimeMillis() - startTime;
        logger.info("定时任务执行结束 - bean：{}，方法：{}，参数：{}，耗时：{} 毫秒"
                , beanName, methodName, params, times);

    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;
        JobRunnable that = (JobRunnable) o;
        if (params == null) {
            return beanName.equals(that.beanName) &amp;&amp;
                    methodName.equals(that.methodName) &amp;&amp;
                    that.params == null;
        }

        return beanName.equals(that.beanName) &amp;&amp;
                methodName.equals(that.methodName) &amp;&amp;
                params.equals(that.params);
    }

    @Override
    public int hashCode() {
        if (params == null) {
            return Objects.hash(beanName, methodName);
        }

        return Objects.hash(beanName, methodName, params);
    }
}
<br><br>实现CommandLineRunner接口的对象，放入spring容器后，如果容器启动后，就开始执行此Runner的run方法<br>@Service
public class JobStartRunner implements CommandLineRunner {

    @Resource
    JobDetailMapper jobDetailMapper;

    @Autowired
    MySchedulerConfigurer mySchedulerConfigurer;

    @Override
    public void run(String... args) throws Exception {
        //从数据库读取实际的任务数据
        List&lt;JobDetail&gt; jobDetailList = jobDetailMapper.selectList(null);
        JobRunnable jobRunnable;
        for (JobDetail jobDetail : jobDetailList) {
            jobRunnable = new JobRunnable(jobDetail.getBeanName()
                        ,jobDetail.getBeanClassName()
                        ,jobDetail.getMethodName()
                        ,jobDetail.getArguments() )  ;
            mySchedulerConfigurer.addCronTask(jobRunnable,jobDetail.getCronexpression());
        }
    }
}
<br><br><br>@Component  //spring容器来管理
public class DemoTask1 {
    public void sayHello(){
        System.out.println("hello spring task");
    }
}
<br><br>-- ----------------------------
-- Records of job_details
-- ----------------------------
INSERT INTO `job_details` VALUES ('1', 'demoTask1', 'wanho.commons.job.DemoTask1', 'taskWithoutParam', null, '0/4 * * * * ?', '222', '2021-12-02 00:13:54', '2021-12-02 00:14:07', '0');
<br><br>@RestController
@RequestMapping("/admin/core/jobDetail")
public class JobDetailController {

    @Autowired
    MySchedulerConfigurer mySchedulerConfigurer;

    @Autowired
    IJobDetailService iJobDetailService;

    @GetMapping("/list")
    public AjaxResult getList(){
        List&lt;JobDetail&gt; list = iJobDetailService.list();
        return AjaxResult.ok("获取数据成功",list);
    }


    @DeleteMapping("/remove/{id}")
    public AjaxResult remove(@PathVariable  int  id){
        JobDetail jobDetail =iJobDetailService.getById(id);
        //取消（移除）Job
        JobRunnable jobRunnable = new JobRunnable(jobDetail.getBeanName()
                ,jobDetail.getBeanClassName()
                ,jobDetail.getMethodName(),jobDetail.getArguments());
        mySchedulerConfigurer.cancalCronTask(jobRunnable);

        //修改数据库
        iJobDetailService.removeById(id);
        return AjaxResult.ok("删除成功");

    }

    @PostMapping("/save")
    public AjaxResult save(@RequestBody JobDetail jobDetail){
        //先做beanName，beanClassName，Method的验证
        // 验证通过，保存数据，增加JOB
        // 验证不通过，直接会 bean内容不合理，请确认
        //保存数据
        boolean flag = iJobDetailService.save(jobDetail);
        //
        if (flag) {
            JobRunnable jobRunnable = new JobRunnable(jobDetail.getBeanName()
                    ,jobDetail.getBeanClassName()
                    ,jobDetail.getMethodName(),jobDetail.getArguments());
            mySchedulerConfigurer.addCronTask(jobRunnable,jobDetail.getCronexpression());
            return AjaxResult.ok("保存成功");
        }
        return AjaxResult.ok("保存失败");
    }

    @GetMapping("/get/{id}")
    public AjaxResult getById(@PathVariable  int  id){
        JobDetail jobDetail = iJobDetailService.getById(id);
        return AjaxResult.ok("获取数据",jobDetail);
    }

    @PutMapping("/update")
    public AjaxResult updateById(@RequestBody JobDetail jobDetail){
        //获取原有信息，先移除旧的JOB
        //增加新的JOB
        return AjaxResult.ok("更新成功");
    }

}
]]></description><link>教程\12、Quartz.html</link><guid isPermaLink="false">教程/12、Quartz.md</guid><pubDate>Mon, 19 Feb 2024 09:13:55 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240219133926721.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240219133926721.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[一、消息队列]]></title><description><![CDATA[ 
 <br><br><br>
<br>
消息Message
网络中的两台计算机或者两个通讯设备之间传递的数据。例如：文本、音乐、视频等内容。

<br>
队列 Queue
一种特殊的线性表。只允许在首部删除元素和在尾部增加元素（FIFO)

<br>
消息队列（Message Queue）
保存消息的队列。消息传输过程中的容器，具有存储消息的能力，提供生产、消费接口供外部调用做数据的存储和获取。

<br>找不到“/01.01.同步处理.png”。<br>找不到“/01.01.异步处理.png”。<br><br>耦合度高：每次加入新的需求，都要修改原来的代码<br>性能下降：调用者需要等待服务提供者响应，如果调用链过长，则响应时间等于每次调用的事件之和<br>资源浪费：调用链中的每条服务在等待响应中，不能释放请求占用的资源，高并发场景下会极度浪费系统资源<br>级联失败：如果服务提供者出现问题，所有调用方都会跟着出问题，迅速导致整个微服务群故障。<br><br>
<br>解耦（类似Spring的IOC）
允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。
<br>可恢复性
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。
<br>缓冲
有助于控制和优化数据流经过系统的速度， 解决生产消息和消费消息的处理速度不一致的情况。
<br>灵活性 &amp; 峰值处理能力（削峰）
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。
<br>异步通信
很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。
<br><br><br>一对一，消费者主动拉取数据，消息收到后消息清除。	<br>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后， queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。最典型的例子就是订单处理系统，多个订单处理器可以同时工作，但是对于一个特定的订单，只有其中一个订单处理器可以拿到该订单进行处理。<br><img alt="01.02.点对点消息" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171838497.png" referrerpolicy="no-referrer"><br><img alt="01.02.点对点消息" src="\C:\\Users\大海\AppData\Roaming\Typora\typora-user-images\image-20240219094015254.png" referrerpolicy="no-referrer"><br><br>一对多，消费者消费数据之后不会清除消息。
消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。有两种方式，一种是队列主动推送模式、一种是消费者主动拉取模式。<br><img alt="01.03.发布订阅模式" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/01.03.%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F.png" referrerpolicy="no-referrer"><br>主动推送方式：生产者一生产消息，就发送给费者。问题：1：要维护订阅的消费者   2：消费者消费能力问题。<br>消费者拉取方式：维持长轮询，不停地访问是否有新的数据。问题：维持长轮询，即使没有数据，也要不停地询问。<br><br>
<br>
RabbitMQ 支持多协议AMQP、XMPP、SMTP、STOMP。支持负载均衡，数据持久化。同时支持Peer-to-Peer和发布/订阅。可靠性和稳定性

<br>
Redis基于key-value对的NoSQL数据库，通知支持MQ功能，可做轻量级队列服务使用。就入队而言，Redis对短消息（小于10kb）的性能比RabbitMQ好，长消息性能比RabblitMQ差。

<br>
Zoom 轻量级，不需要单独的消息服务器或中间件，应用本身扮演该角色，Peer-to-Peer。它本质上是一个库，需要开发人员自己组合多种技术，使用复杂度高。

<br>
ActiveMQ JMS实现，Peer-to-Peer，支持持久化、XA（分布式）事务

<br>
Kafka 高性能跨语言的分布式发布/订阅信息系统，数据持久化、全分布式，同时支持在线和离线处理。

<br>
MetaQ/RocketMQ 纯java实现，发布/订阅信息系统，支持本地事务和XA分布式事务。
<img alt="image-20240219094422411" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97" referrerpolicy="no-referrer">

<br><br>
<br>
任务异步处理
将不需要同步处理的并且耗时长的操作由消息队列通知消息接收方进行异步处理。提高应用程序的响应时间。

<br>
应用程序解耦合
MQ相当于一个中介，生产方通过MQ与消费方交互，它将应用程序进行解耦合。

<br><br><br>
AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。
<br>AMQP是一套公开的消息队列协议，最早在2003年提出，它旨在从协议层定义消息通信数据的标准格式，为的就是解决MQ市场上协议不同意的问题。RabbitMQ就是遵循AMQP标准协议开发的MQ服务。<br><br>RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。<br>为什么使用RabbitMQ呢？<br>
<br>使用简单，功能强大。
<br>基于AMQP协议
<br>社区活跃，文档完善。
<br>高并发性能好，这主要得益于Erlang语言。
<br>Spring Boot默认已集成RabbitMQ
<br><br><br><br>docker search rabbitmq
<br><br>docker pull rabbitmq
<br><br><br>docker run -d --name rabbitmq \
	-p 5672:5672 -p 15672:15672 \
	-v `pwd`/data:/var/lib/rabbitmq \
	--hostname myRabbit \
	-e RABBITMQ_DEFAULT_VHOST=my_vhost  \
	-e RABBITMQ_DEFAULT_USER=admin -e \
	RABBITMQ_DEFAULT_PASS=admin rabbitmq
<br>-d 后台运行容器；
--name 指定容器名；
-p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）；
-v 映射目录或文件；
--hostname  主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）；
-e 指定环境变量；
（RABBITMQ_DEFAULT_VHOST：默认虚拟机名；
RABBITMQ_DEFAULT_USER：默认的用户名；
RABBITMQ_DEFAULT_PASS：默认用户名的密码）<br><br>默认用户名和密码都是guest<br>docker run -d --name rabbitmq 	\
      -p 5672:5672 -p 15672:15672   rabbitmq
<br><br>docker exec -it rabbitmq bash
rabbitmq-plugins enable rabbitmq_management
<br><br>http://192.168.33.10:15672
<br><br><br>
<br>创建/etc/yum.repos.d/rabbitmq.repo文件，内容如下
<br>[rabbitmq_erlang]
name=rabbitmq_erlang
baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearch
repo_gpgcheck=1
gpgcheck=1
enabled=1
# PackageCloud's repository key and RabbitMQ package signing key
gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey
       https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300

##
## RabbitMQ server
##

[rabbitmq_server]
name=rabbitmq_server
baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/$basearch
repo_gpgcheck=1
gpgcheck=1
enabled=1
# PackageCloud's repository key and RabbitMQ package signing key
gpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey
       https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300


[rabbitmq_erlang-source]
name=rabbitmq_erlang-source
baseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMS
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300

[rabbitmq_server-source]
name=rabbitmq_server-source
baseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/SRPMS
repo_gpgcheck=1
gpgcheck=0
enabled=1
gpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey
sslverify=1
sslcacert=/etc/pki/tls/certs/ca-bundle.crt
metadata_expire=300
<br><br>yum update -y
<br><br>yum install socat logrotate -y

yum -y install erlang

yum install erlang rabbitmq-server -y
<br><br>#启动服务
/sbin/service rabbitmq-server start
#查看状态
/sbin/service rabbitmq-server status
#停止服务
/sbin/service rabbitmq-server stop
<br><br>rabbitmq-plugins enable rabbitmq_management
<br><br>如果linux上安装了浏览器，可以通过guest/guest登录（只能本机）<br>在/etc/rabbitmq下创建rabbitmq.conf<br>/etc/rabbitmq/rabbitmq.conf<br>loopback_users = none
#如果无效，则使用下面增加用户的方式
<br>增加用户，并设置管理员权限<br>#增加用户
rabbitmqctl add_user admin admin
#设置权限
rabbitmqctl set_permissions -p / admin ".*" ".*" ".*"
#设置管理员
rabbitmqctl set_user_tags admin administrator
<br><br>输入可以访问，如果不行，则可能是插件没有安装，尝试运行一下命令后再访问<br>http://192.168.33.10:15672
<br><br><br><img alt="03.01.基本结构" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/03.01.%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84.png" referrerpolicy="no-referrer"><br>组成部分说明如下：<br>
<br>Broker：消息队列服务进程，此进程包括两个部分：Exchange和Queue。 
<br>Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过虑。 
<br>Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方。
<br>Producer：消息生产者，即生产方客户端，生产方客户端将消息发送到MQ。 
<br>Consumer：消息消费者，即消费方客户端，接收MQ转发的消息。
<br>队列，交换机和绑定（队列和交换机）统称为AMQP实体（AMQP entities）。<br>消息发布接收流程
1、生产者和Broker建立TCP连接。
2、生产者和Broker建立通道。
3、生产者通过通道消息发送给Broker，由Exchange将消息进行转发。
4、Exchange将消息转发到指定的Queue（队列）<br>接收消息
1、消费者和Broker建立TCP连接
2、消费者和Broker建立通道
3、消费者监听指定的Queue（队列）
4、当有消息到达Queue时Broker默认将消息推送给消费者。
5、消费者接收到消息。<br><br><br>import com.rabbitmq.client.Channel;
import com.rabbitmq.client.Connection;
import com.rabbitmq.client.ConnectionFactory;

public class Producer {
    //队列
    private static final String QUEUE = "helloworld";
    public static void main(String[] args) throws Exception {
        //通过连接工厂创建新的连接和mq建立连接
        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.33.10");
        connectionFactory.setPort(5672);//端口
        connectionFactory.setUsername("admin");
        connectionFactory.setPassword("admin");
        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq
        connectionFactory.setVirtualHost("/");

        Connection connection = null;
        Channel channel = null;
        //建立新连接
        connection = connectionFactory.newConnection();
        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成
        channel = connection.createChannel();
        //声明队列，如果队列在mq 中没有则要创建
        //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments
        /**
         * 参数明细
         * 1、queue 队列名称
         * 2、durable 是否持久化，如果持久化，mq重启后队列还在
         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建
         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）
         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间
         */
        channel.queueDeclare(QUEUE, true, false, false, null);
        //发送消息
        //参数：String exchange, String routingKey, BasicProperties props, byte[] body
        /**
         * 参数明细：
         * 1、exchange，交换机，如果不指定将使用mq的默认交换机（设置为""）
         * 2、routingKey，路由key，交换机根据路由key来将消息转发到指定的队列，如果使用默认交换机，routingKey设置为队列的名称
         * 3、props，消息的属性
         * 4、body，消息内容
         */
        //消息内容
        String message = "hello world";
        channel.basicPublish("", QUEUE, null, message.getBytes());
        System.out.println("send to mq " + message);
        //关闭连接，//先关闭通道
        channel.close();
        connection.close();

    }
}

<br><br>import com.rabbitmq.client.*;

import java.io.IOException;
import java.util.concurrent.TimeoutException;

public class Consumer {
    //队列
    private static final String QUEUE = "helloworld";

    public static void main(String[] args) throws IOException, TimeoutException {
        //通过连接工厂创建新的连接和mq建立连接
        ConnectionFactory connectionFactory = new ConnectionFactory();
        connectionFactory.setHost("192.168.33.10");
        connectionFactory.setPort(5672);//端口
        connectionFactory.setUsername("guest");
        connectionFactory.setPassword("guest");
        //设置虚拟机，一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq
        connectionFactory.setVirtualHost("/");

        //建立新连接
        Connection connection = connectionFactory.newConnection();
        //创建会话通道,生产者和mq服务所有通信都在channel通道中完成
        Channel channel = connection.createChannel();

        //监听队列
        //声明队列，如果队列在mq 中没有则要创建
        //参数：String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments
        /**
         * 参数明细
         * 1、queue 队列名称
         * 2、durable 是否持久化，如果持久化，mq重启后队列还在
         * 3、exclusive 是否独占连接，队列只允许在该连接中访问，如果connection连接关闭队列则自动删除,如果将此参数设置true可用于临时队列的创建
         * 4、autoDelete 自动删除，队列不再使用时是否自动删除此队列，如果将此参数和exclusive参数设置为true就可以实现临时队列（队列不用了就自动删除）
         * 5、arguments 参数，可以设置一个队列的扩展参数，比如：可设置存活时间
         */
        channel.queueDeclare(QUEUE,true,false,false,null);

        //实现消费方法
        DefaultConsumer defaultConsumer = new DefaultConsumer(channel){

            /**
             * 当接收到消息后此方法将被调用
             * @param consumerTag  消费者标签，用来标识消费者的，在监听队列时设置channel.basicConsume
             * @param envelope 信封，通过envelope
             * @param properties 消息属性
             * @param body 消息内容
             * @throws IOException
             */
            @Override
            public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException {
                //交换机
                String exchange = envelope.getExchange();
                //消息id，mq在channel中用来标识消息的id，可用于确认消息已接收
                long deliveryTag = envelope.getDeliveryTag();
                //消息内容
                String message= new String(body,"utf-8");
                System.out.println("receive message:"+message);
            }
        };

        //监听队列
        //参数：String queue, boolean autoAck, Consumer callback
        /**
         * 参数明细：
         * 1、queue 队列名称
         * 2、autoAck 自动回复，当消费者接收到消息后要告诉mq消息已接收，如果将此参数设置为tru表示会自动回复mq，如果设置为false要通过编程实现回复
         * 3、callback，消费方法，当消费者接收到消息要执行的方法
         */
        channel.basicConsume(QUEUE,true,defaultConsumer);

    }
}
<br><br><br>​		AMQP，即Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。Erlang中的实现有RabbitMQ等。<br>​		Spring AMQP是基于AMQP协议定义的一套API规范，提供了模板来放和接收消息。包含两个部分，其中spring-amqp是基础抽象，spring-rabbit是底层的默认实现。<br>特征<br>
<br>侦听器容器，用于异步处理入栈消息。
<br>用于发送和接收消息的RabbitTemplate
<br>RabbitAdmin用于自动声明队列，交换和绑定
<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br><br><br>@RestController
public class Producer {
    @Autowired
    RabbitTemplate rabbitTemplate;

    @RequestMapping("/simpleQueue")
    public String testSimpleQueue(){
        String queueName ="helloworld";
        String message = "hello,simple";
        rabbitTemplate.convertAndSend(queueName,message);
        return "success";
    }
}
<br><br>@Component
public class Consumer {
    @RabbitListener(queues = "helloworld")
    public  void  listenSimpleQueue(String msg) throws InterruptedException {
        System.out.println("接收的消息：" + msg);
    }
}
<br><br>rabbitmq支持以下集中工作模式：<br>​	workqueue：工作队列，不需要交换机，消息发送指定的某个队列当中去的，队列的消费者共同消费队列中的数据。<br>​	pub/sub ：发布订阅：扇形交换机<br>​	routing: 路由模式：直连交换机<br>​	topic:主题模式：主题交换机<br>​	rpc: rpc模式<br>交换机类型<br>​	Direct exchange（直连交换机）<br>​	Fanout exchange（扇型交换机）<br>​	Topic exchange（主题交换机）<br>​	Headers exchange（头交换机）<br><br><img alt="04.消息队列-workqueuel" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/04.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-workqueuel.png" referrerpolicy="no-referrer"><br>消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2,同时监听同一个队列,消息被消费?C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患,高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize,与同步锁的性能不一样) 保证一条消息只能被一个消费者使用)。队列中的数据过多时会被丢弃。提高消息处理的速度，避免消息的队列<br>应用场景:红包;大项目中的资源调度(任务分配系统不需知道哪一个任务执行系统在空闲,直接将任务扔到消息队列中,空闲的系统自动争抢)<br>
<br>
生产者
@RequestMapping("/workQueue")
public String testWorkQueue() throws InterruptedException {
    String queueName ="helloworld";
    String message = "hello,simple";
    for (int i=1;i&lt;50;i++){
        rabbitTemplate.convertAndSend(queueName,message + ",index:" + i);
        Thread.sleep(20);
    }

    return "success";
}


<br>
消费者
@RabbitListener(queues = "helloworld")
public  void  listenWorkQueue1(String msg) throws InterruptedException {
	System.out.println("消费者1接收消息：" + msg);
	Thread.sleep(20);
}

@RabbitListener(queues = "helloworld")
public  void  listenWorkQueue2(String msg) throws InterruptedException {
	System.out.println("消费者2接收消息：" + msg);
	Thread.sleep(50);
}


<br>
消息预取机制：当消息到达的时候，rabbitmq内部会预先取得消息，再后续再处理。
preFetch消息预取限制，可以控制消息的上限。
spring:
  rabbitmq:
    host: 192.168.33.10
    port: 5672
    virtual-host: /
    username: guest
    password: guest
    listener:
      simple:
        prefetch: 1


<br><br>交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的。<br>发布订阅模式交换机模型：<br>Direct exchange（直连交换机）<br>Fanout exchange（扇型交换机）<br>Topic exchange（主题交换机）<br>Headers exchange（头交换机）<br><img alt="04.消息队列-Publish-Subscribe" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/04.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-Publish-Subscribe.png" referrerpolicy="no-referrer"><br>X代表交换机rabbitMQ内部组件，erlang 消息产生者是代码完成，代码的执行效率不高，消息产生者将消息放入交换机,交换机发布订阅把消息发送到所有消息队列中,对应消息队列的消费者拿到消息进行消费。<br>应用场景：:邮件群发,群聊天,广播(广告)<br><br>生产者发送的消息，交换机会将消息路由到所有的队列中。<br>
<br>在消费者当中创建交换机，队列，并绑定交换机和队列。
<br>定义消费者方法
<br>定义生产者方法
<br>创建交换机，队列以及绑定代码<br>@Configuration
public class FanoutConfig {
    //声明交换机
    @Bean(name="fanoutExchange")
    public FanoutExchange fanoutExchange(){
        return new FanoutExchange("fanout.exchange");
    }

    //声明队列
    @Bean(name="fanoutQueue1")
    public Queue fanoutQueue1(){
        return new Queue("fanout.queue1");
    }

    @Bean
    public Binding bindingQueue1(@Qualifier("fanoutQueue1") Queue queue
            ,@Qualifier("fanoutExchange") FanoutExchange fanoutExchange) {
        return BindingBuilder.bind(queue).to(fanoutExchange);
    }

    //声明队列
    @Bean(name="fanoutQueue2")
    public Queue fanoutQueue2(){
        return new Queue("fanout.queue2");
    }
    @Bean
    public Binding bindingQueue2(@Qualifier("fanoutQueue2") Queue queue
            ,@Qualifier("fanoutExchange") FanoutExchange fanoutExchange) {
        return BindingBuilder.bind(queue).to(fanoutExchange);
    }
}

<br>消费者代码<br>@RabbitListener(queues = "fanout.queue1")
public  void  listenFanoutQueue1(String msg) throws InterruptedException {
	System.out.println("消费者1接收消息：" + msg);
	Thread.sleep(20);
}

@RabbitListener(queues = "fanout.queue2")
public  void  listenFanoutQueue2(String msg) throws InterruptedException {
	System.out.println("消费者2接收消息：" + msg);
	Thread.sleep(50);
}
<br>生产者代码<br>@RequestMapping("/fanoutQueue")
public String testFanoutQueue() throws InterruptedException {
	String exchange = "fanout.exchange";
	String message = "hello,simple";
	for (int i=1;i&lt;20;i++){
		//交换机，路由名，信息
		rabbitTemplate.convertAndSend(exchange,"",message);
		Thread.sleep(20);
	}
	return "fanoutQueue success";
}
<br><br>Direct Exchange：会将接收到的消息根据规则路由到指定的Queue，因此称为路由模式。<br>Routing模式要求队列在绑定交换机时要指定routingkey，消息会转发到符合routingkey的队列。<br>每一个Queue都与Exchange设置一个BindingKey
发布者发布消息时，指定消息的RoutingKey
Exchange将消息路由到BindingKey与消息RountingKey一致的队列。<br><img alt="04.消息队列-routing" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/04.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-routing.png" referrerpolicy="no-referrer"><br>消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;<br>业务场景：从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;<br>//科技 tec  ，艺术 art<br>消费者代码<br>@RabbitListener(bindings = @QueueBinding(
            value=@Queue(name = "direct.queue1"),
            exchange = @Exchange(name="direct.exchange",type = ExchangeTypes.DIRECT),
            key={"eat","jump"}
    ))
    public  void  listenRouteQueue1(String msg) throws InterruptedException {
        System.out.println("消费者1--Direct接收消息--eat：" + msg);
        Thread.sleep(20);
    }

    @RabbitListener(bindings = @QueueBinding(
            value=@Queue(name = "direct.queue2"),
            exchange = @Exchange(name="direct.exchange",type = ExchangeTypes.DIRECT),
            key={"jump"}
    ))
    public  void  listenRouteQueue2(String msg) throws InterruptedException {
        System.out.println("消费者1--Direct接收消息--jump：" + msg);
        Thread.sleep(20);
    }
<br>生产者代码<br>@RequestMapping("/routeQueue")
public String testRouteQueue() throws InterruptedException {
    String exchange = "direct.exchange";
    //交换机，路由名，信息
    rabbitTemplate.convertAndSend(exchange,"eat","...eat.....");
    rabbitTemplate.convertAndSend(exchange,"jump","...jump.....");

    return "routeQueue success";
}
<br><br>TopicExchange与DirectExchange类似，区别在于routingKey必须是多个单词的列表，并且以.分隔。<br>Queue与exchange指定的BindingKey时，可以使用通配符：<br>*：代指一个单词<br> ‘#’：代指零个或者多个单词 a.#.b  ==&gt;a.x.b    ,a.x.y.z.b<br><img alt="04.消息队列-topic" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/04.%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-topic.png" referrerpolicy="no-referrer"><br>消费者代码<br>@RabbitListener(bindings = @QueueBinding(
            value=@Queue(name = "topic.queue1"),
            exchange = @Exchange(name="topic.exchange",type = ExchangeTypes.TOPIC),
            key={"wanho.*"}
    ))
    public  void  listenTopicQueue1(String msg) throws InterruptedException {
        System.out.println("消费者1--topic接收消息--wanho：" + msg);
        Thread.sleep(20);
    }
    @RabbitListener(bindings = @QueueBinding(
            value=@Queue(name = "topic.queue2"),
            exchange = @Exchange(name="topic.exchange",type = ExchangeTypes.TOPIC),
            key={"*.news"}
    ))
    public  void  listenTopicQueue2(String msg) throws InterruptedException {
        System.out.println("消费者2--topic接收消息--news：" + msg);
        Thread.sleep(20);
    }
<br>生产者代码<br>@RequestMapping("/topicQueue")
public String testTopicQueue() throws InterruptedException {
    String exchange = "topic.exchange";
    //交换机，路由名，信息
    rabbitTemplate.convertAndSend(exchange,"wanho.news","wanho,hahaha");
    rabbitTemplate.convertAndSend(exchange,"weather.news","sunny");

    return "routeQueue success";
}
<br><br>header模式与routing不同的地方在于，header模式取消routingkey，使用header中的 key/value（键值对）匹配队列。<br>接收方<br>@RabbitListener(bindings = @QueueBinding(
            value=@Queue(name = "head.query1"),
            exchange = @Exchange(name="header.exchange",type = ExchangeTypes.HEADERS),
            key = {"sms"}
    ))
    public  void  listenHeadQueue1(byte[] bytes) throws InterruptedException {
    	System.out.println("消费者1--header接收消息--sms：" + new String(bytes));
    	Thread.sleep(20);
    }
<br>发送方<br>@RequestMapping("/headerQueue")
    public String testHeaderQueue() throws InterruptedException {
        String exchange = "header.exchange";
        MessageProperties messageProperties = new MessageProperties();
        messageProperties.setHeader("query","query1");
        //交换机，路由名，信息
        Message message = new Message("info".getBytes(),messageProperties);
        rabbitTemplate.convertAndSend(exchange,"",message);

        return "routeQueue success";
    }
<br><br><br>Spring对消息对象的处理是由org.springframework.amqp.support.converter.MessageConverter来处理的，默认实现是SimpleMessageConverter，基于JDK的ObjectOutputStream完成序列化。
如果要修改只需要定义一个MessageConverter类型的Bean即可。推荐用JSON方式序列化。<br><br>​      <br>在publisher服务声明MessageConverter<br>@Bean
public MessageConverter messageConverter(){
	return  new Jackson2JsonMessageConverter();
}
<br>发送代码<br>@RequestMapping("/objectQueue")
    public String testObjectQueue(){
        String queueName ="object.queue";
        Map&lt;String,String&gt; map = new HashMap&lt;&gt;();
        map.put("name","dola");
        map.put("age","5");
        rabbitTemplate.convertAndSend(queueName,map);
        return "success";
    }
<br><br>引入依赖和声明MessageConverter参考发送方<br>接收方代码：需要用和发送消息一致的类型接收。<br>@RabbitListener(queues = "helloworld")
public  void  listenWorkQueue2(Map&lt;String,String&gt; map) throws InterruptedException {
    System.out.println("name：" + map.get("name"));
    System.out.println("age：" + map.get("age"));
    Thread.sleep(50);
}
<br><br>存储型交换机和队列：RabbitMQ会将消息保存在磁盘，如果服务器再次启动，会从磁盘将数据读入内存。<br>非存储型交换机和队列：数据仅仅放在内存当中，当服务重启或者发生宕机之后，数据就会不存在。<br>持久化队列和交换机，是要牺牲一部分性能。<br><br>在创建队列时，使用map参数进行设置<br>x-message-ttl：超时参数，时间单位是毫秒<br>x-max-length:     队列中最多能存储的数量<br>==》死信<br><br>死信：这些信息没有被处理，直接被丢掉了。<br>​	消息过期<br>​	队列达到最大的长度<br>​	消息被拒绝（basicReject/basicNack），并且requeue=false<br>死信队列：用来处理死信的队列<br>用来处理死信的交换机称为死信交换机，用来处理死信的队列，称之为死信队列<br>创建一个普通队列  normalqueue（消费者罢工），队列设置过期时间以及长度，<br>​	当出现死信的时候，配置死信交换机以及队列<br><br>x-dead-letter-exchange： 配置死信交换机
x-dead-letter-routing-key：死信路由key<br><br>@Configuration
public class DeathConfig {

    @Bean("normal.exchange")
    public FanoutExchange normalExchange(){
        return new FanoutExchange("normal");
    }

    @Bean("normal.queue")
    public Queue normalQueue(){
        Map&lt;String,Object&gt; args = new HashMap&lt;&gt;();
        //超时
        args.put("x-message-ttl",3000);
        //最大长度
        args.put("x-max-length",5);
        //死信交换机(用死信交换机的名字--rabbitmq当中的名字)
        args.put("x-dead-letter-exchange","death");
        //设置死信队列的路由key
        //args.put("x-dead-letter-routing-key","tec");
        return new Queue("normal",true,false,false,args);
    }

    @Bean
    public Binding normalBinding(@Qualifier("normal.exchange")FanoutExchange fanoutExchange
            ,@Qualifier("normal.queue")Queue queue){
        return BindingBuilder.bind(queue).to(fanoutExchange);
    }


    //死信相关
    @Bean("death.exchange")
    public FanoutExchange deathExchange(){
        return new FanoutExchange("death");
    }

    @Bean("death.queue")
    public Queue DeathQueue(){
        return new Queue("death");
    }

    @Bean
    public Binding deathBinding(@Qualifier("death.exchange")FanoutExchange fanoutExchange
            ,@Qualifier("death.queue")Queue queue){
        return BindingBuilder.bind(queue).to(fanoutExchange);
    }
<br><br>默认情况下，都是自动确认，需要手工确认的情况下，需要配置<br><br><br>spring:
  rabbitmq:
    host: 192.168.33.10
    port: 5672
    virtual-host: /
    username: guest
    password: guest
    listener:
      direct:
        acknowledge-mode: manual #配置确认模式为手动确认
    publisher-confirm-type: correlated #生产者需要手工确认
<br><br>//定义一个特殊的属性对象
    RabbitTemplate.ConfirmCallback confirmCallback = new RabbitTemplate.ConfirmCallback() {
        @Override
        public void confirm(CorrelationData correlationData, boolean b, String s) {
            System.out.println("消息发送id：" +  correlationData.getId()  + "，发送状态：" +  b );
        }
    };

    @RequestMapping("/cfm")
    public String testCfm(){
        String message = "hello,死信消息";

        rabbitTemplate.setConfirmCallback(confirmCallback);
        CorrelationData correlationData = new CorrelationData();
        System.out.println("发送的id:" + correlationData.getId());
        rabbitTemplate.convertAndSend("normal","",message ,correlationData);

        return "cfg success";
    }
<br><br><br>spring:
  rabbitmq:
    host: 192.168.33.10
    port: 5672
    virtual-host: /
    username: guest
    password: guest
    listener:
      simple:
        prefetch: 2 #消息的预取限制
        acknowledge-mode: manual #手工确认
      direct:
        acknowledge-mode: manual  #手工确认
<br><br>@RabbitListener(queues = "normal")
    public void normalConsumer(Channel channel, Message message) throws IOException {
        System.out.println("正常消费者：" +message);
        long deliveryTag = message.getMessageProperties().getDeliveryTag();
        System.out.println("deliveryTag: " + deliveryTag);
        //消费者确认消息
        channel.basicAck(deliveryTag ,true);
        //拒绝消息,requeue为false，则变成死信
        //channel.basicReject(deliveryTag,false);
        //channel.basicReject(deliveryTag,true);
        //未确认消息重新入队
        //channel.basicRecover(true);
    }
<br><br><br>Direct exchange（直连交换机）<br>Fanout exchange（扇型交换机）<br>Topic exchange（主题交换机）<br>Headers exchange（头交换机）<br><br>Work queues<br>Publish/Subscribe<br>Routing <br>Topics <br>Header<br>RPC<br><br>默认情况下，生产者将消息发送到队列后，默认是存储在内存当中，这样可以将消息发送给消费者。即使是持久化队列，也会在内存当中留一个备份。当需要释放内存的时候，将内存中的数据写入磁盘。<br>在某些特殊的情况，消息的生产和消费不是同一时间的场合下，可以设置惰性队列，无论队列是否是持久化，默认将数据写入磁盘，目的主要是为了减少内存的消耗。当需要消费消息的时候，再从磁盘读入内如。<br>拿时间换空间，可以部分解决消息堆积问题。<br>map.put("x-queue-mode","lazy")
<br><br>业务：注册用户，给用户发送邮件，用户在邮件中点击链接，确认登录（修改状态位），如果超过24小时不确认，则删除此用户。<br>​	解决方案：<br>​				 注册时，发送一条消息（用来发送邮件），邮件确认后，修改状态<br>​							超时24未确认：<br>​									采用消息队列，使用扇形交换机，同时发送两个队列，一个用来处理邮件，一个作为延时队列（设置消息的有效时间），此队列没有消费者，指定另外的死信交换机，死信交换机的消费者，根据状态，确定是否要删除用户（未确认，则删除）。使用直连交换机，两条消息，一条用来发送邮件，一个用来处理过期。<br>​									定时任务：查询数据库，到目前位置，注册时间已经到24小时，但是用户状态依旧是未确认的，将这些数据直接删除掉。<br>​	解决方案2：注册完（写入数据库） --直接发送邮件，通过rabbitmq发送一条消息（用来确认用户是否注册），此消息没有消费者，而是在超时之后，直接转入死信队列，由死信消费者来进行处理。<br>​	<br>美团，饿了么订单，用户生成订单后(未付款)，付款后状态发生变化，超过15分钟未付款，则删除订单。<br>​	解决：生成订单时，直接通过消息队列发送一条消息（15分钟），消息没有对应的消费，转入死信队列，消费者（死信）获取到信息，判断数据状态位，如果为未付款，则删除此订单。<br>目的：练习rabbitmq收发消息，同时要查阅官网，学习如何发送邮件<br>1：编写一个注册页面<br>​	用户名，密码，电话，邮件地址  （存入数据库，默认状态为0--未确认）<br>   注册处理：<br>​	写入数据库<br>​	并且将用户的信息，通过rabbitmq发送到指定的队列当中<br>2：rabbitmq的消费者<br>​	从队列当中拿到用户信息（用户名，邮箱）<br>​	向指定邮箱发送邮件，邮件中带有用户信息，当用户点击连接的时候，要将数据库当中的状态从0（未确认状态）--1(已确认)<br>3：超时删除<br>​	如果用户注册后超过24小时未确认，则删除表中的用户信息]]></description><link>教程\13、rabbitMQ.html</link><guid isPermaLink="false">教程/13、rabbitMQ.md</guid><pubDate>Mon, 19 Feb 2024 02:12:57 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171838497.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308171838497.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Nginx 基础]]></title><description><![CDATA[ 
 <br><br>yaml<br>(x)njcb1234
<br><br><br><br>一个域名一定会被解析为一个或多个 ip，一般包含两步：<br>
<br>
本地域名解析
浏览器会首先在本机的 hosts 文件中查找域名映射的 IP 地址，如果找到就返回 IP，没找到则进行域名服务器解析，一般本地解析都会失败，因为默认这个文件是空的。
Windows 下的 hosts 文件地址：C:/windows/system 32/drivers/etc/hosts
Linux 下的 hosts 文件所在路径： /etc/hosts

<br>
域名服务器解析
本地解析失败，才会进行域名服务器解析，域名服务器就是网络中的一台计算机，里面记录了所有注册备案的域名和 IP 映射关系，一般只要域名是正确的，并且备案通过，一定能找到。

<br><br>是一个 WEB 服务器，是一个高性能的反向代理的服务器、还是一个负载均衡服务器，同时还可以实现动静分离。<br>特点：在高并发和处理静态资源上相对于 tomcat 有更多优势.<br>
<br>
什么是反向代理

<br>
正向代理：客户端先进行代理服务器的设置，客户端发送请求到代理服务器，代理服务器将请求转发至原始服务器。代理服务器所代理的对象是很多个客户端。

<br>
反向代理：对于客户而言反向代理就像原始服务器, 客户不需要作任何设置，客户端发送请求，直接发送到代理服务器，代理服务器判断向何处转发请求, 并将获得的内容返回给客户端。反向代理是对多个服务器进行代理



<br>
什么是负载均衡
可以按照调度规则实现动态、静态页面分离，可以按照轮询、ip 哈希、权重等多种方式实现将请求平均分配到后端服务器上

<br><br><br>Docker pull nginx<br><br>
<br>
docker run -d --name mynginx 1 -p 80:80 nginx bash

<br>
配置文件在/etc/nginx/nginx. Conf, 默认没有 vi 命令

<br>
拷贝 nginx 目录到宿主机：

<br>
docker cp mynginx 1:/etc/nginx   /opt/nginx

<br>
docker cp mynginx 1:/usr/share/nginx/html  /usr/share/nginx/html



<br>
删除容器：docker stop mynginx 1--》docker rm mynginx 1

<br>
启动容器并添加数据卷：

<br>
docker run  -v  /opt/data/nginx:/etc/nginx   -di --name mynginx  -p 80:80 nginx
​		  

<br><br>
<br>
安装 yum 仓库 yum-utils
#可以不执行，当出现版本问题时，再进行更新
sudo yum install yum-utils -y


<br>
创建/etc/yum. Repos. D/nginx. Repo 文件，
vi /etc/yum.repos.d/nginx.repo

内容如下
[nginx-stable]
name=nginx stable repo
baseurl=http://nginx.org/packages/centos/$releasever/$basearch/
gpgcheck=1
enabled=1
gpgkey=https://nginx.org/keys/nginx_signing.key
module_hotfixes=true

#[nginx-mainline]
#name=nginx mainline repo
#baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/
#gpgcheck=1
#enabled=0
#gpgkey=https://nginx.org/keys/nginx_signing.key
#module_hotfixes=true

Nginx-stable: 稳定版的信息。一般情况下使用此版本
Nginx-mainline：主力版本（或开发版本），如果想要安装此版本，可以先使用如下命令，再安装
使用 stable 版本，下面这句话不要执行
#使用stable版本，下面这句话不要执行
sudo yum-config-manager --enable nginx-mainline


<br>
安装
sudo yum install nginx -y


<br>
启动测试
nginx


<br>
在 windows 主机上输入 <a rel="noopener nofollow" class="external-link" href="http://192.168.33.10" target="_blank">http://192.168.33.10</a>

<br>
其它命令
#停止
nginx  -s  stop
#重启
nginx -s reopen
#检查是否有语法错误
nginx -t
#重新加载
nginx  -s  reload
#查看版本
nginx  -V  或nginx -v
#查看80端口的程序
netstat –ano | grep 80
#卸载Nginx
yum remove nginx


<br>关闭防火墙 (需要重启)：chkconfig  iptables off<br>卸载步骤：<br>卸载时
1：先停止nginx服务 nginx -s stop
2：查找nginx目录文件：find / -name nginx
3: 依次删除找到的目录：rm -rf /usr/sbin/nginx
4：使用yum清除 yum remove nginx
<br>其它 Linux 版本的安装请参考以下文档：<br><a rel="noopener nofollow" class="external-link" href="http://nginx.org/en/linux_packages.html#RHEL-CentOS" target="_blank">http://nginx.org/en/linux_packages.html#RHEL-CentOS</a><br><br>/etc/nginx  <br>主配置文件 ngixn. Conf<br>每个服务器配置的 conf. D 目录下<br>主启动页：/usr/share/nginx/html<br><br><br>​		nginx 是一个多进程/多线程高性能 web 服务器，在 linux 系统中，nginx 启动后会以后台守护进程（daemon）的方式去运行，后台进程包含一个 master 进程和多个 worker 进程（可以通过在 nginx. Conf 配置文件中配置 worker_processes 参数设置），可以充分利用多核架构。<br> 		Nginx 默认的工作模式是以多进程的方式来工作的，nginx 也是支持多线程的方式的，只是我们主流的方式还是多进程的方式。Nginx 在启动之后会有一个 master 进程和多个 worker 进程（默认是一个），多个 worker 子进程将监听同一个端口，并行处理请求。Worker 进程数应该设置为等于 CPU 的核数，高流量并发场合也可以考虑将进程数提高至 CPU 核数 * 2。<br>​		master 主进程主要用来管理 worker 进程，主要作用是：读取并验正配置信息，管理真正提供服务的 worker 进程，向各 worker 进程发送信号，监控 worker 进程的运行状态，当 worker 进程退出后 (异常情况下)，会自动重新启动新的 worker 进程。Master 进程不会对用户请求提供服务，而用户的请求则是 worker 进程来响应的。<br>​		nginx 是通过信号来控制，比如关闭，重启等去控制 nginx 进程。Nginx 信号是属于 nginx 进程间的通信的一种机制，比如 master 主进程控制多个 worker 子进程，也是通过信号控制的，如下图。<br><img alt="image-20240221125546160" src="\C:\\Users\大海\AppData\Roaming\Typora\typora-user-images\image-20240221125546160.png" referrerpolicy="no-referrer"><br><br>信号控制语法<br>​	kill -信号选项 nginx 的主进程号<br>
<br>TERM，INT：快速关闭
<br>QUIT ：从容关闭（优雅的关闭进程, 即等请求结束后再关闭）
<br>HUP ：平滑重启，重新加载配置文件 （平滑重启，修改配置文件之后不用重启服务器。直接 kill -PUT 进程号即可）
<br>USR 1 ：重新读取日志文件，在切割日志时用途较大（停止写入老日志文件，打开新日志文件，之所以这样是因为老日志文件就算修改的文件名，由于 inode 的原因，nginx 还会一直往老的日志文件写入数据）
<br>USR 2 ：平滑升级可执行程序，nginx 升级时候用
<br>WINCH ：优雅的关闭旧的进程 (配合上 USR 2 来进行升级)
<br>#查找nginx .pid
Find / -name nginx. Pid
#查看nginx .pid 的进程 id ==》结果为 4851
Cat /var/run/nginx. Pid
#关闭nginx进程 （id 号为 4851，每次都不一样，会变化，需要查找）
#关闭后无法访问 ，需要重新启动
Kill -QUIT 4851
<br><br>找不到“/配置文件结构.png”。<br><img alt="配置文件结构" src="\C:\\Users\大海\AppData\Roaming\Typora\typora-user-images\image-20240221135134611.png" referrerpolicy="no-referrer"><br><br>Nginx 在运行时与具体业务功能（比如 http 服务或者 email 服务代理）无关的一些参数，比如工作进程数，运行的身份等。<br>## 指定 nginx 进程使用什么用户启动，默认是 nobody
user       www www ;  
#指定启动多少进程来处理请求 ，一般情况下设置成 CPU 的核数。默认为1
Worker_processes  4;  
#在高并发情况下 ，通过设置将 CPU 和具体的进程绑定来降低由于多核 CPU 切换造成的寄存器等现场重建带来的性能损耗。
#位数和进程数相关 。
#两个cpu内核开启两个进程
#worker_processes  2;  
#worker_processes  01 10；分别对应第一个 CPU 内核，第二个 CPU 内核  
worker_cpu_affinity 0001 0010 0100 1000;  #分别对应第一个CPU内核 ……第四个 CPU 内核 
# Error_log 是个主模块指令，用来定义全局错误日志文件。
#日志输出级别有debug 、info、notice、warn、error、crit 可供选择，其中，debug 输出日志最为最详细，而 crit 输出日志最少。
Error_log  logs/error. Log crit;
#指定进程pid文件的位置 。
Pid        logs/nginx. Pid;
#用于指定一个nginx进程可以打开的最多文件描述符数目 ，需要使用命令“ulimit -n 8192”来设置。
Worker_rlimit_nofile 8192;
<br><br>Events {
  #每一个worker进程能并发处理 （发起）的最大连接数（包含与客户端或后端被代理服务器间等所有连接数）。
  #默认是1024
  #进程的最大连接数受Linux系统进程的最大打开文件数限制 ，最大不能超过 worker_rlimit_nofile 的值
  Worker_connections  4096;  
  #use是个事件模块指令 ，用来指定 Nginx 的工作模式。
  #Nginx支持的工作模式有select 、poll、kqueue、epoll、rtsig 和/dev/poll。
  # 其中 select 和 poll 都是标准的工作模式，kqueue 和 epoll 是高效的工作模式，
  # 不同的是 epoll 用在 Linux 平台上，而 kqueue 用在 BSD 系统中。对于 Linux 系统，epoll 工作模式是首选。
  # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ;
  Use epoll;
}
<br><br>#include是个主模块指令 ，实现对配置文件所包含的文件的设定，可以减少主配置文件的复杂度。
#类似于Apache中的include方法 。
Include    conf/mime. Types;
Include    /etc/nginx/proxy. Conf;
Include    /etc/nginx/fastcgi. Conf;
#定义路径下默认访问的文件名
Index    index. Html index. Htm index. Php;
#default_type属于HTTP核心模块指令 ，这里设定默认类型为二进制流，也就是当文件类型未定义时使用这种方式。
#例如在没有配置PHP环境时 ，Nginx 是不予解析的，此时，用浏览器访问 PHP 文件就会出现下载窗口。
Default_type application/octet-stream;
<br><br>#服务器名字的hash表大小
Server_names_hash_bucket_size 128;
#用来指定来自客户端请求头的header buffer 大小。
Client_header_buffer_size 32 k; 
#用来指定客户端请求中较大的消息头的缓存最大数量和大小 ，4 为个数，128 k 为大小，最大缓存为 4 个 128 KB。
Large_client_header_buffers 4 128 k; 
#允许户端请求的最大单个文件字节数 。如果有上传较大文件，请设置它的限制值。
Client_max_body_size 10 m; 
#缓冲区代理缓冲用户端请求的最大字节数 。
Client_body_buffer_size 128 k; 
#高效文件传输模式 ，sendfile 指令指定 nginx 是否调用 sendfile 函数来输出文件，
#减少用户空间到内核空间的上下文切换 。对于普通应用设为 on，
# 如果用来进行下载等应用磁盘 IO 重负载应用，可设置为 off，以平衡磁盘与网络 I/O 处理速度，降低系统的负载。
# 开启 tcp_nopush on; 和 tcp_nodelay on; 防止网络阻塞。
Sendfile on ; 
Tcp_nopush on;
Tcp_nodelay on;
#长连接超时时间 ，单位是秒，65 s 内没上传完成会导致失败。
Keepalive_timeout 65 : 
#用于设置客户端请求主体读取超时时间 ，默认是 60 s。
Client_body_timeout 60 s;
#用于指定响应客户端的超时时间 。
Send_timeout 60 s;
<br><br>FastCGI 相关参数是为了改善网站的性能：减少资源占用，提高访问速度。<br>#指定连接到后端FastCGI的超时时间 。
Fastcgi_connect_timeout 300;  
#指定向FastCGI传送请求的超时时间 ，此值是已经完成两次握手后向 FastCGI 传送请求的超时时间。
Fastcgi_send_timeout 300;  
#指定接收FastCGI应答的超时时间 ，此值是已经完成两次握手后接收 FastCGI 应答的超时时间。
Fastcgi_read_timeout 300; 
#用于指定读取FastCGI应答第一部分需要多大的缓冲区 。
# 此值表示将使用 1 个 64 KB 的缓冲区读取应答的第一部分（应答头）
Fastcgi_buffer_size 64 k; 
# 指定本地需要用多少和多大的缓冲区来缓冲 FastCGI 的应答请求。
Fastcgi_buffers 4 64 k;  
#默认值是fastcgi_buffers的两倍 。
Fastcgi_busy_buffers_size 128 k;  
#表示在写入缓存文件时使用多大的数据块 ，默认值是 fastcgi_buffers 的两倍。
Fastcgi_temp_file_write_size 128 k;
#表示开启FastCGI缓存并为其指定一个名称 。开启缓存非常有用，可以有效降低 CPU 的负载，并且防止 502 错误的发生。
Fastcgi_cache TEST;  
#FastCGI缓存指定一个文件路径 、目录结构等级、关键字区域存储时间和非活动删除时间。
fastcgi_cache_path /usr/local/nginx/fastcgi_cache levels=1:2 keys_zone=TEST: 10 m inactive=5 m;  
#用来指定应答代码的缓存时间 。
#实例中的值表示将200和302应答缓存一个小时 。
Fastcgi_cache_valid 200 302 1 h;  
#将301应答缓存1天 ，其他应答均缓存 1 分钟。
Fastcgi_cache_valid 301 1 d;
#
Fastcgi_cache_valid any 1 m; 
<br><br>#开启gzip压缩输出
Gzip on;
#最小压缩文件大小 ，页面字节数从 header 头的 Content-Length 中获取。默认值为 0，不管多大页面都压缩，建议设置成大于 1 K 的字节数，小于 1 K 可能会越压越大。
Gzip_min_length 1 k;
#压缩缓冲区 ，表示申请四个 8 K 的内存作为压缩结果流缓存
#默认是申请与原始数据大小相同的内存空间来存储gzip压缩结果 。
Gzip_buffers    4 8 k;
#用于设置识别HTTP协议版本 ，默认是 1.1
#（默认 1.1，前端如果是 squid 2.5 请使用 1.0）
Gzip_http_version 1.1;
#压缩等级 ，1 压缩比最小，处理速度最快，9 压缩比最大，传输速度快，但是消耗 CPU 资源。
#范围1 ~9
Gzip_comp_level 5;
#压缩类型 ，默认已包含 text/html。
Gzip_types text/html text/plain text/css text/javascript application/json application/javascript application/x-javascript application/xml;
#和http头有关系 ，会在响应头加个 Vary: Accept-Encoding ，
# 可以让前端的缓存服务器缓存经过 gzip 压缩的页面，例如，用 Squid 缓存经过 Nginx 压缩的数据。
Gzip_vary on;
#Nginx作为反向代理的时候启用 ，决定开启或者关闭后端服务器返回的结果是否压缩，
#  匹配的前提是后端服务器必须要返回包含”Via”的 header 头。
#gzip_proxied any;
<br><br><br>1：拷贝一段完整的 server 段，并放入 http 标签内<br>2：更改 server_name 以及对应网页的 root 根目录<br>3：创建 server_name 对应网页的根目录，如果没有 index 首页会出现 404错误。<br>4：对客户端 server_name 的主机做 host 解析或 DNS 配置。<br>5：浏览器访问，或者在 Linux 客户端做 host 解析，用 wget 或 curl 访问。<br>Server {
         Listen 80;
         Server_name localhost;
         Index index. Html index. Htm;

         Location /emp {
         			#在/opt/project目录下存放各种html文件
                    Root /opt/project;
                    #默认的首页
                    Index index. Html index. Htm;
         }
   }

#浏览器中使用localhost/emp来访问对应的资源
<br>如果出现 502,503 错误，尝试临时关闭 SELinux 后再测试。<br>#临时关闭SELinux
Setenforce 0
永久关闭：
#输入命令 （需要重启服务器）
Vim /etc/selinux/config
#设置config文件中的SELINUX =enforcing 改为 SELINUX=disabled，然后退出保存。
<br>如果出现 403 错误，用以下方式解决<br>
<br>看 log，查看路径是否正确
<br>如果路径正确，则确认配置文件中用户是什么，修改和当前用户匹配（如果当前用户为 root，请也将用户改成 root）。
<br><br>Location 的语法规则有两种：前缀字符串（路径名）和正则表达式<br>
<br>前缀字符串
<br>#匹配以/some/path/开头的路径 ，如：/some/path/domt. Html
Location /some/path/ { }
<br>
<br>
正则表达式
正则表达式前加上“~”表示区分大小写，加上"~*"表示不区分大小写
※当使用插入符时“^~"则表示只匹配前缀字符串，不匹配正则表达式

<br>Location [=|~|~*|^~] /uri/ { … }**  <br>
<br>=     精确匹配，如果找到匹配=号的内容，立即停止搜索，并立即处理请求 (优先级最高)
<br>~     区分大小写
<br>~*  不区分大小写
<br>^~  只匹配字符串，不匹配正则表达式
<br>/    通用匹配，任何请求都会匹配到
<br>#匹配跟目录
Location =/ {
	
}
#各种图片格式结尾的 （正则匹配）
# ~ 区分大小写
# . 匹配除换行符之外的任何字符
# * 匹配 0 或多次
#\ 转义字符 \. 匹配点好（.)
Location ~ .*\. (gif|jpg|jpeg|png|bmp|icon)$ {
}
#将所有请求都交给
Location / {

}
<br><br><br>在 Web 开发中，通常来说，动态资源其实就是指那些后台资源，而静态资源就是指 HTML、JavaScript、CSS、img 等文件。<br>动静分离就是将动态资源和静态资源分开，将静态资源部署在 Nginx 上。当一个请求来的时候，如果是静态资源的请求，就直接到 nginx 配置的静态资源目录下面获取资源，如果是动态资源的请求，nginx 利用反向代理的原理，把请求转发给后台应用去处理，从而实现动静分离。<br>优点：<br>
<br>可以很大程度的提升静态资源的访问速度。
<br>前后端可以并行开发、有效地提高开发效率。
<br><br><br>编写一个带图片的 index. Html, 放置在/opt/project/emp 目录中。<br>图片 fruit 01. Jpg 放入/opt/project/static/img 目录中<br>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset="UTF-8"&gt;
&lt;title&gt;Insert title here&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
	&lt;form action=""&gt;
		用户：&lt;input name="user"&gt;&lt;br&gt;
		密码：&lt;input name="password"&gt;&lt;br&gt;
		&lt;input type="submit" value="登录"&gt;
		&lt;input type="reset" value="取消"&gt; 
	&lt;/form&gt; 
	&lt;img src="/static/img/fruit01.jpg" style="width:200px;height:200px"/&gt;
&lt;/body&gt;
&lt;/html&gt;
<br><br>思路：动、静态的文件，请求时匹配不同的目录<br>当访问 gif, jpeg 时直接访问/opt/project/static/目录下内容, 正则自行配置<br>User  root;
Worker_processes  1;

Error_log  /var/log/nginx/error. Log warn;
Pid        /var/run/nginx. Pid;

Events {
    Worker_connections  1024;
}

Http {
    Include       /etc/nginx/mime. Types;
    Default_type  application/octet-stream;

    Log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    Access_log  /var/log/nginx/access. Log  main;

    Sendfile        on;
    #tcp_nopush     on;
    Keepalive_timeout  65;
    #gzip  on;

   # include /etc/nginx/conf. D/*. Conf;
   Server {
        Listen 8100;
        Server_name localhost;
	    Location / {
		    Root /opt/project/emp;
		     Index index. Html index. Htm;
	     }
	 	
  	     # 所有静态图片请求都放到 static 目录下
	     Location ~ .*\. (jpg|jpeg|png)$ { 
      		Alias   /opt/project/static/;  
  	      }  
  	     Error_page   500 502 503 504  /50 x. Html;  
  		    Location = /50 x. Html {  
     		    root   e: wwwroot ;  
  	     }
    }
}
<br><br>图片能够正常加载<br>通过以下语句测试图片的正常加载 <br>curl -I http://localhost/static/img/fruit01.jpg
<br><img alt="动静分离图片验证" src=".\file:\\D:\\资料\我的笔记\02.Nginx\图例\动静分离图片验证.png" referrerpolicy="no-referrer"><br><br><br>
<br>代理：通过客户机的配置，实现让一台服务器代理客户机，客户的所有请求都交给代理服务器处理
<br>反向代理：用一台服务器，代理真实服务器，用户访问时，不是访问真实的服务器，而是访问代理服务器。
<br>Nginx 可以当作反向代理服务来使用时，我们需要提前在 Nginx 中配置好反向代理的规则，不同的请求，交给不同的真实服务器处理。当请求到达 nginx，nginx 会根据已经定义的规则进行请求的转发，从而实现路由功能。<br>安装在主机上<br>找不到“/反向代理1.jpg”。<br>安装在虚拟机上<br>找不到“/反向代理2.jpg”。<br><br><br>将/etc/nginx/conf. D 目录下的 default. Conf 拷贝一份，并命名成 my.Conf<br>#进入配置server的目录
Cd /etc/nginx/conf. D
#拷贝文件 （保留模板文件，防止被破坏）
Cp default. Conf  my. Conf
#打开my .conf 进行编辑
Vi  my. Conf
<br><br>使用 proxy_pass 来设置反向代理的服务器<br>
      1 server {
      2     listen       80;
      3     server_name  localhost;
      4
      5     #access_log  /var/log/nginx/host. Access. Log  main;
      6
      7     location / {
                #修改内容 ，注释掉 8，9 行，增加第 10 行数据
      8         #root   /usr/share/nginx/html;
      9         #index  index. Html index. Htm;
     10         proxy_pass  http://192.168.40.251:8080 ;
     11     }
     12  ....



<br><br>/etc/nginx/nginx. Conf 中的 http 节点中修改以下内容<br>	#修改内容
    #include /etc/nginx/conf. D/*. Conf;
    Include /etc/nginx/conf. D/my. Conf;

<br><br><br>Nginx 的负载均衡功能依赖于 ngx_http_upstream_module 模块，所支持的代理方式有 proxy_pass (一般用于反向代理). Fastcgi_pass (一般用于和动态程序交互），memcached_pass, proxy_next_upstream, fastcig_next_pass 以及 memcached_next_pass 。<br>Upstream 模块应该放于 http{}标签内。<br>Upstream dynamic {
    Zone upstream_dynamic 64 k;


    Server backend 1. Example. Com      weight=5;
    Server backend 2. Example. Com: 8080 fail_timeout=5 s slow_start=30 s;
    Server 192.0.2.1                 max_fails=3;
    Server backend 3. Example. Com      resolve;

    Server backup 1. Example. Com: 8080  backup;
    Server backup 2. Example. Com: 8080  backup;
    #通过该指令配置了每个worker进程与上游服务器可缓存的空闲连接的最大数量 。
    #当超出这个数量时 ，最近最少使用的连接将被关闭。Keepalive 指令不限制 worker 进程与上游服务器的总连接。
    Keepalive 100;
}

//案例
Upstream tc{
		#ip_hash ;
		server 192.168.4.91:80 weight=1 backup;
		server 192.168.4.91:8080 weight=3;
	}	
<br><br>proxy_pass http://tc ;
<br><br>轮询 (rr)：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器故障，故障系统自动清除，使用户访问不受影响。适用于多个服务器的性能相当的情况下，适用此策略。<br>轮询权值 (weight), weight 值越大，分配到的访问几率越高，主要用于后端每个服务器性能不均的情况。<br>Ip_hash，每个请求按访问 IP 的 hash 结果分配 (IP 地址的前三段)，这样来自同一个 IP 的固定访问一个后端服务器，主要解决动态网站 session 共享的问题。 192.168.40.Xxx<br>Url_hash，按照访问的 URL 的 hash 结果来分配请求，是每个 URL 定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率，nginx 本身不支持，如果想使用需要安装 nginx 的 hash 软件包。<br><br>Server IP 调度状态<br>Server 指令指定后端服务器 IP 地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。<br>
<br>Down  表示当前的 server 暂时不参与负载均衡。
<br>Backup 预留的备份服务器，当其他所有的非 backup 服务器出现故障或者忙的时候，才会请求 backup 机器，因为这台集群的压力最小。
<br>Max_fails 允许请求失败的次数，默认是 1，当超过最大次数时，返回 proxy_next_upstream 模块定义的错误。0 表示禁止失败尝试，企业场景：2-3. 京东 1 次，蓝汛 10 次，根据业务需求去配置。
<br>Fail_timeout，在经历了 max_fails 次失败后，暂停服务的时间。京东是 3 s，蓝汛是 3 s，根据业务需求配置。常规业务 2-3 秒合理。
<br><br><br><br><br>​      放入 vagrant 共享目录， vagrant reload 读取文件，通过 cp 命令 copy 到 opt 目录下<br><br>#nginx .conf
Http {
   .....
   Upstream tc {
      server  192.168.66.182:8080;
   }
   
   Include /etc/nginx/conf. D/my. Conf
}

#my .conf
Server {
    ....
    Location /{
       Root  /opt/dist;
       Index index. Html index. Htm;
    }
    Location /core {
       proxy_pass   http://tc ;
    }
}
<br><br><br>缺点：<br>
<br>分配不均匀。
<br>如果后端还作了其他负载均衡，就不能共享 session
<br><br>会话数据会存储在每个服务器上的堆内存中<br><br>
<br>
在每一个 tomcat 中添加集群缓存配置
在 tomcat 的 conf 中找到 server. Xml，在这一行下面添加下面内容：
&lt;Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster" channelSendOptions="8"&gt;
  &lt;Manager className="org. Apache. Catalina. Ha. Session. DeltaManager"
             ExpireSessionsOnShutdown="false"
             NotifyListenersOnReplication="true"/&gt;
  &lt;Channel className="org.apache.catalina.tribes.group.GroupChannel"&gt;
      &lt;Membership className="org. Apache. Catalina. Tribes. Membership. McastService"
            Address="228.0.0.4" port="45564" frequency="500" dropTime="3000"/&gt;
      &lt;Receiver className="org. Apache. Catalina. Tribes. Transport. Nio. NioReceiver"
  Address="auto" port="4000" autoBind="100" selectorTimeout="5000" maxThreads="6"/&gt;
    &lt;Sender className="org.apache.catalina.tribes.transport.ReplicationTransmitter"&gt;       &lt;Transport       className="org.apache.catalina.tribes.transport.nio.PooledParallelSender"/&gt;
    &lt;/Sender&gt;
     &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.TcpFailureDetector"/&gt;
     &lt;Interceptor className="org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor"/&gt;
    &lt;/Channel&gt;
    &lt;Valve className="org.apache.catalina.ha.tcp.ReplicationValve" filter=""/&gt;
    &lt;Valve className="org.apache.catalina.ha.session.JvmRouteBinderValve"/&gt;
    &lt;Deployer className="org. Apache. Catalina. Ha. Deploy. FarmWarDeployer"
        TempDir="/tmp/war-temp/" deployDir="/tmp/war-deploy/"
        WatchDir="/tmp/war-listen/" watchEnabled="false"/&gt;
    
    &lt;ClusterListener className="org.apache.catalina.ha.session.ClusterSessionListener"/&gt;
&lt;/Cluster&gt;


<br>
在每个项目的 web. Xml 中添加下面标签
&lt;distributable/&gt;


<br><br>
<br>因为每个服务器都存储一份 session，所以数据冗余
<br>如果某个服务器内存很小，可能无法存储。
<br><br>推荐使用 Spring do 方案，主流, 会话存储在远程的 redis 缓存中.<br><br>
<br>
客户端第一次发请求时，没有携带 sessionID，nginx 将请求分发给服务器 1 ，然后服务器 1 产生 session 0，spring 对 sesion 0 封装成 sesion 1，并根据 session 0 计算并更新 session 1 的 id, 然后放入 redis 中，并把 session 0 的原始 ID 回写到浏览器，这样服务器 1 和 redis 中都会有一个相同的 session1

<br>
当客户端发送第二次请求的时候，nginx 将请求分发给服务器 2 （无 session），因为请求中携带了一个 sessionID，那么服务器 2 就根据 sessionID 得出 session 1 的 id，用这个 id 去 redis 中获取 session。

<br><br>建两个 springboot 项目，内容如下，除了端口号不同<br>
<br>
两个项目的 pom 依赖
&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org. Springframework. Boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org. Springframework. Boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org. Springframework. Boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org. Springframework. Session&lt;/groupId&gt;
    &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;
    &lt;version&gt;2.0.4. RELEASE&lt;/version&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;


<br>
templates 目录添加 login. Html
    &lt;form action="/login" method="post"&gt;
        &lt;input name="username"&gt;&lt;br&gt;
        &lt;input type="submit"&gt;
    &lt;/form&gt;


<br>
templates 目录添加 success. Html
    &lt;html lang="en" xmlns:th="http://www.w3.org/1999/xhtml"&gt;
    &lt;h1&gt;this is session 1&lt;/h1&gt;
    &lt;span th:text="${session.username}"&gt;&lt;/span&gt;


<br>
yml 内容如下, 注意：另一项目端口为 8080
Server:
  Port: 80
Spring:
  Redis:
    Host: 127.0.0.1
    Port: 6379
    Jedis:
      Pool:
        Max-idle: 8


<br>
config 包下添加类
@Configuration
Public class MyConfig implements WebMvcConfigurer {
    Public void addViewControllers (ViewControllerRegistry registry) {
        Registry.AddViewController ("/showSuc"). SetViewName ("success");
        Registry.AddViewController ("/showLogin"). SetViewName ("login");
    }
}


<br>
controller 包中添加类
@Controller
Public class UserCtl {
@RequestMapping ("/login")
Public String hello (HttpSession session, String username){
    Session.SetAttribute ("username", username);
    //注意：这里的 session 已不是传统 session, 被重构成新的 session，存储在 redis 中
    System.Out.Println ("name: "+username+", sessionID："+session.GetId ());
    Return "success";
}
}


<br>
主类添加注解
//使用该注解，会重构 session, 参数为 session 存活时间
@EnableRedisHttpSession (maxInactiveIntervalInSeconds = 10000*30)
@SpringBootApplication
Public class SessionApp {
Public static void main (String[] args) {
    SpringApplication.Run (SessionApp. Class, args);
}
}


<br>
nginx 中

<br>
修改配置
Location / {
		Root   /opt/project/emp;
		Index  index. Html index. Htm;
		proxy_pass http://tc ;
}
Upstream tc{
    server 192.168.1.144:80;
  server 192.168.1.144:8080;
  }


<br>
重启 nginx


 /usr/local/nginx/sbin/nginx -s reload

<br>
启动 redis: redis-server redis. Conf

<br>
启动 80 和 8080 两个端口的项目

<br>
测试

<br>
浏览器输入 <a rel="noopener nofollow" class="external-link" href="http://192.168.184.100/login.html" target="_blank">http://192.168.184.100/login.html</a> ,输入用户名

<br>
<a rel="noopener nofollow" class="external-link" href="http://192.168.184.100/showSuc" target="_blank">http://192.168.184.100/showSuc</a> ，反复刷新观看



]]></description><link>教程\14、Nginx.html</link><guid isPermaLink="false">教程/14、Nginx.md</guid><pubDate>Wed, 21 Feb 2024 05:56:38 GMT</pubDate><enclosure url="\C:\\Users\大海\AppData\Roaming\Typora\typora-user-images\image-20240221125546160.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\C:\\Users\大海\AppData\Roaming\Typora\typora-user-images\image-20240221125546160.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[一、简介]]></title><description><![CDATA[ 
 <br><br><br>了解linux<br>修改虚拟机ip为静态：<br>
<br>vim /etc/sysconfig/network-scripts/ifcfg-ens33

<br>BOOTPROTO="static"
<br>IPADDR="192.168.146.101"
<br>NETMASK=255.255.255.0
<br>GATEWAY=192.168.146.2
<br>DNSI=192.168.146.2


<br>重启网络服务：systemctl restart network
<br><br>软件在windows上开发完成后，把jar或war包交给运维，运维部署到linux或阿里云时，可能会因为环境不同或配置不同，而导致不能正常工作。用docker就可能方便的解决该问题。<br><br>如果到宠物店只买回一条鱼，回家后可能因为环境不适应而死亡，而从宠物店买回的是带鱼缸和鱼这一整套环境就不会出问题。也就是从系统底层至上层整体打包成镜像文件，从而达到完全跨平台的到处运行。<br><br>Docker是一个精简版的虚拟机，只是少了对操作系统和硬件的虚拟，所以启动速度是秒级的,而虚拟机的启动则是分钟级的。<br>Docker是基于Go语言实现的云开源项目，Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。<br>Docker的主要目标是“build，Ship and Run Any App，Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。
将应用运行在Docker容器上面，而Docker容器在任何操作系统上一致的，这就是实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机器上就可以简化操作、一键部署。<br>找不到“/01.docker和虚拟机.png”。<br>找不到“/02.docker和虚拟机.png”。<br><br>docker三要素：镜像、容器、仓库<br>
<br>
镜像：相当于java中的类,如Person。应用程序和配置及依赖打包成一个可运行的环境，这个包就是镜像文件。

<br>
容器：相当于new Person产生对象,容器是以镜像为模板产生，可把容器看成镜像一个简化版的linux环境和若干运行在其中的应用程序。

<br>
仓库：是集中存放镜像的地方。

<br>
仓库注册服务器：放着多个仓库。

<br>找不到“/03.docker架构.jpg”。<br><br><br>#yum install -y yum-utils device-mapper-persistent-data lvm2
yum install -y device-mapper-persistent-data lvm2
<br>lvm2（LogicalVolume Manage，Version2），逻辑卷管理工具。它是Linux环境下对磁盘分区进行管理的一种机制，将一个或多个底层块设备组织成一个逻辑设备。通过LVM管理员可以轻松管理磁盘分区，使用LVM与传统的分区方法相比有很多的优势，如：容量的分配更加灵活、逻辑卷的扩展和缩减更加方便、使用snapshot（快照）来备份数据也非常方便。通过本文你可以快速了解LVM2的使用方法。<br><br>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
<br>如果安装出错，可以进入到  /etc/yum.repos.d目录下，将dockerxxx.repo相关的文件删除后，再次使用上述命令来指定镜像。<br><br>yum makecache fast   #为加快安装速度，对缓存加速
yum -y install docker-ce
<br>如果 /etc/ yum.repos.d/<br><br>docker version 或  docker --version<br>#简单的版本信息
docker --version
#详细的版本信息
docker version
<br><br>
<br>启动docker:   systemctl start docker
<br>重启:  systemctl restart docker
<br>卸载docker:   yum remove docker
<br>设置开机启动:  systemctl enable docker
<br><br>是一个代理仓库，放了一些镜像，因为中央仓库<a data-tooltip-position="top" aria-label="https://hub.docker.com%E6%98%AF%E5%9B%BD%E5%A4%96%E7%BD%91%E7%AB%99%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%85%A2%EF%BC%8C%E6%9C%89%E4%B8%A4%E4%B8%AA%E4%BA%91%E5%8F%AF%E7%94%A8%EF%BC%8C%E7%BD%91%E6%98%93%E4%BA%91%E5%92%8C%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%9B%B4%E5%85%A8%E9%9D%A2%EF%BC%8C%E5%85%B6%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps://www.aliyun.com/product/acr" rel="noopener nofollow" class="external-link" href="https://hub.docker.com%E6%98%AF%E5%9B%BD%E5%A4%96%E7%BD%91%E7%AB%99%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%85%A2%EF%BC%8C%E6%9C%89%E4%B8%A4%E4%B8%AA%E4%BA%91%E5%8F%AF%E7%94%A8%EF%BC%8C%E7%BD%91%E6%98%93%E4%BA%91%E5%92%8C%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%9B%B4%E5%85%A8%E9%9D%A2%EF%BC%8C%E5%85%B6%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps://www.aliyun.com/product/acr" target="_blank">https://hub.docker.com是国外网站，非常慢，有两个云可用，网易云和阿里云，推荐使用阿里云，更全面，其镜像地址：https://www.aliyun.com/product/acr</a><br>获取加速器地址的方法如下：<br>
<br>
注册--&gt;可使用淘宝帐号注册,搜索容器镜像服务

<br>
获取加速器地址：通过网址<a data-tooltip-position="top" aria-label="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors%E8%8E%B7%E5%8F%96" rel="noopener nofollow" class="external-link" href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors%E8%8E%B7%E5%8F%96" target="_blank">https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors获取</a>

<br>
配置加速器

<br>
mkdir /etc/docker

<br>
vi /etc/docker/daemon.json

<br>
内容如下：每个帐号都不同，使用下面一个也可以。
{
"registry-mirrors": ["https://c40fbq35.mirror.aliyuncs.com"]
}

<br>
使配置生效：systemctl daemon-reload，systemctl restart docker
#加载文件
systemctl daemon-reload
#重新启动
systemctl restart docker




<br>
helloworld镜像生成容器:docker run hello-world，默认先从本地的镜像中找，没找到就从阿里云中找其镜像并拉取。

<br><br><br>
<br>
docker info---查看docker的总体信息

<br>
docker help---查看docker有哪些命令

<br><br><br>​		镜像是一种轻量级的、可以执行的独立软件包，用来打包软件运行环境和基于运行环境的软件，她包含某个软件锁需要的所有内容，包括代码、运行时库、环境变量和配置文件。<br>​	    在 Docker 中，一个只读层被称为镜像，一个镜像是永久不会变的。由于 Docker 使用一个统一文件系统，Docker 进程认为整个文件系统是以读写方式挂载的。 但是所有的变更都发生顶层的可写层，而下层的原始的只读镜像文件并未变化。由于镜像不 可写，所以镜像是无状态的。<br><img style="zoom:50%;" alt="04.docker-filesystems-multilayer" src="\04.docker-filesystems-multilayer.png" referrerpolicy="no-referrer"><br>​		bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs，这一层和Linux、Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核都在内存中了，此时内存的使用权已经由bootfs转交给内核，此时系统也会卸载bootfs。
​		rootfs（foot file system），在bootfs之上，包含的就是典型的Linux系统中的/dev ,/proc,/bin等标准目录和文件，rootfs就是各种不同的操作系统发行版，比如说Ubuntu，Centos，Redhat等 <br>   镜像是层叠式的，上面的镜像依赖于下面的镜像。镜像是只读的，不能写操作。 联合文件系统<br><img style="zoom:50%;" alt="05.docker-filesystems-multilayer" src="\05.docker-filesystems-multilayer.png" referrerpolicy="no-referrer"><br>
<br>
查看仓库里有什么对应的镜像
docker search  镜像名

<br>
查看镜像

<br>docker images---查看有哪些镜像，repository表示镜像的仓库源，tag是版本，image id是镜像的唯一ID,created是创建时间，size是镜像大小。
<br>docker images -a---查看镜像及中间映像层，也就是一个表面镜像内部还包含了哪些镜像。
<br>docker images -q---只显示镜像ID


<br>
下载镜像
语法： docker pull  镜像名:版本号

<br>docker pull nginx,相当于docker pull nginx:latest下载最新版本。
<br>docker pull tomcat:8.5.32


<br>
删除镜像

<br>docker rmi hello-world---失败，因为提示说该镜像的容器正在运行，
<br>docker rmi -f hello-world- --强制删除


<br><br><br>以centos镜像为例演示<br>
<br>docker pull centos---从阿里上拉取centos镜像
<br>docker run -it centos---启动容器，i为交换模式，t为打开终端，it常常一起使用，exit退出
<br>docker run -it --name mycts centos---启动并指定容器名称，上面没指定都会随机给个名字
<br><br>
<br>docker ps  查看正在运行的容器
<br>docker ps -q  ---只显示容器id
<br>docker ps -a  列表形式查看所有的容器
<br>docker ps -qa   查看所有，包括没有运行的容器
<br><br>
<br>exit---从终端退出并可能停止容器，ctrl+p+q（键盘）退出但容器仍然运行。
<br>docker stop aea7a56b0c7d或容器名---停止容器
<br>docker start 容器名或容器id  重新启动被停止的容器
<br><br>不是停止，停止后容器还在，只是不运行了<br>
<br>docker rm 容器id或名称---注意，必须先关闭容器才能删除，rmi是删除镜像
<br>docker rm -f $(docker ps -aq)---批量删除
<br><br>docker exec -it 容器id bash<br><br>
<br>
从容器中拷贝到宿主机
docker run -it centos

cd /tmp

vi hello.txt

ctrl+p+q

docker ps

docker  cp  容器id:/tmp/hello.txt  /opt


<br>
从宿主机拷贝到容器
docker cp  /opt/a.txt  容器id:/tmp

<br><br><br>
<br>
目录映射：
为方便宿主机与容器间传递数据，产生目录映射，使两者共享同一目录。使用数据卷可将宿主机上的一个目录映射到容器的一个目录中。

<br>
持久化容器数据
容器运行中所产生的数据，如果不通过commit生成新镜像，当容器被删除后数据就丢失了。使用数据卷可在不产生新镜像的前提下保存数据在磁盘上，有点像redis中的持久化。

<br>
部署项目方便

<br>为了部署项目，需要使用到cp命令将宿主机内的war包复制到容器内部。<br>使用数据卷可以在宿主机中操作目录中内容，那么容器内部映射的文件，也会跟着一起改变<br><br>
<br>数据卷可在容器之间共享
<br>修改卷中数据可以直接生效，并且对卷的修改不会引起镜像的更新。
<br>卷的生命周期一直持续到没有容器使用它为止。
<br><br>docker run -di -v /myData:/myContainerData --name myc1  centos<br>docker run -di -v /mydata:/opt --name myc1  centos
<br>参数说明：<br>
<br>-di:产生交互式后台进程
<br>-v:创建一个目录数据卷并挂载到容器里,myData是宿主机中目录，myContainerData是容器中目录
<br>--name:给容器启一名称为myc1
<br>centos：镜像名（如果是其他的，则换其名称）
<br>docker volume prune 清除所有的数据卷<br><br>
<br>vim /myData/a.txt
<br>docker exec -it myc1 bash
<br>cat /myContainerData/a.txt
<br>
<br><br><br><br>
<br>
搜索mysql镜像：docker search mysql

<br>
拉取镜像：docker pull centos/mysql-57-centos7  ，镜像选择的是centos/mysql-57-centos7

<br><br>docker run -di --name=mysql5.7 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root centos/mysql-57-centos7

docker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root  mysql
<br>参数说明：<br>
<br>-di:  以守护进程交互式启动容器
<br>--name:  给容器启名为mysql5.7
<br>-p:  端口映射，格式为：宿主机端口：容器端口，为什么要映射？因为容器的ip地址跟windows的ip不在一个网段，无法通信。从win7访问容器就只能通过win7访问宿主机(虚拟机)的ip+映射的端口。
<br>-e:  当从win7远程连接容器mysql时，要设置root帐号的密码，这里设置远程连接密码为root,但要注意：在进入容器内访问时，密码是空的。
<br>最后一个参数：是上面下载的镜像名.
<br><br><br>
<br>
docker exec -it mysql5.7 bash

<br>
mysql -uroot -p  ，密码为空，回车

<br><br>mysql    -uroot    -proot    -h192.168.146.101   ，默认连接的是3306，如果映射的宿主机不是3306，则后面添加   -P3306<br>mysql8.0遇到的问题<br><img alt="image-20221128174837761" src="\C:\\Users\mameiping\AppData\Roaming\Typora\typora-user-images\image-20221128174837761.png" referrerpolicy="no-referrer"><br>2026问题：<br>方案一：<br>my.cnf中增加<br>skip_ssl
<br>方案二：<br>mysql -uroot -p123456 -h192.168.33.10 -P3306 --ssl-mode=DISABLED
<br>2059问题：<br>ALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER;
ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
FLUSH PRIVILEGES;
<br><br><br>docker search tomcat
<br><br>docker images tomcat
<br><br>最新版本不需要指定版本号<br>#docker pull tomcat:版本号，最新版不需要版本号
docker pull tomcat:8.5
<br><br>docker run -di -p 8080:8080 -v /opt/data:/usr/local/tomcat/webapps/ --name mytomcat  tomcat:8.5
<br><br>http://192.168.33.10:8080/
<br>如果出现404，则是因为版本中的webapps当中没有内容。进行以下将webapps删除，并且将webapps.dist改名为webapps<br>#进入容器，会进入usr/local/tomcat目录
docker exec -it mytomcat /bin/bash
#查看内容，会发现有webapps和webapps.dist
ls -l
#查看webspps当中的内容，会发现是空的,退到上一层目录，移除webapps
cd webapps
ls -l
cd ..
rm -rf webapps
#将webapps.dist变成webapps
mv webapps.dist webapps
<br>再次在浏览器中访问。<br><br>
<br>将window当中打好的war上传到Linux（docker01.war）
<br>
<br>
将war拷贝放入数据卷目录
cp /home/vagrant/docker01.war /opt/data


<br>
<br>测试：<a rel="noopener nofollow" class="external-link" href="http://192.168.33.10:8080/docker01" target="_blank">http://192.168.33.10:8080/docker01</a>
<br><br><br>docker pull nginx<br><br>
<br>
docker run -d --name mynginx1 -p 80:80 nginx bash

<br>
配置文件在/etc/nginx/nginx.conf,默认没有vi命令

<br>
拷贝nginx目录到宿主机：

<br>ctr+p+q
<br>docker ps
<br>docker cp mynginx1:/etc/nginx   /opt/data


<br>
删除容器：docker stop mynginx1--》docker rm mynginx1

<br>
启动容器并添加数据卷：
docker run  -v  /opt/data/nginx:/etc/nginx   -di --name mynginx  -p 80:80 nginx

<br><br><a rel="noopener nofollow" class="external-link" href="http://192.168.146.101/" target="_blank">http://192.168.146.101/</a><br><br><br>docker pull redis<br><br>以aop方式持久化，如果用rdb则不加--appendony yes<br>docker run -d --name myredis -p 6379:6379 redis --appendonly yes<br><br>
<br>进入容器
<br>docker exec -d myredis bash<br>
<br>启动客户端

<br>cd /usr/local/bin
<br>redis-cli


<br><br>官网地址<br><a rel="noopener nofollow" class="external-link" href="https://www.minio.org.cn/" target="_blank">https://www.minio.org.cn/</a><br>什么是MinIO<br>OSS：对象存储的中间件<br>前提<br>1、在<a data-tooltip-position="top" aria-label="https://cloud.tencent.com/product/cvm?from=10680" rel="noopener nofollow" class="external-link" href="https://cloud.tencent.com/product/cvm?from=10680" target="_blank">服务器</a>的安全组和防火墙中放通相对应的端口，操作系统：centos 7.6，需要放通9000端口<br>2、登录自己的Linux系统服务器<br>3、关闭服务器内部的firewalld防火墙<br>4、开启内核端口转发：<br>通过vim /etc/sysctl.conf把里面的net.ipv4.ip_forward = 0修改为net.ipv4.ip_forward = 1后进行保存退出，通过sysctl -p命令使修改后的内核转发文件生效<br>5、下载安装好<a data-tooltip-position="top" aria-label="https://cloud.tencent.com/product/tke?from=10680" rel="noopener nofollow" class="external-link" href="https://cloud.tencent.com/product/tke?from=10680" target="_blank">docker</a><br>6、安装配置好镜像加速源（由于正常拉取镜像是从境外的docker官网拉取，建议设置镜像加速源）<br><br>docker search minio
<br><br>docker pull minio/minio

<br><br>这里的 \ 指的是命令还没有输入完，还需要继续输入命令，先不要执行的意思。
这里的9090端口指的是minio的客户端端口。虽然设置9090，但是我们在访问9000的时候，他会自动跳到9090。<br>MINIO_ACCESS_KEY：登录的用户名<br>MINIO_SECRET_KEY：登录的密码<br>20以后的命令<br>docker run -p 9000:9000 -p 9090:9090 \
 --net=host \
 --name minio \
 -d --restart=always \
 -e "MINIO_ACCESS_KEY=minioadmin" \
 -e "MINIO_SECRET_KEY=minioadmin" \
 -v /opt/minio/data:/data \
 -v /opt/minio/config:/root/.minio \
 minio/minio server \
 /data --console-address ":9090" -address ":9000"

<br>【WARNING: Published ports are discarded when using host network mode
744135519b57a75d58b6c4bac2bee74a83a03b38e146db33426616ce921b49ac】  不影响使用<br><br>http://192.168.33.10:9090/
<br><br>[MinIO上传文件The difference between the request time and the server's time is too large.异常<br># 安装ntp ntpdate
yum -y install ntp ntpdate

#与时间服务器同步时间
ntpdate cn.pool.ntp.org

#将系统时间写入硬件时间
hwclock --systohc
<br><br><br>docker search rabbitmq
<br><br>docker pull rabbitmq
<br><br><br>docker run -d --name rabbitmq \
	-p 5672:5672 -p 15672:15672 \
	-v `pwd`/data:/var/lib/rabbitmq \
	--hostname myRabbit \
	-e RABBITMQ_DEFAULT_VHOST=my_vhost  \
	-e RABBITMQ_DEFAULT_USER=admin -e \
	RABBITMQ_DEFAULT_PASS=admin rabbitmq
<br>-d 后台运行容器；
--name 指定容器名；
-p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）；
-v 映射目录或文件；
--hostname  主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）；
-e 指定环境变量；
（RABBITMQ_DEFAULT_VHOST：默认虚拟机名；
RABBITMQ_DEFAULT_USER：默认的用户名；
RABBITMQ_DEFAULT_PASS：默认用户名的密码）<br><br>默认用户名和密码都是guest<br>docker run -d --name rabbitmq 	\
      -p 5672:5672 -p 15672:15672   rabbitmq
<br><br>docker exec -it rabbitmq bash
rabbitmq-plugins enable rabbitmq_management
<br><br>http://192.168.33.10:15672
<br><br><br>使用Dockerfile可以根据需求开发一个自定义的镜像，其实就是一个文本文件，由一系列命令和参数构成，Docker可读取这个文件构建一个镜像。<br><br>
<br>
向/opt/data/jdk目录添加jdk压缩文件

<br>
在/opt/data/jdk目录中创建并编辑Dockerfile文件
vim Dockerfile   ，添加下面内容：
FROM centos:7
MAINTAINER aowin
WORKDIR /usr
RUN mkdir /usr/local/java
ADD jdk-8u261-linux-x64.tar.gz /usr/local/java/
ENV JAVA_HOME /usr/local/java/jdk1.8.0_144
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JAR_HOME/lib:$CLASSPATH
ENV PATH $JAVA_HOME/bin:$PATH


<br>
编译并构建镜像，镜像名为jdk1.8
docker build -t='jdk1.8'  ./

<br>
查看镜像
docker images

<br>
通过镜像jdk1.8创建容器myjdk
docker run -it --name myjdk jdk1.8 bash

<br><br><br>在/opt/data/eureka目录中添加eureka-server-1.0.jar<br>​	注意eureka-server打包时，指定的主机和端口号，需要是192.168.146.101:7100<br><br>
<br>docker search jdk   得到ascdc/jdk8镜像，也可使用前面创建的镜像jdk1.8
<br><br>
<br>
在/opt/data/eureka中创建并编辑Dockerfile文件
#基于哪个镜像
FROM ascdc/jdk8
#目录挂载，将本地文件夹挂载到当前容器,这里用不着，了解
VOLUME /tmp
#将文件复制到容器指定目录
ADD eureka-server-1.0.jar /usr/local/java/
#暴露服务的端口
EXPOSE 7100
#设置容器启动后要自动执行的命令
ENTRYPOINT ["java","-jar","/usr/local/java/eureka-server-1.0.jar"]


ENTRYPOINT ：如果有多个ENTRYPOINT ，只有最后一个起作用

<br><br>
<br>
编译并创建镜像
docker build -t='eureka-server' ./

<br>
查看生成的镜像：docker images

<br>
启动容器：

<br>前台启动：docker run -p 7100:7100 eureka-server
<br>后台启动：docker run -di -p 7100:7100 eureka-server


<br>
192.168.146.101:7100

]]></description><link>教程\15、docker.html</link><guid isPermaLink="false">教程/15、docker.md</guid><pubDate>Mon, 04 Sep 2023 02:29:44 GMT</pubDate><enclosure url="\04.docker-filesystems-multilayer.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\04.docker-filesystems-multilayer.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[spring-security]]></title><description><![CDATA[<a class="tag" href="?query=tag:userEntity" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#userEntity</a> 
 <br><br><br>Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。它提供了一组可以在Spring应用上下文中配置的Bean，充分利用了Spring IoC（控制反转Inversion of Control ），DI（依赖注入:Dependency Injection ）和AOP（面向切面编程）功能，为应用系统提供声明式的安全访问控制功能，减少了为企业系统安全控制编写大量重复代码的工作。<br>Spring Security对Web安全性的支持大量地依赖于Servlet过滤器。这些过滤器拦截进入请求，并且在应用程序处理该请求之前进行某些安全处理。 Spring Security提供有若干个过滤器，它们能够拦截Servlet请求，并将这些请求转给认证和访问决策管理器处理，从而增强安全性。根据自己的需要，可以使用适当的过滤器来保护自己的应用程序。<br>项目模块<br>
<br>spring-security-core
spring-security-remoting
spring-security-web
spring-security-config
spring-security-ldap
spring-security-oauth2-core
spring-security-oauth2-client
spring-security-oauth2-jose
spring-security-acl
spring-security-cas
spring-security-openid
spring-security-test
<br><br>Spring Security
优点：与Spring无缝连接，全面的权限控制，专为web开发而设计的
缺点：需要依赖spring，旧版本不能脱离web使用，新版本对框架实现了分层抽取，分成核心模块和web模块<br>shiro
优点：简单高效：shiro主张的理念是把复杂事情简单化，针对性能更高的互联网应用有更好表现
通用性：不局限于web环境，可以脱离web使用
缺点：在web环境下一些特定的需求需要手动编写代码
<br>相对shiro，Spring Security在ssm整合时非常麻烦，因此此类项目中使用较少。随着springboot简化配置，spring security的开发和配置越来越简单。<br><br>认证（Authentication）<br>即身份认证，指验证用户是否为使用系统的合法主体，就是说用户能否访问该系统。 （解决你是谁的问题）<br>最常用的简单身份认证方式如下：<br>
<br>用户名密码方式：系统通过核对用户输入的用户名和口令，看其是否与系统中存储的该用户的用户名和口令一致，来判断用户身份是否正确。
<br>指纹打卡机：对于采用指纹等系统，则出示指纹。
<br>硬件key刷卡系统：对于硬件Key等刷卡系统，则需要刷卡。
<br>动态验证码：通过手机动态验证码。
<br>Spring Security支持的认证方式有：用户名和密码、OAuth2.0登录、SAML2.0登录、中央认证服务器（CAS）、记住我、JAAS身份认证、OpenID、预身份验证方案、X509认证<br>授权（Authorization）<br>即身份鉴权，指验证某个用户是否具有权限使用系统的某个操作，身份认证后需要分配权限方可访问系统的资源，对于某些资源没有权限是无法访问的。（解决你能做什么的问题）<br>用户对象User：当前操作的用户，程序等<br>资源对象resource：当前被访问的对象<br>角色对象role：一组权限操作许可的集合<br>权限对象premission：权限操作许可权<br>Spring Security支持的授权方案：基于过滤器授权、基于表达式访问控制、安全对象实现、方法安全、域对象安全（ACL）<br>攻击防护<br>防止会话固定、点击劫持、跨站点请求伪造等攻击。（解决系统安全问题）<br>Spring Security支持的攻击防护有：CSRF、会话固定保护、安全请求头、HTTPS、HTTP防火墙<br><br><br>1：创建一个Spring boot的web工程<br>2：增加Spring security依赖<br>3： 增加一个index.html页面<br><br>&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
	&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>项目启动时，springSecurity也会跟着启动，默认使用HttpBasic的方式启动，用户名是user，密码在启动日志里面，是个随机字符串，例如下图。<br>找不到“/A01-自动登录密码.png”。<br>Spring Security会默认生成一个login的页面，用于进行登录。输入用户名user和控制台的密码，即可以访问主页面index.html<br>找不到“/A02.默认登录页面.png”。<br>主页面有DefaultLoginPageGeneratingFilter的generateLoginPageHtml()方法生成。<br><br>Spring security的认证和授权，是由很多的过滤器一起来完成工作的。它们形成一个过滤器连。<br><img style="zoom:80%;" alt="B01-过滤器链" src="\B01-过滤器链.png" referrerpolicy="no-referrer"><br><br>DelegatingFilterProxy本身是一个Filter。Servlet容器可以注册其标准的过滤器（filter），但是并不会知道applicationcontext容器中的bean。DelegatingFilterProxy是Servlet容器和applicationcontext容器的桥梁，它注册在Servlet容器中，并且调用applicationcontext容器的bean。<br><img style="zoom:80%;" alt="B02-DelegatingFilterProxy" src="\B02-DelegatingFilterProxy.png" referrerpolicy="no-referrer"><br><br>FilterChainProxy是Spring Security提供的一种特殊过滤器，允许通过SecurityFilterChain委托给多个过滤器实例。FilterChainProxy是一个bean，它一般包含在DelegatingFilterProxy中<br><img style="zoom:80%;" alt="B03-FilterChainProxy" src="\B03-FilterChainProxy.png" referrerpolicy="no-referrer"><br><br>FilterChainProxy使用SecurityFilterChain确定应该请求调用哪些Spring安全筛选器。<br><img style="zoom:80%;" alt="B04-securityfilterchain" src="\B04-securityfilterchain.png" referrerpolicy="no-referrer"><br>SecurityFilterChain中包含一个list，指定有哪些SecurityFilter<br><img style="zoom:80%;" alt="B04-securityfilterchain源码" src="\B04-securityfilterchain源码.png" referrerpolicy="no-referrer"><br><br>通过debug时，查看FilterChainProxy的filterChains属性，可以查看默认配置的过滤器<br>找不到“/A04.默认的filter.png”。<br>security的处理主要是依赖各种类型的过滤器<br>
<br>WebAsyncManagerIntegrationFilter：用于继承SecurityContext到Spring异步执行机制中的WebAsyncManager,和spring整合必须的。
<br>SecurityContextPersistenceFilter：  首当其冲的一个过滤器。主要是使用SecurityContextRepository在session中保存或更新一个SecurityContext，并将SecurityContext给以后的过滤器使用，来为后续filter建立所需的上下文，SecurityContext中存储了当前用户的认证和权限信息。
<br>HeaderWriterFilter：向请求的header中添加响应的信息，可以在http标签内部使用security:headers来控制
<br>CsrfFilter：Csrf又称跨域请求伪造，SpringSecurity会对所有post请求验证是否包含系统生成的csrf的token信息，如果不包含则报错，起到防止csrf攻击的效果
<br>LogoutFilter：匹配URL为/logout的请求，实现用户退出，清楚认证信息
<br>UsernamePasswordAuthenticationFilter※：认证操作全靠这个过滤器，默认匹配URL为/login且必须为POST请求
<br>DefaultLoginPageGeneratingFilter※：如果没有在配置文件中指定认证页面，则由该过滤器生成一个默认的认证界面
<br>DefaultLogoutPageGeneratingFilter：由此过滤器生成一个默认的退出登录页面
<br>BasicAuthenticationFilter：此过滤器会自动解析HTTP请求中头部名字包含有Authentication，且以Basic开头的头部信息，提取参数构造UsernamePasswordAuthenticationToken进行认证，成功则填充SecurityContextHolder的Authentication
<br>RequestCacheAwareFilter：通过HttpSessionRequestCache内部维护一个RequestCache，用于缓存HttpServletRequest
<br>SecurityContextHolderAwareRequestFilter：对ServletRequest进行一次包装，使得request具有更加丰富的API
<br>AnonymousAuthenticationFilter：当SecurityContextHolder中认证信息为空，则会创建一个匿名用户存储到SecurityContextHolder中，SpringSecurity为了兼容未登录的访问，也走了一套认证流程，只不过是一个匿名的身份
<br>SessionManagementFilter：SecurityContextRepository限制同一个用户开启多个会话的数量
<br>ExceptionTranslationFilter：位于整个SpringSecurityFilterChain的后方，用来转换整个链路中出现的异常
<br>FilterSecurityInterceptor※※：授权过滤器，获取所有配置资源的访问授权信息，根据SecurityContextHolder中存储的用户信息来决定其是否有权限。
<br><br><br>如果想要修改默认的登录和密码，可以修改application.properties，增加登录用户相关内容<br># 应用名称
spring.application.name=boot18-security
# 应用服务 WEB 访问端口
server.port=8080
#增加以下内容（security的默认用户信息）
spring.security.user.name=java
spring.security.user.password=111
spring.security.user.roles=admin
<br><br>定义一个配置类，继承WebSecurityConfigurerAdapter<br>WebSecurityConfigurerAdapter：用来自定义自定义策略<br>PasswordEncoder：用于对密码进行加密的接口<br>@EnableWebSecurity<br>开启WebSecurity模式，主要作用如下：
1：控制Spring Security是否使用调试模式（debug属性），默认为false
2：导入WebSecurityConfiguration，用于配置web安全过滤器FilterChainProxy
3：若干个WebSecurityConfigurerAdapter作用于一个WebSecurity生成一个最终使用的web安全过滤器FilterChainProxy
4：如果是Servlet环境，导入WebMvcSecurityConfiguration，如果是OAuth2环境，导入OAuth2ClientConfiguration
6：使用EnableGlobalAuthentication启用全局认证机制。Spring Security依赖于全局认证机制<br>@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.inMemoryAuthentication()
                .withUser("java")
                .password(new BCryptPasswordEncoder().encode("111") )
                .roles("admin");
    }

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }
}
<br><br><br>SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for `menu`
-- ----------------------------
DROP TABLE IF EXISTS `menu`;
CREATE TABLE `menu` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) DEFAULT NULL,
  `url` varchar(100) DEFAULT NULL,
  `parentid` bigint(20) DEFAULT NULL,
  `permission` varchar(20) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of menu
-- ----------------------------
INSERT INTO `menu` VALUES ('1', '系统管理', '', '0', 'menu:system');
INSERT INTO `menu` VALUES ('2', '用户管理', '', '0', 'menu:user');

-- ----------------------------
-- Table structure for `role`
-- ----------------------------
DROP TABLE IF EXISTS `role`;
CREATE TABLE `role` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `name` varchar(20) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of role
-- ----------------------------
INSERT INTO `role` VALUES ('1', 'ADMIN');
INSERT INTO `role` VALUES ('2', 'USER');

-- ----------------------------
-- Table structure for `role_menu`
-- ----------------------------
DROP TABLE IF EXISTS `role_menu`;
CREATE TABLE `role_menu` (
  `mid` bigint(20) NOT NULL,
  `rid` bigint(20) NOT NULL,
  PRIMARY KEY (`mid`,`rid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of role_menu
-- ----------------------------
INSERT INTO `role_menu` VALUES ('1', '1');
INSERT INTO `role_menu` VALUES ('2', '1');
INSERT INTO `role_menu` VALUES ('2', '2');

-- ----------------------------
-- Table structure for `role_user`
-- ----------------------------
DROP TABLE IF EXISTS `role_user`;
CREATE TABLE `role_user` (
  `uid` bigint(20) NOT NULL,
  `rid` bigint(20) NOT NULL,
  PRIMARY KEY (`uid`,`rid`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of role_user
-- ----------------------------
INSERT INTO `role_user` VALUES ('1', '1');
INSERT INTO `role_user` VALUES ('2', '2');

-- ----------------------------
-- Table structure for `users`
-- ----------------------------
DROP TABLE IF EXISTS `users`;
CREATE TABLE `users` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `username` varchar(20) NOT NULL,
  `password` varchar(100) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `username` (`username`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8;

-- ----------------------------
-- Records of users  
-- 密码：111
-- ----------------------------
INSERT INTO `users` VALUES ('1', 'java', '$2a$10$TigfHF7Cn2.DJ487NNRrXenvRh72FW/LEviYgn/Yyj2b8tExf.bCi');
INSERT INTO `users` VALUES ('2', 'web', '$2a$10$TigfHF7Cn2.DJ487NNRrXenvRh72FW/LEviYgn/Yyj2b8tExf.bCi');
<br><br>引入依赖<br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;6.0.6&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;2.1.4&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
<br><br>server:
  port: 8080
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/authc?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
mybatis:
  type-aliases-package: com.boot03dbuser.entity
  mapper-locations: classpath:mapper/*.xml
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
<br><br>需要实现UserDetails接口，用户名属性必须为username，密码字段必须是password，否则无法接收<br>注意点：如果数据库中的角色名称不是以ROLE_开头，则必须添加（为角色验证服务）<br>@Data
public class Users implements UserDetails {

    private Long id;
    private String username;
    private String password;
    private List&lt;String&gt; roles;

    @Override
    public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() {
        List&lt;SimpleGrantedAuthority&gt; authorities = new ArrayList&lt;&gt;();

        for (String role : roles) {
            //Role的字符串必须以：Role_开头（如果数据库中没有输入role，则此处需要添加）
            //具体可以参考：org.springframework.security.core.userdetails.User的roles方法
            authorities.add(new SimpleGrantedAuthority("ROLE_" + role));
        }
        return authorities;
    }

    @Override
    public boolean isAccountNonExpired() {
        return true;
    }

    @Override
    public boolean isAccountNonLocked() {
        return true;
    }

    @Override
    public boolean isCredentialsNonExpired() {
        return true;
    }

    @Override
    public boolean isEnabled() {
        return true;
    }
}
<br><br>public interface UsersDao {
    Users selectOne(String username);

    List&lt;String&gt; selectRolesByUser(String username);
}
<br><br>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" &gt;
&lt;mapper namespace="com.boot03dbuser.dao.UsersDao"&gt;
    &lt;select id="selectOne" resultType="Users"&gt;
        select id,username,password
        from users
        where username = #{username}
    &lt;/select&gt;

    &lt;select id="selectRolesByUser"  resultType="string"&gt;
        select name
        from role
        INNER  JOiN role_user ON
            role.id = role_user.rid
        INNER  JOIN users ON
           role_user.uid = users.id
        WHERE users.username = #{username}
    &lt;/select&gt;
&lt;/mapper&gt;
<br><br>实现UserDetailsService接口，用于在程序中引入一个自定义的AuthenticationProvider，实现数据库访问模式的验证<br>UserDetailsService接口(位于org.springframework.security.core.userdetails包下) 用户详情信息服务，此接口定义了获取用户详细信息的唯一的一个方法，通过用户名称获取用户信息；但是获取用户信息的源头有很多自己也可定义只要实现了此接口重写loadUserByUsername方法，在方法内部定义自己获取用户信息的逻辑，后续认证工作交由SpringSecurity来完成即可。我们获取用户名和密码的代码需要写入此接口的实现类当中<br>@Service
public class UserService implements UserDetailsService {

    @Resource
    UsersDao usersDao;

    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
        //获取用户
        Users users= usersDao.selectOne(username);
        if(users == null) {
            throw new UsernameNotFoundException("用户不存在");
        }
        //获取角色
        List&lt;String&gt; roles = usersDao.selectRolesByUser(username);
        users.setRoles(roles);
        return users;
    }
}
<br><br>@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Resource
    UserService userService;
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.userDetailsService(userService);
    }

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }
}
<br><br>自定义一个类来实现AuthenticationProvider，完成用户的认证工作，然后加入到配置文件中。<br><br>@Component
public class BackdoorAuthenticationProvider implements AuthenticationProvider {
    @Override
    public Authentication authenticate(Authentication authentication) throws AuthenticationException {
        String name = authentication.getName();
        String password = authentication.getCredentials().toString();

        //利用mamp用户名登录，不管密码是什么都可以，伪装成admin用户
        if (name.equals("mamp")) {
            Collection&lt;GrantedAuthority&gt; authorityCollection = new ArrayList&lt;&gt;();
            authorityCollection.add(new SimpleGrantedAuthority("ROLE_ADMIN"));
            authorityCollection.add(new SimpleGrantedAuthority("ROLE_USER"));
            return new UsernamePasswordAuthenticationToken(
                    "admin", password, authorityCollection);
        }
        return null;
    }

    @Override
    public boolean supports(Class&lt;?&gt; authentication) {
        return authentication.equals(
                UsernamePasswordAuthenticationToken.class);
    }
}
<br><br>将自定义的后门验证类加入进来<br>@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Resource
    UserService userService;

    @Resource
    BackdoorAuthenticationProvider backdoorAuthenticationProvider;
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth.userDetailsService(userService);
        //将自定义的类注册进来
        auth.authenticationProvider(backdoorAuthenticationProvider);
    }

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }
}
<br><br><br>在static中增加两个页面，admin.html 和user.html<br>admin.html只可以admin角色用户可以访问<br>user.html只可以user角色的用户可以访问<br><br>每个方法上都增加@PreAuthorize注解，用来控制方法的访问权限<br>注意此时的角色字符串不能带有ROLE_<br>如果用户具备给定角色就允许访问,否则出现403。<br>@Controller
public class UserController {

    @RequestMapping("/admin")
    @PreAuthorize("hasRole('ADMIN')")
    public String admin(){
        return "redirect:/admin.html";
    }

    @RequestMapping("/user")
    @PreAuthorize("hasRole('USER')")
    public String user(){
        return "redirect:/user.html";
    }
}
<br><br>在SecurityConfig类上增加@EnableGlobalMethodSecurity(prePostEnabled = true)<br>@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true)
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Resource
    UserService userService;

    @Resource
    BackdoorAuthenticationProvider backdoorAuthenticationProvider;
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        System.out.println("............AuthenticationManagerBuilder.......");
        auth.userDetailsService(userService);
        //将自定义的类注册进来
        auth.authenticationProvider(backdoorAuthenticationProvider);
    }

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }
}

<br><br>使用java用户测试admin是否可以登录<br><br>用来开启在控制器方法上使用Spring Security的访问注解权限，默认不开启<br>
<br>securedEnabled=true：开启@Secured 注解过滤权限， @Secured({"ROLE_admin","ROLE_hr"})
<br>jsr250Enabled=true：开启@RolesAllowed 注解过滤权限，指定访问，@RolesAllowed("admin")
<br>prePostEnabled=true：开启以下四个注解

<br>@PreFilter 允许方法调用,但必须在进入方法之前过滤方法的参数值
<br>@PostFilter 允许方法调用,但必须按照表达式来过滤方法的结果
<br>@PreAuthorize 在方法调用之前,基于表达式的计算结果来限制对方法的访问
<br>@PostAuthorize 允许方法调用,但是如果表达式计算结果为false,将抛出一个安全性异常


<br>@PreAuthorize和@PostAuthorize支持spring表达式语言，提供基于表达式的访问控制，适用于比较复杂的权限控制条件。例如@PreAuthorize("hasRole('admin')")和@PreAuthorize("hasAnyRole('admin','user')")<br>@PreAuthorize("hasRole('ROLE_SYSTEM') and <a href=".?query=tag:userEntity" class="tag" target="_blank" rel="noopener nofollow">#userEntity</a>.password&gt;8 or hasRole('ROLE_ADMIN')")<br>使用@PreFilter和@PostFilter可以对集合类型的参数或返回值进行过滤。使用@PreFilter和@PostFilter时，Spring Security将移除使对应表达式的结果为false的元素。<br>单场景来说，面向权限的注解，包括Spring Security的@Secured以及基于标准的@RolesAllowed都很便利.
当安全规则更为复杂的时候，组合使用@PreAuthorize、@PostAuthorize以及SpEL能够发挥更强大的威力。我们还看到通过为@PreFilter和@PostFilter提供SpEL表达式，过滤方法的输入和输出。<br><br><br>主页面由DefaultLoginPageGeneratingFilter的generateLoginPageHtml()方法生成。<br>请求地址：/login<br>请求方式:  POST<br>参数：username，password<br><br><br>static中增加两个html，一个是mylogin.html，用于用户输入登录信息，另一个是error.html，当登录失败时，进入此页面。<br>注意：mylogin.html中form表单的action，method以及参数需要和默认的登录页面一致<br>    &lt;form action="/login" method="post"&gt;
        username:&lt;input type="text" name="username" value="java"&gt;&lt;br&gt;
        password:&lt;input type="text" name="password" value="111"&gt;&lt;br&gt;
        &lt;input type="submit" value="login"&gt;
    &lt;/form&gt;
<br><br>logout时会做以下处理<br>
<br>使 HTTP 会话无效
<br>清理已配置的所有 RememberMe 身份验证
<br>清除SecurityContextHolder
<br>重定向到/login?logout
<br>&lt;body&gt;
    welcome security
    &lt;a href="/logout"&gt;退出系统，回到登录&lt;/a&gt;
&lt;/body&gt;
<br><br>重写 configure(HttpSecurity http) 方法，用来配置用户自定义登录页面以及其失败，没有权限的页面<br>阻止csrf验证<br>
 http.csrf().disable(); //跨站请求伪造
<br>设置哪些可以不用登录即可访问的页面<br>
http.authorizeRequests()
.antMatchers("/index","/mylogin.html","/login")
.permitAll();
<br>定义登录页面以及其处理<br>
http.formLogin()
.loginPage("/mylogin.html")  //登录的视图页面
.loginProcessingUrl("/login") //登录处理
.failureUrl("/error.html");  //登录错误时显示页面
<br>@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true)
public class SecurityConfig extends WebSecurityConfigurerAdapter {

    @Resource
    UserService userService;

    @Resource
    BackdoorAuthenticationProvider backdoorAuthenticationProvider;
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        System.out.println("............AuthenticationManagerBuilder.......");
        auth.userDetailsService(userService);
        //将自定义的类注册进来
        auth.authenticationProvider(backdoorAuthenticationProvider);
    }

    @Override
    protected void configure(HttpSecurity http) throws Exception {
        //必须先关掉，否则无法正确访问启动页面
        //CSRF（Cross-site request forgery），中文名称：跨站请求伪造
        //CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账…造成的问题包括：个人隐私泄露以及财产安全。
        http.csrf().disable(); //跨站请求伪造
        //定义哪些可以不需要认证即可访问的路径
        //自定义启动页以及处理的/login必须匿名即可访问，因为此时还没有登录
       http.authorizeRequests()
               .antMatchers("/index","/mylogin.html","/login")
               .permitAll();
       http.formLogin()
               .loginPage("/mylogin.html")  //登录的视图页面
               .loginProcessingUrl("/login") //登录处理
                .failureUrl("/error.html");  //登录错误时显示页面
        //自定义403页面
        // 当用户权限时，显示此页面
        http.exceptionHandling()
                .accessDeniedPage("/unauth.html");
    }

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }
}
<br><br>AuthenticationSuccessHandler：当spring框架用户认证成功后执行的接口，方法为onAuthenticationSuccess<br>AuthenticationFailureHandler：当spring框架用户认证失败后执行的接口，方法为onAuthenticationFailure<br>需要实现此俩个接口，用于返回json类型的数据的数据<br><br>&lt;body&gt;
    username:&lt;input type="text" id="username" value="java"&gt;&lt;br&gt;
    password:&lt;input type="text" id="password" value="111"&gt;&lt;br&gt;
    &lt;button id="login"&gt;login&lt;/button&gt;
    &lt;script&gt;
        $(function () {
            $("#login").click(function () {
                let user = $("#username").val();
                let pwd = $("#password").val();
                $.ajax({
                    url:"/login",
                    type:"post",
                    data:{
                        username:user,
                        password:pwd
                    },
                    success:function (data) {
                        alert(data);
                        console.log(data);
                    }
                })
            })
        })
    &lt;/script&gt;
&lt;/body&gt;
<br><br>实现AuthenticationSuccessHandler接口<br>@Component
public class UserSuccessHandler implements AuthenticationSuccessHandler {
    /**
     * 登录成功后
     * @param request
     * @param response
     * @param authentication  登录成功后的封装类
     * @throws IOException
     * @throws ServletException
     */
    @Override
    public void onAuthenticationSuccess(HttpServletRequest request
            , HttpServletResponse response
            , Authentication authentication) throws IOException, ServletException {
        response.setContentType("application/json;charset=utf-8");

        ServletOutputStream out = response.getOutputStream();
        AjaxResult result = AjaxResult.success("登录成功");
        ObjectMapper mapper = new ObjectMapper();
        mapper.writeValue(out,result);
        out.flush();
        out.close();

    }
}
<br><br>@Component
public class UserFailHandler implements AuthenticationFailureHandler {
    /**
     *当框架验证用户失败时，进行处理
     * @param request
     * @param response
     * @param e
     * @throws IOException
     * @throws ServletException
     */
    @Override
    public void onAuthenticationFailure(HttpServletRequest request,
                                        HttpServletResponse response,
                                        AuthenticationException e) throws IOException, ServletException {
        response.setContentType("application/json;charset=utf-8");
        ServletOutputStream out = response.getOutputStream();

        AjaxResult result = AjaxResult.error(-1,"登录失败，请联系管理员");
        ObjectMapper mapper = new ObjectMapper();
        mapper.writeValue(out,result);
        out.flush();
        out.close();
    }
}
<br><br>@Configuration
@EnableWebSecurity
//启用security的部分注解
@EnableGlobalMethodSecurity(prePostEnabled = true)
public class SecurityConfig  {

    @Resource
    UserFailureHandler userFailureHandler;
    @Resource
    UserSuccessHandler userSuccessHandler;

    @Bean
    PasswordEncoder passwordEncoder(){
        return new BCryptPasswordEncoder();
    }

    @Bean
    public SecurityFilterChain securityFilterChain(HttpSecurity httpSecurity) throws Exception {
        //禁止掉CSRF处理
        httpSecurity
                .csrf()
                .disable();
        //设置哪些URL可以不需要登录就直接可以访问
        httpSecurity.authorizeRequests()
                .antMatchers("/login.html","/login")
                .permitAll();
        //设置自定义的登录页面
        httpSecurity.formLogin()
                .loginPage("/login.html")
                .loginProcessingUrl("/login")
                .successHandler(userSuccessHandler)
                .failureHandler(userFailureHandler);
        //自定义403错误页面，当用户没有权限时，会自动跳入此页面
        httpSecurity.exceptionHandling()
                .accessDeniedPage("/unauthc.html");

        return httpSecurity.build();
    }

}
<br><br>思路：用户登录时将token写入redis，并且带回到客户端。<br>​	实现OncePerRequestFilter接口，从用户端获取token，并进行处理<br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;!-- 阿里JSON解析器 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
            &lt;version&gt;1.2.80&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
            &lt;artifactId&gt;jjwt&lt;/artifactId&gt;
            &lt;version&gt;0.9.1&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;version&gt;6.0.6&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;2.1.4&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
        &lt;/dependency&gt;
<br><br>server:
  port: 8080
token:
  header: authentication
  secret: 123456
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/authc?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
  redis:
    host: 127.0.0.1
    port: 6379
mybatis:
  type-aliases-package: com.boot06jwt.vo
  mapper-locations: classpath:mappers/*.xml
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
<br><br><br>@Component
public class RedisCache {
    @Autowired
    RedisTemplate redisTemplate;

    /**
     * 缓存基本的对象，Integer、String、实体类等
     *
     * @param key 缓存的键值
     * @param value 缓存的值
     */
    public &lt;T&gt; void setCacheObject(final String key, final T value)
    {
        redisTemplate.opsForValue().set(key, value);
    }

    /**
     * 缓存基本的对象，Integer、String、实体类等
     *
     * @param key 缓存的键值
     * @param value 缓存的值
     * @param timeout 时间
     * @param timeUnit 时间颗粒度
     */
    public &lt;T&gt; void setCacheObject(final String key, final T value, final Integer timeout, final TimeUnit timeUnit)
    {
        redisTemplate.opsForValue().set(key, value, timeout, timeUnit);
    }

    /**
     * 设置有效时间
     *
     * @param key Redis键
     * @param timeout 超时时间
     * @return true=设置成功；false=设置失败
     */
    public boolean expire(final String key, final long timeout)
    {
        return expire(key, timeout, TimeUnit.SECONDS);
    }

    /**
     * 设置有效时间
     *
     * @param key Redis键
     * @param timeout 超时时间
     * @param unit 时间单位
     * @return true=设置成功；false=设置失败
     */
    public boolean expire(final String key, final long timeout, final TimeUnit unit)
    {
        return redisTemplate.expire(key, timeout, unit);
    }

    /**
     * 获得缓存的基本对象。
     *
     * @param key 缓存键值
     * @return 缓存键值对应的数据
     */
    public &lt;T&gt; T getCacheObject(final String key)
    {
        ValueOperations&lt;String, T&gt; operation = redisTemplate.opsForValue();
        return operation.get(key);
    }

    /**
     * 删除单个对象
     *
     * @param key
     */
    public boolean deleteObject(final String key)
    {
        return redisTemplate.delete(key);
    }

    /**
     * 删除集合对象
     *
     * @param collection 多个对象
     * @return
     */
    public long deleteObject(final Collection collection)
    {
        return redisTemplate.delete(collection);
    }

    /**
     * 缓存List数据
     *
     * @param key 缓存的键值
     * @param dataList 待缓存的List数据
     * @return 缓存的对象
     */
    public &lt;T&gt; long setCacheList(final String key, final List&lt;T&gt; dataList)
    {
        Long count = redisTemplate.opsForList().rightPushAll(key, dataList);
        return count == null ? 0 : count;
    }

    /**
     * 获得缓存的list对象
     *
     * @param key 缓存的键值
     * @return 缓存键值对应的数据
     */
    public &lt;T&gt; List&lt;T&gt; getCacheList(final String key)
    {
        return redisTemplate.opsForList().range(key, 0, -1);
    }

    /**
     * 缓存Set
     *
     * @param key 缓存键值
     * @param dataSet 缓存的数据
     * @return 缓存数据的对象
     */
    public &lt;T&gt; BoundSetOperations&lt;String, T&gt; setCacheSet(final String key, final Set&lt;T&gt; dataSet)
    {
        BoundSetOperations&lt;String, T&gt; setOperation = redisTemplate.boundSetOps(key);
        Iterator&lt;T&gt; it = dataSet.iterator();
        while (it.hasNext())
        {
            setOperation.add(it.next());
        }
        return setOperation;
    }

    /**
     * 获得缓存的set
     *
     * @param key
     * @return
     */
    public &lt;T&gt; Set&lt;T&gt; getCacheSet(final String key)
    {
        return redisTemplate.opsForSet().members(key);
    }

    /**
     * 缓存Map
     */
    public &lt;T&gt; void setCacheMap(final String key, final Map&lt;String, T&gt; dataMap)
    {
        if (dataMap != null) {
            redisTemplate.opsForHash().putAll(key, dataMap);
        }
    }

    /**
     * 获得缓存的Map
     */
    public &lt;T&gt; Map&lt;String, T&gt; getCacheMap(final String key)
    {
        return redisTemplate.opsForHash().entries(key);
    }

    /**
     * 往Hash中存入数据
     *
     * @param key Redis键
     * @param hKey Hash键
     * @param value 值
     */
    public &lt;T&gt; void setCacheMapValue(final String key, final String hKey, final T value)
    {
        redisTemplate.opsForHash().put(key, hKey, value);
    }

    /**
     * 获取Hash中的数据
     *
     * @param key Redis键
     * @param hKey Hash键
     * @return Hash中的对象
     */
    public &lt;T&gt; T getCacheMapValue(final String key, final String hKey)
    {
        HashOperations&lt;String, String, T&gt; opsForHash = redisTemplate.opsForHash();
        return opsForHash.get(key, hKey);
    }

    /**
     * 删除Hash中的数据
     *
     * @param key
     * @param hKey
     */
    public void delCacheMapValue(final String key, final String hKey)
    {
        HashOperations hashOperations = redisTemplate.opsForHash();
        hashOperations.delete(key, hKey);
    }

    /**
     * 获取多个Hash中的数据
     *
     * @param key Redis键
     * @param hKeys Hash键集合
     * @return Hash对象集合
     */
    public &lt;T&gt; List&lt;T&gt; getMultiCacheMapValue(final String key, final Collection&lt;Object&gt; hKeys)
    {
        return redisTemplate.opsForHash().multiGet(key, hKeys);
    }

    /**
     * 获得缓存的基本对象列表
     *
     * @param pattern 字符串前缀
     * @return 对象列表
     */
    public Collection&lt;String&gt; keys(final String pattern)
    {
        return redisTemplate.keys(pattern);
    }
}
<br><br>@Component
public class JwtTokenUtil {

    @Value("${token.header}")
    private String header;
    @Value("${token.secret}")
    private String secret;


    public String createToken(LoginUsers loginUsers){
        //创建JwtBuilder对象
        //通过JwtBuilder对象的一系列方法，来设置token中信息，compact()方法创建token字符串
        JwtBuilder jwtBuilder = Jwts.builder();
        String token = jwtBuilder.setHeaderParam("typ","JWT")   //类型
                .setHeaderParam("alg","HS256")  //加密算法
                .claim("id", loginUsers.getId())
                .claim("uuid",UUID.randomUUID().toString())
                .setIssuer("wanho")  //签发主题
                .setAudience("wanho")
                .setSubject(loginUsers.getUsername())  //主体
                .setIssuedAt(new Date())  //发行事件
                .setNotBefore(new Date())  //有效开始时间（参数指定的时间之后才会有效）
                .setExpiration(new Date(System.currentTimeMillis()+ 360000)) //过期时间
                .setId(UUID.randomUUID().toString())
                .signWith(SignatureAlgorithm.HS256,secret)
                .compact();
        return token;
    }

    //解析token字符串
    public Claims parseToken(String token){
        JwtParser parser = Jwts.parser();
        Jws&lt;Claims&gt; claimsJws = parser.setSigningKey(secret).parseClaimsJws(token);
        Claims claims = claimsJws.getBody();
        return claims;

    }

    //获取用户名
    public Integer getUserID(String token){
        Integer userid;
        try {
            Claims claims = parseToken(token);
            userid = (Integer) claims.get("id");
        } catch (ExpiredJwtException ex) {
            userid =(Integer)  ex.getClaims().get("id");
        }

        return userid;
    }

    //获取用户名
    public String getUUIDFromToken(String token){
        String userid;
        try {
            Claims claims = parseToken(token);
            userid = (String) claims.get("uuid");
        } catch (ExpiredJwtException ex) {
            userid = (String) ex.getClaims().get("uuid");
        }

        return userid;
    }


    //获取用户名
    public String getUsername(String token){
        String username = "";
        try {
            Claims claims = parseToken(token);
            username = claims.getSubject();
        } catch (ExpiredJwtException ex) {
            username = ex.getClaims().getSubject();
        }

        return username;
    }

    public String getTokenFromRequest(HttpServletRequest request){
        return request.getHeader(header);
    }
}

<br><br>@Data
public class LoginUsers implements UserDetails {

    private Long id;
    private String username;
    private String password;
    private List&lt;String&gt; roles;

    @Override
    public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() {
        List&lt;SimpleGrantedAuthority&gt; simpleGrantedAuthorities = new ArrayList&lt;&gt;();

        for (String role : roles) {
            simpleGrantedAuthorities.add(new SimpleGrantedAuthority("ROLE_"+ role));
        }
        return simpleGrantedAuthorities;
    }

    @Override
    public boolean isAccountNonExpired() {
        return true;
    }

    @Override
    public boolean isAccountNonLocked() {
        return true;
    }

    @Override
    public boolean isCredentialsNonExpired() {
        return true;
    }

    @Override
    public boolean isEnabled() {
        return true;
    }
}

<br><br>public interface UsersDao {
    LoginUsers selectOne(String username);

    List&lt;String&gt; selectRolesByUser(String username);
}
<br><br>&lt;mapper namespace="com.boot06jwt.dao.UsersDao"&gt;
    &lt;select id="selectOne" resultType="loginUsers"&gt;
        select id,username,password
        from users
        where username = #{username}
    &lt;/select&gt;

    &lt;select id="selectRolesByUser"  resultType="string"&gt;
        select name
        from role
        INNER  JOiN role_user ON
            role.id = role_user.rid
        INNER  JOIN users ON
           role_user.uid = users.id
        WHERE users.username = #{username}
    &lt;/select&gt;
&lt;/mapper&gt;
<br><br>@Service
public class UserService implements UserDetailsService {

    @Resource
    UsersDao usersDao;

    @Override
    public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {
        //获取用户
        LoginUsers loginUsers = usersDao.selectOne(username);
        if(loginUsers == null) {
            throw new UsernameNotFoundException("用户不存在");
        }
        //获取角色
        List&lt;String&gt; roles = usersDao.selectRolesByUser(username);
        loginUsers.setRoles(roles);
        return loginUsers;
    }
}

<br><br>@RestController
@CrossOrigin
public class LoginController {
    @Autowired
    UserService userService;

    @Resource
    JwtTokenUtil jwtTokenUtil;

    @Resource
    RedisCache redisCache;

    @PostMapping("/login")
    public AjaxResult login(String username,String password){
        UserDetails userDetails = userService.loadUserByUsername(username);
        if (userDetails==null){
            throw new UsernameNotFoundException("用户不存在");
        }

        String token = jwtTokenUtil.createToken((LoginUsers) userDetails);
        String uuid = jwtTokenUtil.getUUIDFromToken(token);
        //将token写入
        redisCache.setCacheObject(uuid,(LoginUsers) userDetails);
        //AjaxResult result = AjaxResult.success("用户登录成功",token);
        return AjaxResult.success("登录成功",token);
    }
}

<br><br>@RestController
@CrossOrigin
public class UserController {

    @GetMapping("/admin")
    @PreAuthorize("hasRole('ADMIN')")
    public String admin(){
        return "admin access success";
    }

    @GetMapping("/user")
    @PreAuthorize("hasRole('USER')")
    public String user(){
        return "USER access success";
    }

    @GetMapping("/authc")
    public String authc(){
        return "authc success";
    }

    @GetMapping("/anonymous")
    public String anonymous(){
        return "anonymous success";
    }
}


<br><br>@Component
public class JwtAuthTokenFilter extends OncePerRequestFilter
{
    @Autowired
    private JwtTokenUtil jwtTokenUtil;

    @Autowired
    RedisCache redisCache;


    @Override
    protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain)
            throws ServletException, IOException
    {
        //通过token获取用户信息的UUID
        String token = jwtTokenUtil.getTokenFromRequest(request);
        //如果token为空，说明没有登录，则需要跳转到登录页面
        if (!StringUtils.isEmpty(token)) {
            String uuid = jwtTokenUtil.getUUIDFromToken(token);
            System.out.println(SecurityContextHolder.getContext().getAuthentication());

            ////根据uuid获取用户信息（从redis缓存中获取）
            LoginUsers loginUsers = redisCache.getCacheObject(uuid);
            //
            //用户存在，但是未存入验证信息
            if (loginUsers != null
                    &amp;&amp; SecurityContextHolder.getContext().getAuthentication()==null){
                UsernamePasswordAuthenticationToken authenticationToken =
                        new UsernamePasswordAuthenticationToken(loginUsers.getUsername(), loginUsers.getPassword(), loginUsers.getAuthorities());
                //authenticationToken.setDetails(new WebAuthenticationDetailsSource().buildDetails(request));
                authenticationToken.setDetails(loginUsers);
                SecurityContextHolder.getContext().setAuthentication(authenticationToken);
            }
        }


        chain.doFilter(request, response);
    }
}

<br><br>@Component
public class AuthenticationEntryPointImpl implements AuthenticationEntryPoint, Serializable
{
    private static final long serialVersionUID = -8970718410437077606L;

    //commence:开始，着手
    @Override
    public void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException e)
            throws IOException
    {

        response.setHeader("Access-Control-Allow-Origin","*"); //允许所有域都可以跨域
        response.setHeader("Access-Control-Allow-Methods","GET,POST,PUT,DELETE,OPTIONS");
        response.setHeader("Access-Control-Allow-Headers","x-requested-with,content-type");
        response.setContentType("application/json;charset=utf-8");

        AjaxResult result = AjaxResult.error(-1,"用户未登录，请登录后再访问");
        response.getWriter().write(JSON.toJSONString(result));
    }
}

<br><br>@Component
public class CustomizeAccessDeniedHandler implements AccessDeniedHandler {
    @Override
    public void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException {
        //登录log更新
        AjaxResult result = AjaxResult.error(-1,"没有权限");
        response.setHeader("Access-Control-Allow-Origin","*"); //允许所有域都可以跨域
        response.setHeader("Access-Control-Allow-Methods","GET,POST,PUT,DELETE,OPTIONS");
        response.setHeader("Access-Control-Allow-Headers","x-requested-with,content-type");
        response.setContentType("application/json;charset=utf-8");
        response.getWriter().write(JSON.toJSONString(result));
    }
}

<br><br>@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)
public class SecurityConfig extends WebSecurityConfigurerAdapter
{
    /**
     * 自定义用户认证逻辑
     */
    @Resource
    private UserDetailsService userService;
    
    /**
     * 认证失败处理类
     */
    @Autowired
    private AuthenticationEntryPointImpl unauthorizedHandler;


    //@Resource
    //JwtLoginFilter jwtLoginFilter;
    ///**
    // * token认证过滤器
    // */
    @Resource
    private JwtAuthTokenFilter jwtAuthTokenFilter;


    @Resource
    CustomizeAccessDeniedHandler customizeAccessDeniedHandler;
    

    
    ///**
    // * 解决 无法直接注入 AuthenticationManager
    // *
    // * @return
    // * @throws Exception
    // */
    //@Bean
    //@Override
    public AuthenticationManager authenticationManagerBean() throws Exception
    {
        return super.authenticationManagerBean();
    }

    /**
     * 强散列哈希加密实现
     */
    @Bean
    public BCryptPasswordEncoder bCryptPasswordEncoder()
    {
        return new BCryptPasswordEncoder();
    }

    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        System.out.println("............AuthenticationManagerBuilder.......");
        auth.userDetailsService(userService);
    }


    /**
     * anyRequest          |   匹配所有请求路径
     * access              |   SpringEl表达式结果为true时可以访问
     * anonymous           |   匿名可以访问
     * denyAll             |   用户不能访问
     * fullyAuthenticated  |   用户完全认证可以访问（非remember-me下自动登录）
     * hasAnyAuthority     |   如果有参数，参数表示权限，则其中任何一个权限可以访问
     * hasAnyRole          |   如果有参数，参数表示角色，则其中任何一个角色可以访问
     * hasAuthority        |   如果有参数，参数表示权限，则其权限可以访问
     * hasIpAddress        |   如果有参数，参数表示IP地址，如果用户IP和参数匹配，则可以访问
     * hasRole             |   如果有参数，参数表示角色，则其角色可以访问
     * permitAll           |   用户可以任意访问
     * rememberMe          |   允许通过remember-me登录的用户访问
     * authenticated       |   用户登录后可访问
     */
    @Override
    protected void configure(HttpSecurity httpSecurity) throws Exception
    {

        httpSecurity.csrf().disable()//跨站请求伪造
                .cors(); //允许跨域
        httpSecurity.headers().frameOptions().disable();
        //设置认证异常处理
        httpSecurity.authorizeRequests()
                .requestMatchers(CorsUtils::isPreFlightRequest).permitAll()
                .antMatchers("/anonymous").permitAll()
                .antMatchers("/login").permitAll()
                .antMatchers(HttpMethod.OPTIONS).permitAll() //不加此项，会导致跨域无效
                .anyRequest().authenticated();

        //禁止session，
        // Spring Security不采用session机制了，
        // 并不是禁用掉了整个系统的session功能。
        httpSecurity.sessionManagement()
            .sessionCreationPolicy(SessionCreationPolicy.STATELESS);
        //定义异常处理
        httpSecurity.exceptionHandling()
                .authenticationEntryPoint(unauthorizedHandler)  //认证失败的情况
                .accessDeniedHandler(customizeAccessDeniedHandler); //权限失败的情况下

        //不能直接使用addFilter来添加过滤器JwtAuthTokenFilter
        // 必须要指定顺序，addFilterBefore或者addFilterAfter或者addFilterAt
        //httpSecurity.addFilter(jwtAuthTokenFilter);
        httpSecurity.addFilterBefore(jwtAuthTokenFilter
                ,UsernamePasswordAuthenticationFilter.class);

    }

}

]]></description><link>教程\16、spring security.html</link><guid isPermaLink="false">教程/16、spring security.md</guid><pubDate>Mon, 09 Oct 2023 00:49:29 GMT</pubDate><enclosure url="\B01-过滤器链.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\B01-过滤器链.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mybatis-plus]]></title><description><![CDATA[ 
 <br><br><br>MyBatis-Plus 是一个 Mybatis 增强版工具，在 MyBatis 上扩充了其他功能没有改变其基本功能，为了简化开发提交效率而存在。<br>官网文档地址：　<a rel="noopener nofollow" class="external-link" href="https://mp.baomidou.com/guide/" target="_blank">https://mp.baomidou.com/guide/</a><br><br><br>使用 IDEA 安装一个 mybatis-plus 插件
<img alt="01.插件.png" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-1001.%E6%8F%92%E4%BB%B6.png" referrerpolicy="no-referrer"><br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
    &lt;artifactId&gt;lombok&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.4.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;2.1.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;version&gt;6.0.6&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;druid&lt;/artifactId&gt;
    &lt;version&gt;1.1.24&lt;/version&gt;
&lt;/dependency&gt;
<br><br>server:
  port: 8080
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/java160?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
    type: com.alibaba.druid.pool.DruidDataSource

    initialSize: 5
    minIdle: 5
    maxActive: 20
    maxWait: 60000
mybatis:
  type-aliases-package: com.hyy.entity
<br><br>@Configuration
public class MyConfig {
    @Bean("dataSource")
    @ConfigurationProperties(prefix = "spring.datasource")
    public DataSource druid() {
        return new DruidDataSource();
    }
}
<br><br>@Data
public class Teacher {
    String tno;
    String tname;
    String tsex;
    @DateTimeFormat(pattern = "yyyy-MM-dd")
    Date tbirthday;
    String prof;
    String depart;
}
<br><br>public interface TeacherMapper extends BaseMapper&lt;Teacher&gt; {
}
<br><br>增加@MapperScan注解<br>@SpringBootApplication
@MapperScan(basePackages = "com.hyy.dao")
public class Base04MybatisplusApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base04MybatisplusApplication.class, args);
    }

}
<br><br>此控制器跳开service，直接调用了Mapper<br>@RestController
public class TeacherController {
    @Autowired
    TeacherMapper teacherMapper;
    @RequestMapping("/getall")
    public List&lt;Teacher&gt; selectAll(){
        return teacherMapper.selectList(null);
    }
}
<br><br>mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
<br><br>@TableName：用于表名，放在entity上面，value值是数据库表名（主要用于pojo和数据库表名不一致的情况下）<br>@TableId：用于定义表的主键，其value是表的主键column名，type是指主键类型<br>@TableField：用于定义表的非主键字段。<br>​	value：指定数据库表中的cloumn名<br>​	exist：用于表明当前的field是否是数据库表的一个属性，会影响sql语句<br>​	fill：用于指定数据的自动填充策略，一般用于修改时间或者创建时间，默认不填充<br>@TableLogic：用于定义表的逻辑删除字段。<br>​	value：用于定义未删除状态的值<br>​	delval：用于定义删除状态的值<br>​	<br><br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.5.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt;
            &lt;version&gt;3.5.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt;
            &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt;
            &lt;version&gt;2.3&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>@Test
    void mybatisGenerator() {
        String url = "jdbc:mysql://localhost:3306/authc?serverTimezone=UTC&amp;useSSL=false";
        //总体配置
         FastAutoGenerator fastAutoGenerator = FastAutoGenerator.create(url, "root", "root")
                .globalConfig(builder -&gt; {
                    builder.author("mamp") // 设置作者
                            //.commentDate(LocalDateTime.now().toString())
                            //.enableSwagger() // 开启 swagger 模式
                            .fileOverride()
                            .outputDir("D://"); // 指定输出目录
                });
        //包配置
        fastAutoGenerator.packageConfig(builder -&gt; {
                    builder.parent("net")
                            .moduleName("system")
                            .controller("controller")
                            .service("service")
                            .entity("domain")
                            .mapper("mapper")
                            .serviceImpl("impl");
                });
        //实体策略
        fastAutoGenerator.strategyConfig(builder -&gt; {
            builder.entityBuilder()
                    .naming(NamingStrategy.underline_to_camel)
                    .columnNaming(NamingStrategy.underline_to_camel);
            builder.controllerBuilder().enableRestStyle();
        });
        //执行
        fastAutoGenerator.execute();
    }
<br><br><br>定义模板并放在resources/templates目录下，以下为controller.java.vm<br>package ${package.Controller};

import org.springframework.web.bind.annotation.RequestMapping;
import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
import ${package.Entity}.${entity};
import ${package.Service}.${table.serviceName};
import org.springframework.web.bind.annotation.DeleteMapping;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.PathVariable;
import org.springframework.web.bind.annotation.RestController;

import javax.annotation.Resource;
import java.util.List;

#if(${restControllerStyle})
import org.springframework.web.bind.annotation.RestController;
#else
import org.springframework.stereotype.Controller;
#end
#if(${superControllerClassPackage})
import ${superControllerClassPackage};
#end

/**
 * &lt;p&gt;
 * $!{table.comment} 前端控制器
 * &lt;/p&gt;
 *
 * @author ${author}
 * @since ${date}
 */
#if(${restControllerStyle})
@RestController
#else
@Controller
#end
@RequestMapping("#if(${package.ModuleName})/${package.ModuleName}#end/#if(${controllerMappingHyphenStyle})${controllerMappingHyphen}#else${table.entityPath}#end")
#if(${kotlin})
class ${table.controllerName}#if(${superControllerClass}) : ${superControllerClass}()#end

#else
#if(${superControllerClass})
public class ${table.controllerName} extends ${superControllerClass} {
#else
public class ${table.controllerName} {

        }
#end

    @Resource
    ${table.serviceName} #serviceName();

    @GetMapping("list")
    public List&lt;${entity}&gt; doList(){
            QueryWrapper&lt;${entity}&gt; query = new QueryWrapper&lt;&gt;();
            query.likeLeft("phone","23")
            .like("email","2189");
            List&lt;${entity}&gt; list = #serviceName().list(query);
            return list;
    }

    @GetMapping("findOne/{id}")
    public ${entity} findOne(@PathVariable("id") Long id){
        return #serviceName().getById(id);
    }

    @DeleteMapping("delete/{id}")
    public void deleteOne(@PathVariable("id") Long id){
        ${table.serviceName.substring(0,1).toLowerCase()}${table.serviceName.substring(1)}.removeById(id);
    }


}
#end

#macro(serviceName)
    ${table.serviceName.substring(0,1).toLowerCase()}${table.serviceName.substring(1)}
#end

<br><br>@Test
    void mybatisGenerator() {
         ...
        //resourceLoader使用的是ClasspathResourceLoader，所以只需要写classpath下的目录即可，不需要classpath前缀
        String controllerTemplate="templates/controller.java";
        fastAutoGenerator.templateConfig(builder -&gt; {
            builder.controller(controllerTemplate);
        });
        fastAutoGenerator.execute();
    }
<br><br>使用代码生成器能够方便的生成所需要的代码<br>注意在主类中需要增加@EnableAutoConfiguration或者给@SpringBootApplication注解添加属性exclude = {DataSourceAutoConfiguration.class}<br>@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class})
public class GeneratorApplication {
	public static void main(String[] args) {
        SpringApplication.run(GeneratorApplication.class, args);
    }
}
<br><br>&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt;
    &lt;version&gt;3.4.1&lt;/version&gt;
&lt;/dependency&gt;
&lt;!-- 默认的引擎模板--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt;
    &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt;
    &lt;version&gt;2.3&lt;/version&gt;
&lt;/dependency&gt;
<br><br>AutoGenerator mpg = new AutoGenerator();
<br><br>// Step2：全局配置
GlobalConfig gc = new GlobalConfig();
// 填写代码生成的目录(需要修改)
String projectPath = "D:\\springbootProject\\springbootsample\\base05-mybatisplus-generator";
// 拼接出代码最终输出的目录
gc.setOutputDir(projectPath + "/src/main/java");
// 配置开发者信息（可选）（需要修改）
gc.setAuthor("mamp");
// 配置是否打开目录，false 为不打开（可选）
gc.setOpen(false);
// 实体属性 Swagger2 注解，添加 Swagger 依赖，开启 Swagger2 模式（可选）
//gc.setSwagger2(true);
// 重新生成文件时是否覆盖，false 表示不覆盖（可选）
gc.setFileOverride(false);
// 配置主键生成策略，此处为 ASSIGN_ID（可选）
gc.setIdType(IdType.ASSIGN_ID);
// 配置日期类型，此处为 ONLY_DATE（可选）
gc.setDateType(DateType.ONLY_DATE);
// 默认生成的 service 会有 I 前缀
gc.setServiceName("%sService");
mpg.setGlobalConfig(gc);
<br><br>// Step3：数据源配置（需要修改）
DataSourceConfig dsc = new DataSourceConfig();
// 配置数据库 url 地址
String url="jdbc:mysql://localhost:3306/java160?"
        +"serverTimezone=Asia/Shanghai&amp;useSSL=false";
System.out.println(url);
dsc.setUrl(url);
// 配置数据库驱动
dsc.setDriverName("com.mysql.cj.jdbc.Driver");
// 配置数据库连接用户名
dsc.setUsername("root");
// 配置数据库连接密码
dsc.setPassword("root");
mpg.setDataSource(dsc);
<br><br>// Step:4：包配置
PackageConfig pc = new PackageConfig();
// 配置父包名（需要修改）
pc.setParent("com.hyy");
// 配置模块名（需要修改）
pc.setModuleName("system");
// 配置 entity 包名
pc.setEntity("entity");
// 配置 mapper 包名
pc.setMapper("mapper");
// 配置 service 包名
pc.setService("service");
// 配置 controller 包名
pc.setController("controller");
mpg.setPackageInfo(pc);
<br><br>// Step5：策略配置（数据库表配置）
StrategyConfig strategy = new StrategyConfig();
// 指定表名（可以同时操作多个表，使用 , 隔开）（需要修改）
strategy.setInclude("teacher");
// 配置数据表与实体类名之间映射的策略
strategy.setNaming(NamingStrategy.underline_to_camel);
// 配置数据表的字段与实体类的属性名之间映射的策略
strategy.setColumnNaming(NamingStrategy.underline_to_camel);
// 配置 lombok 模式
strategy.setEntityLombokModel(true);
// 配置 rest 风格的控制器（@RestController）
strategy.setRestControllerStyle(true);
// 配置驼峰转连字符
strategy.setControllerMappingHyphenStyle(true);
// 配置表前缀，生成实体时去除表前缀
// 此处的表名为 test_mybatis_plus_user，模块名为 test_mybatis_plus，去除前缀后剩下为 user。
//        strategy.setTablePrefix(pc.getModuleName() + "_");
mpg.setStrategy(strategy);
<br><br>mpg.execute();
<br><br><br>给POJO的属性@TableField上增加fill属性<br>定义一个实现MetaObjectHandler 接口的组件（需要能够扫描到）<br>
<br>
POJO属性
@Data
@EqualsAndHashCode(callSuper = false)
public class Teacher implements Serializable {

    private static final long serialVersionUID = 1L;

    //.....其他属性

    @TableField(value = "createTime",fill = FieldFill.INSERT)
    private Date createtime;

    @TableField(value = "updateTime",fill = FieldFill.INSERT_UPDATE)
    private Date updatetime;

}



<br>
MetaObjectHandler 的实现类，定义自动填充规则
@Component
public class BaseObjectHandler implements MetaObjectHandler {
    @Override
    public void insertFill(MetaObject metaObject) {
        this.strictInsertFill(metaObject, "createtime", Date.class, new Date());
        this.strictInsertFill(metaObject, "updatetime", Date.class, new Date());
    }

    @Override
    public void updateFill(MetaObject metaObject) {
        this.strictInsertFill(metaObject, "updatetime", Date.class, new Date());
    }
}


<br><br>支持的数据类型为Integer，Boolean以及Date类型。<br>操作方法：给实体类的对象增加@TableLogic(value="0",delval = "1")注解<br>
<br>value：正常有效数据值
<br>delval：删除时的值
<br>使用 mybatis-plus 封装好的方法时，会自动添加逻辑删除的功能。若是自定义的 sql 语句，需要手动添加逻辑。<br><br>在application.yml文件中增加以下配置，并在entity的指定属性上增加@TableLogic注解<br>mybatis-plus  
  global-config:
    db-config:
      logic-delete-field: del_flag # 全局逻辑删除的实体字段名
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)

<br>entity<br>@Data
@TableName(value="sample")
public class Sample implements Serializable {
	...
    @TableLogic
    private Integer delFlag;
}

<br><br>使用@TableLogic的value和delValue来设置<br>@Data
@EqualsAndHashCode(callSuper = false)
public class Teacher implements Serializable {

    private static final long serialVersionUID = 1L;

     。。。

         
    @TableLogic(value="0",delval = "1")  //增加此字段和注解
    @TableField("deleteFlag")
    private Integer deleteflag;

}
<br><br><br>@Configuration
public class MybatisPlusConfig {
    @Bean
    public MybatisPlusInterceptor mybatisPlusInterceptor() {
        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));
        return interceptor;
    }
}
<br><br>mybatis提供了一系列分页的方法，例如page<br>@GetMapping("page")
public Page&lt;Sample&gt; findPage(){
    Page&lt;Sample&gt; page = new Page&lt;&gt;();
    page.setCurrent(1);
    page.setSize(2);
    Page&lt;Sample&gt; page1 = sampleService.page(page);
    return page1;
}
<br><br>
<br>
修改mapper
@Mapper
public interface SampleMapper extends BaseMapper&lt;Sample&gt; {

    IPage&lt;Sample&gt; selectPageVo(IPage&lt;?&gt; page,  Sample sample);

}


//mapper.xml
&lt;select id="selectPageVo" resultType="net.wanho.base01.entity.Sample"&gt;
        select * from sample
        where name like concat('%',#{sample.name},'%')
    &lt;/select&gt;


<br>
修改service
public interface ISampleService extends IService&lt;Sample&gt; {
    IPage&lt;Sample&gt; selectPageVo(IPage&lt;?&gt; page, Sample sample);
}


@Service
public class SampleServiceImpl extends ServiceImpl&lt;SampleMapper, Sample&gt; implements ISampleService {

    @Override
    public IPage&lt;Sample&gt; selectPageVo(IPage&lt;?&gt; page, Sample sample) {
        SampleMapper baseMapper = this.getBaseMapper();
        return baseMapper.selectPageVo(page,sample);
    }
}


<br>
测试处理器
@GetMapping("mypage")
    public Page&lt;Sample&gt; findMyPage(){
        Page&lt;Sample&gt; page = new Page&lt;&gt;();
        page.setCurrent(1);
        page.setSize(2);
        Sample sample = new Sample();
        sample.setName("test");
        IPage&lt;Sample&gt; page1 = sampleService.selectPageVo(page,sample);

      return (Page&lt;Sample&gt;)page1;
    }


<br><br><br>QueryWrapper：查询条件构造器<br>QueryWrapper&lt;Teacher&gt; queryWrapper = new QueryWrapper&lt;&gt;();
queryWrapper
            .select("tno", "tname", "tbirthday")
            .eq("tno", '702')
            .like("tname", "j");
 teacherService
            .list(queryWrapper)
            .forEach(System.out::println);
]]></description><link>教程\17、mybatis-plus笔记.html</link><guid isPermaLink="false">教程/17、mybatis-plus笔记.md</guid><pubDate>Tue, 10 Jun 2025 08:40:44 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-1001.%E6%8F%92%E4%BB%B6.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-1001.%E6%8F%92%E4%BB%B6.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[整合Swagger]]></title><description><![CDATA[ 
 <br><br>Swagger 是一个规范和完整的框架，用于生成、描述、调用和可视化 RESTful 风格的 Web 服务，用于文档管理的工具。。<br>总体目标是使客户端和文件系统作为服务器以同样的速度来更新。文件的方法、参数和模型紧密集成到服务器端的代码，允许 API 来始终保持同步。Swagger 让部署管理和使用功能强大的 API 从未如此简单。<br><br><br>@ApiModel： 用来标注实体类的作用<br>@ApiModelProperty：用在实体类的属性上，添加一些自定义的属性属性<br><br>@Api(tags="用户管理"):定义在类上<br>@Tag(name="" ,descipt=""):定义在类上，说明控制器的作用，和@Api注解作用基本类型，是3新增加的注解<br>@ApiOperation("说明"):定义在方法上，用来表明此方法是干什么的<br>@ApiParam()定义在参数上<br><br>&lt;dependency&gt;
            &lt;groupId&gt;io.springfox&lt;/groupId&gt;
            &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.0.0&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>增加@EnableOpenApi注解<br><br>spring2.6.X的以后版本需要<br><br>http://localhost:8080/swagger-ui/index.html<br><br>使用在控制器接口上注解<br>@Api(tags="") :定义控制器类上，用于说明当前控制器的模块<br>@ApiOperation("获取。。。数据")：定义在方法上<br>@ApiParam(valu3="角色id"，required=true，example="1001")<br>使用在Entity上的注解<br>@ApiModel<br>@ApiModelProperty<br><br>整合下面两个ui后，访问路径变成 http://localhost:8080/doc.html<br><br>&lt;dependency&gt;
    &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;
    &lt;artifactId&gt;swagger-bootstrap-ui&lt;/artifactId&gt;
    &lt;version&gt;1.9.6&lt;/version&gt;
&lt;/dependency&gt;
<br><br>&lt;dependency&gt;
    &lt;groupId&gt;com.github.shijingsh&lt;/groupId&gt;
    &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.1.0&lt;/version&gt;
&lt;/dependency&gt;
<br><br>@Configuration
public class AppConfig {

    @Bean
    public Docket apiDocket(){
        return new Docket(DocumentationType.OAS_30)
                .groupName("admin")
                .apiInfo(addApiInfo())
                .select()
                //.paths(Predicates.and(PathSelectors.regex("/user/.*")))  //配置路由，可以只显示一部分接口
                .build();
    }

    /**
     * 配置Api信息
     * @return
     */
    private ApiInfo addApiInfo(){
        return new ApiInfoBuilder()
                .title("万和物美后台管理系统")
                .description("万物智联项目")
                .version("1.0")
                .contact(new Contact("小万","http://helper.wanho.net","helper@wanho.net"))
                .build();
    }
}
<br><br><br>项目中操作的记录信息，可以通过日志查看程序的运行信息以及异常信息等。<br><br>trace，debug，info，warn，error，all或off<br><br>springboot的内部使用logback作为日志实现的框架<br>在resouces中创建logback-spring.xml或者logback.xml文件（两个默认的文件名）<br>如果不是上述两个文件名，则需要进行修改。使用logging.config<br>]]></description><link>教程\18、整合Swagger.html</link><guid isPermaLink="false">教程/18、整合Swagger.md</guid><pubDate>Thu, 31 Aug 2023 06:08:54 GMT</pubDate></item><item><title><![CDATA[OSS对象存储]]></title><description><![CDATA[ 
 <br><br><br>Object Store Service： 对象存储服务，是一种云存储服务，OSS一般都提供与平台无关的REST风格的接口，可以在任何时间，地点以及存储位置访问任意类型的数据。<br><br>MinIO对象存储使用buckets来组织对象，buckets（桶）类似于文件目录，每个桶可以存储任意数量的对象。<br>MinIO是一个高性能的，分布式的存储系统，对于硬件系统的要求相对比较低。针对要求比较高的私有云进行架构。<br><br><br>​	如果使用的是user创建，则需要指定权限<br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;io.minio&lt;/groupId&gt;
            &lt;artifactId&gt;minio&lt;/artifactId&gt;
            &lt;version&gt;8.4.5&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>public static void main(String[] args) throws IOException, InvalidKeyException, InvalidResponseException, InsufficientDataException, NoSuchAlgorithmException, ServerException, InternalException, XmlParserException, ErrorResponseException {
        String host = "http://192.168.33.10:9000";
        String accessKey="java178";
        String secretKey="12345678";
        //MinioClient用来连接的服务器
        MinioClient client =MinioClient.builder()
                            .endpoint(host)
                            .credentials(accessKey,secretKey)
                            .build();
        //判断
        boolean bucketExists = client.bucketExists(BucketExistsArgs.builder().bucket("java1792").build());
        if (!bucketExists){
            client.makeBucket(MakeBucketArgs.builder().bucket("java1792").build());
        }
        String fileName = "d:/fox.jpg";
        InputStream in = new FileInputStream(fileName);
        PutObjectArgs objectArgs = PutObjectArgs.builder().bucket("java1792")
                .object("fox.jpg")
                .stream(in, in.available(), 0)
                .build();
        client.putObject(objectArgs);


        System.out.println("文件上传成功");

    }
<br><br><br><br><br>]]></description><link>教程\19、OSS对象存储.html</link><guid isPermaLink="false">教程/19、OSS对象存储.md</guid><pubDate>Fri, 24 Nov 2023 09:06:56 GMT</pubDate></item><item><title><![CDATA[ElasticSearch]]></title><description><![CDATA[ 
 <br><br><br>Lucene是apache软件基金会 jakarta<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E9%A1%B9%E7%9B%AE%E7%BB%84/6791625?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E9%A1%B9%E7%9B%AE%E7%BB%84/6791625?fromModule=lemma_inlink" target="_blank">项目组</a>的一个子项目，是一个<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81/114160?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%BC%80%E6%94%BE%E6%BA%90%E4%BB%A3%E7%A0%81/114160?fromModule=lemma_inlink" target="_blank">开放源代码</a>的全文<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E/144626?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E/144626?fromModule=lemma_inlink" target="_blank">检索引擎</a><a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%B7%A5%E5%85%B7%E5%8C%85/4576772?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%B7%A5%E5%85%B7%E5%8C%85/4576772?fromModule=lemma_inlink" target="_blank">工具包</a>，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/11046544?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/11046544?fromModule=lemma_inlink" target="_blank">文本分析</a>引擎（英文与<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%BE%B7%E6%96%87/26064?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%BE%B7%E6%96%87/26064?fromModule=lemma_inlink" target="_blank">德文</a>两种西方语言）。Lucene的目的是为<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/3448966?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6%E5%BC%80%E5%8F%91/3448966?fromModule=lemma_inlink" target="_blank">软件开发</a>人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。<br><br>The Elastic Stack是一个项目工具集，包含ElasticSearch、Kinaba，Beats以及Logstash。能够安全可靠地获取各种来源的数据，并且对数据进行实时的搜索、分析以及可视化。<br>Elasticsearch 是一个高度可扩展且开源的REST风格的全文检索和分析引擎。它可以让您快速且近实时地存储，检索以及分析海量数据。它通常用作那些具有复杂搜索功能和需求的应用的底层引擎或者技术。<br><br>正排索引：文档的id为关键字，索引文档种每个内容的位置，查找时扫描每个文档当中的内容直到找到锁包含的关键字，应用在结构统一并且数据量不大的情况。<br>倒排索引：反向索引。通过某个单词，能够快速定位到包含此单词的文档。包含两个部分：单词词典和倒排文件。应用在结构不固定且数据量比较大的情况。<br>原理（过程）：将结构化的数据的一部分内容抽取出来，重新组织，使其变成一定结构化的数据。然后对齐进行索引，从而提供查询效率<br><br>1：Solr利用Zookeeper进行分布式管理，ES自带分布式管理协调器<br>2：Solr的安装比较复杂，ES比较简单<br>3：Solr支持的数据类型比较多，json，xml，csv，ElasticSearch只支持json数据格式<br>4：Solr提供的底层功能更多，ES更注重核心功能，图形化界面比较友好（kibana）<br>5：Solr的索引更新比较慢，查询速度比较块<br>​       ES这块查询比较慢，索引的更新比较快，即时性性更好<br><br>window版本解压即可适用<br>点击/bin/elasticsearch.bat
<img alt="image-20230314142728249.png" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-10-image-20230314142728249.png" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br>9300: ES的集群之间维持心跳的端口<br>9200：客户端连接的端口
<img alt="image-20230314142944859.png" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-10-image-20230314142944859.png" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br><img alt="image.png" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-11-202506110925166.png" referrerpolicy="no-referrer" style="width: 600px; max-width: 100%;"><br><br>索引：相似特征的文档的集合。一个索引必须要由标识符进行标记，可以对索引进行增加，删除以及搜索等操作<br>在ES当中可以定义多个索引，能搜索的数据先进行索引再进行查询，提升查询的效率。<br>ES当中的索引可以类比于结构化数据库当中的表，但是表当中所有的数据结构是相同的，索引当中文档的结构则可以不同。<br><br>一个文档是一个可以被索引的基本单元，类似于结构化数据库当中的record。可以是某个客户的文档，也可以是产品的文档，也可以商户的文档。文档以JSON格式表示。<br><br>相当于结构化数据库的column，用来记录文档的属性<br><br>一个索引的数据量可能会超过单个硬件限制的范围。比如10亿数据量的文档索引可能1TB的磁盘空间，一般情况下，单个的硬件不会有那么大的磁盘空间，而且单个节点来处理请求，响应比较慢。为了解决这个问题，ElasticSearch提供将索引分成多份的功能，每一份就称之为分片。每一个分片都有相对独立的索引功能。<br><br>在大的网络环境当中，其中某一个节点因为机器的故障或者网络的故障等多种原因，可能处于离线状态。如果没有副本，不进行故障转移，集群的服务就会出现问题。为了集群的高可用性，ES允许为分片创建副本。当主分片出现故障后，从副本上进行读取数据。<br>主分片和副本不在同一个节点上。<br><br><br>适用put请求<br>PUT /product
<br><br>适用GET请求<br>GET /product
<br><br>GET /_cat/indices
<br><br>适用delete<br>DELETE /product
<br><br><br>POST /product/_doc
{
  "title":"java编程基础",
  "price":200,
  "category":"计算机技术",
  "author":"陈阳",
  "publish":"西北工业大学"
}
<br><br>POST /product/_doc/1
{
  "title":"C语言",
  "price":50,
  "category":"计算机技术",
  "author":"陈星驰",
  "publish":"清华大学出版社"
}
<br><br><br>shell<br>yml#查找单个索引
GET /product/_doc/1
#查找所有
GET /product/_search
GET /book/_ search
{
    "query": {
        “match": {
        	"publisher":“出社"
        }
    }
}

//组合
GET /book/_ search
{
    "query": {
	    "bool":{
	    "should":[
            {“match": {"title":"西游"}}
            {“match": {"publisher":“出社}}
	    ]
	    }
        
    }
}


<br><br>trem:数值类型，不做分词处理<br>match<br><br>#全量修改
PUT /product/_doc/1
{
  "title":"C语言11",
  "price":80,
  "category":"计算机技术",
  "author":"陈星驰",
  "publish":"清华大学出版社"
}
#部分修改
POST /product/_update/1
{
  "doc":{
    "title":"python"
  }
}

<br><br>DELETE /product/_doc/di_63oYBP0mK2zQDTlTg
<br><br>GET /product/_search
 {
    "query":{
      "match_all": {

      }
    },
    "from": 0,  
    "size": 2,
    "_source": ["title","price"], 
    "sort": [   
      {
        "price": {
          "order": "asc"
        }
      }
    ]
    
  }
<br><br>shoud表示or条件，must表示and条件<br>GET /product/_search
 {
    "query":{
      "bool": {
        "should": [
          {
             "match": {
                   "category": "编"
              }
          },
           {
             "match": {
                   "publish": "西北"
              }
          }
        ]
      } 
     
    }
  
  }
<br><br><br><br><br>当集群当中的某一个节点，出现单点的故障（宕机或者网络问题），集群会自动进行故障转移。如果是master挂掉了，集群会重新选择一台机器作为主节点。分片和副本都会进行自动分配。<br>当集群当中如有新的节点加入的话，也会重新分配。<br><br>ES当中主分片的数量不能进行修改。<br>当存储一个文档的时候，集群会根据主分片的数量，计算存储在那个分片上。ES内部有它自己的路由规则<br>hash（routing)%主分片数量=shard<br>routing是一个可变值，默认是文档的_id，也可以是自定义的值。<br>写操作<br>客户端发送请求到协调节点（集群中的任意一个）<br>协调节点将请求转发的指定节点（包含主分片）<br>主分片保存数据<br>主分片将数据分发给副本<br>副本保存完之后反馈给主分片<br>主分片进行响应<br>客户端获得响应结果<br>索引的创建和删除，文档的创建、修改、删除都是写操作，都需要在主分片上完成，然后复制给副本。<br>读操作<br>客户端发送请求到协调节点（集群中的任意一个）<br>协调节点计算获取到主分片以及其所有副本所在的位置<br>将请求转发到具体的节点（有负载均衡的策略）<br>节点返回查询节点，并将结果返回给客户端。<br><br>一般情况下，主分片 + 副本的总数=节点的平方<br>put /users/_settings
{
  "number_of_replicas":2
}

<br><br>ES内置了很多的分析器。对存入的数据预先进行分析，并形成词条。<br>目前使用的标准的分析器，根据unicode联盟定义的单词边界进行分词处理，它会删除掉绝大部分的标点。<br>IK分词器：中文分词器，下载解压后放入es的plugins目录下即可。提供两种分词器：<br>ik_max_word: 会将文本做做多词汇的拆分（最细粒度），尽可能多的拆出词语<br>ik_smart: 粗粒度的拆分，已经被拆分出来的词语不会被其他词占用]]></description><link>教程\20、ElasticSearch.html</link><guid isPermaLink="false">教程/20、ElasticSearch.md</guid><pubDate>Wed, 11 Jun 2025 01:25:57 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-10-image-20230314142728249.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/2025-06-10-image-20230314142728249.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Spring cloud]]></title><description><![CDATA[ 
 <br><br>Spring Cloud是一个基于Spring boot实现的微服务架构开发工具,微服务架构是SOA架构的发展。它为微服务架构中提供配置管理、服务治理、智能路由、断路器以及集群状态管理等等。Spring cloud是基于HTTP协议的架构。<br>Springboot只用来开发单个服务<br>Springcloud可以开发多个服务<br>核心组件：<br>​	注册中心：Eureka ，Nacos，Consul<br>​	负载均衡：Ribbon，sentinel， loadbalancer<br>​	容错保护：Hystrix，resilience4j，sentinel<br>​	服务调用：feign，openfeign<br>​	网关：Zuul，Gateway<br>​	配置中心：config，Nacos<br><br>有一个服务（提供者），提供图书的检索功能。<br>有另外一个服务（消费者），需要买书时，按照编号查看书的信息。<br><br>创建普通maven工程base00-common，并编写实体类<br>@Data
@NoArgsConstructor
@AllArgsConstructor
public class Book {
    String isbn;
    String name;
    String author;
    double price;
}
<br><br>创建一个spring boot的web工程，并增加base00-common的依赖<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base00-common&lt;/artifactId&gt;
	&lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;
<br><br>@Service
public class BookService {

    static Map&lt;String,Book&gt; map = new HashMap&lt;&gt;();
    static {
        map.put("SB1001",new Book("SB1001","随便","佚名",50));
        map.put("SB1002",new Book("SB1002","浮士德","歌德",60));
        map.put("SB1003",new Book("SB1003","我们仨","杨绛",25));
    }


    public Book findByIsbn(String isbn) {
        //查询数据库
        return map.get(isbn);
    }
}
<br><br>@Resource
BookService bookService;

@GetMapping("book/{isbn}")
public Book findBookByIsbn(@PathVariable("isbn") String isbn){
	return bookService.findByIsbn(isbn);
}
<br><br>创建一个普通springboot的web工程，并增加base00-common的依赖<br>用户服务<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base00-common&lt;/artifactId&gt;c
	&lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;c
<br><br>@Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
<br><br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";

    @Resource
    RestTemplate restTemplate;

    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }
}
<br><br>@RestController
public class UserController {

    @Resource
    UserService userService;

    @GetMapping("borrow/{isbn}")
    public Book searchBook(@PathVariable("isbn") String isbn) {
        return userService.searchBook(isbn);
    }
}
<br><br>是Spring cloud中的一个服务治理模块。<br>NetFlix公司一系列开源产品中的其中之一，它的主要作用是服务的注册和发现。<br>服务器端：也称为服务注册中心，提供服务的注册和发现。Eureka支持高可用的配置，当集群当中有节点（分片）出现故障时，Eureka会自动进入自我保护模式，它允许故障期间提供服务的发现和注册，当故障分片（节点）恢复后，集群的其他节点（分片）会把数据同步过来。<br>客户端：主要包含服务的生产者和服务消费者。服务的提供者要和服务器端维持心跳，来更新它的服务租约。可以将服务器端的注册信息缓存到本地，并周期性的更新服务状态。<br>找不到“/eureka.png”。<br><br>创建一个普通springboot工程base01-eureka，注意不要选择web依赖，增加Eureka服务端依赖<br><br>&lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.7.9&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base01-eureka&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
    &lt;name&gt;base01-eureka&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;spring-cloud.version&gt;2021.0.6&lt;/spring-cloud.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
<br><br>server:
  port: 7100
spring:
  application:
    name: eureka-server
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
      #是否从注册中心拉取信息，本身就是注册中心，不需要拉取信息
    fetch-registry: false
    #当前工程是否要到注册中心去注册， 本身就是注册中心，所以不需要
    register-with-eureka: false
  instance:
    hostname: localhost
<br><br>增加@EnableEurekaServer注解<br>@SpringBootApplication
@EnableEurekaServer  //启用Eureka的服务器端
public class Base01EurekaApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01EurekaApplication.class, args);
    }

}

<br><br>在原来的base01-provider上进行修改<br><br>在各自的节点内，增加以下相关内容，注意不要覆盖<br>&lt;properties&gt;
        &lt;spring-cloud.version&gt;Hoxton.SR9&lt;/spring-cloud.version&gt;
    &lt;/properties&gt;
    
    &lt;dependencies&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        
    &lt;/dependencies&gt;
     &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
            
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

<br><br>server:
  port: 8090
spring:
  application:
    name: bookapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>增加@EnableEurekaClient注解或者@EnableDiscoveryClient <br>@SpringBootApplication
@EnableEurekaClient  //启用Eureka的客户端
//@EnableDiscoveryClient  //使用于Eureka以及其他非Eureka的卡护短
public class Base01ProviderApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ProviderApplication.class, args);
    }

}

<br><br>在原来的base01-consumer上进行修改<br><br>参考服务提供者<br><br>server:
  port: 8081
spring:
  application:
    name: userapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>增加@EnableEurekaClient注解<br>@SpringBootApplication
@EnableEurekaClient
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>增加负载均衡<br>@Bean
@LoadBalanced  //启用ribbon的负载均衡
public RestTemplate restTemplate(){
    return new RestTemplate();
}
<br><br>用服务名替换原来的具体节点URL<br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";
    //用服务名替换具体的服务器的URL
    String host = "http://BOOKAPP";

    @Resource
    RestTemplate restTemplate;

    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }
}
<br><br>使用eureka.instance.prefer-ip-address=true显示ip<br>eureka.instance.ip-address=127.0.0.1来指定ip地址<br>server:
  port: 8070
spring:
  application:
    name: bookapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
  instance:
    prefer-ip-address: true
    ip-address: 127.0.0.1
<br><br>默认情况下，Eureka client是可以刷新的。当刷新客户端时，客户端暂时从服务器中取消注册，可能在短暂的时间内不提供给定的服务实例。设置配置：eureka.client.refresh.enable=false ，则不刷新客户端<br><br>默认情况下，Eureka服务器端在一定的时间内如没有接收某个服务端实例的心跳，EurekaServer将会注销该实例。当网络发生故障的时候，微服务就可能无法正常通信。Eureka通过自我保护来解决这个，在短时间内失去过多的客户端的时候，进入自我保护模式，一但进入该模式，就会保护服务列表，不再删除服务注册列表中的数据。当故障恢复以后，退出自我保护模式。<br><br><br>客户端的负载均衡器，进程内部的负载均衡器。默认的策略是轮询，还有一个是随机。可以自定义策略。<br>使用方式，在RestTemplate对象上加入@LoadBalanced<br><br>定义一个类（不能使用@Configuration注解），在此类当中增加一个@Bean注解的方法。返回RactorLoadbalancer接口的对象。<br>在配置类或者主启动类上使用@@LoadBalancerClients或者@LoadBalancerClient，指定上述定义的类为配置类<br><br>注意：千万不要增加@Configuration注解<br>public class LoadBalancerConfig {

    @Bean
    ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
                                                            LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new RandomLoadBalancer(loadBalancerClientFactory
                .getLazyProvider(name, ServiceInstanceListSupplier.class),
                name);
    }
}
<br><br>@SpringBootApplication
@EnableEurekaClient
//配置单个服务的负载均衡策略
//@LoadBalancerClient(value = "GOODS",configuration = LoadBalancerConfig.class)
//多个服务，采用同一个策略
@LoadBalancerClients(defaultConfiguration = LoadBalancerConfig.class)

//@LoadBalancerClients(value = {@LoadBalancerClient(value = "GOODS",configuration =LoadBalancerConfig.class )}
//                , defaultConfiguration = LoadBalancerConfig.class)
public class Base01OrderApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01OrderApplication.class, args);
    }


    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>需求：使用轮询方式访问服务器，每个服务器访问三次之后换下一个服务器<br>需要两个属性：1）用来记录当前的服务器被调用了几次 <br>​						 2）记录当前服务器是第几台服务器<br>如果当前的服务器已经被调用三次，换下一台服务器（i ）<br><br>public class MyRRLoadBalancer implements ReactorServiceInstanceLoadBalancer {
    private static final Log log = LogFactory.getLog(RoundRobinLoadBalancer.class);
    final AtomicInteger position;
    final String serviceId;
    ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider;
    int count=0;
    int MAX=3;

    public MyRRLoadBalancer(String serviceId, ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider) {
        this((new Random()).nextInt(1000),serviceId,serviceInstanceListSupplierProvider);
    }

    public MyRRLoadBalancer(int position, String serviceId, ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider) {
        this.position = new AtomicInteger(position);;
        this.serviceId = serviceId;
        this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider;
    }

    public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) {
        ServiceInstanceListSupplier supplier = (ServiceInstanceListSupplier)this.serviceInstanceListSupplierProvider.getIfAvailable(NoopServiceInstanceListSupplier::new);
        return supplier.get(request).next().map((serviceInstances) -&gt; {
            return this.processInstanceResponse(supplier, serviceInstances);
        });
    }

    private Response&lt;ServiceInstance&gt; processInstanceResponse(ServiceInstanceListSupplier supplier, List&lt;ServiceInstance&gt; serviceInstances) {
        Response&lt;ServiceInstance&gt; serviceInstanceResponse = this.getInstanceResponse(serviceInstances);
        if (supplier instanceof SelectedInstanceCallback &amp;&amp; serviceInstanceResponse.hasServer()) {
            ((SelectedInstanceCallback)supplier).selectedServiceInstance((ServiceInstance)serviceInstanceResponse.getServer());
        }

        return serviceInstanceResponse;
    }

    private Response&lt;ServiceInstance&gt; getInstanceResponse(List&lt;ServiceInstance&gt; instances) {
        if (instances.isEmpty()) {
            if (log.isWarnEnabled()) {
                log.warn("No servers available for service: " + this.serviceId);
            }

            return new EmptyResponse();
        } else if (instances.size() == 1) {
            return new DefaultResponse((ServiceInstance)instances.get(0));
        } else {
            int pos;
            if(count&lt;MAX) {
               pos =  this.position.get();
            } else {
               pos = this.position.incrementAndGet() &amp; 2147483647;
               count=0;
            }
            ServiceInstance instance = (ServiceInstance)instances.get(pos % instances.size());
            count++;
            return new DefaultResponse(instance);
        }
    }
}
<br><br>public class LoadBalancerConfig {

    //@Bean
    //ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
    //                                                        LoadBalancerClientFactory loadBalancerClientFactory) {
    //    String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
    //    return new RandomLoadBalancer(loadBalancerClientFactory
    //            .getLazyProvider(name, ServiceInstanceListSupplier.class),
    //            name);
    //}

    @Bean
    ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
                                                            LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new MyRRLoadBalancer(name,loadBalancerClientFactory
                .getLazyProvider(name, ServiceInstanceListSupplier.class)
                );
    }
}
<br><br>Ribbon是NetFlix发布的客户端负载均衡器，主要是用来控制HTTP和TCP客户端的行为。为Ribbon配置了服务提供者的地址列表后，Ribbon就可以基于某种负载均衡算法，自动地帮助服务消费者去请求对应的服务实例。Ribbon提供很多的负载均衡策略：轮询，随机，最少使用等。<br>Nginx和Ribbon的区别：<br>Nginx：是集中式的负载均衡设备（软件），Ribbon是进程内的负载均衡器，只是一个类库，集成在消费方的进程当中，消费方通过它来获取服务提供者的位置。<br>Nignx是服务器端负载均衡器，客户端的请求都是交给Nginx，然后由Nginx进行转发。<br>Ribbon：在调用微服务接口的时候，会在注册中心上获取注册的服务列表，缓存到本地。<br><br>@Configuration
public class AppConfig {

    @Bean
    public IRule iRule(){
        return new RandomRule();
    }
}

<br><br>RoundRobinRule：轮询，尝试超过10次以后，直接不提供服务。<br>RandomRule: 随机策略<br>Retry：先按照轮询的策略获取服务，如果服务失败，则在指定的时间内进行重试，获取可用的服务<br>WeightedResponseTimeRule：是对轮询策略的扩展，每30秒钟计算一次服务器的响应时间，以响应时间作为权重，响应时间越短，响应速度越快的服务器被选中的概率越大。<br>BestAvailableRule：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，在可用列表中选择一个并发量最小的服务实例。<br>AvailabilityFilteringRule：：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，再选择一个相对并发量较小的实例。<br>ZoneAvoidanceRule：根据服务提供者实例的所在区域以及响应的可用性选择服务器。<br><br>需求：使用轮询方式访问服务器，每个服务器访问三次之后换下一个服务器<br>需要两个属性：1）用来记录当前的服务器被调用了几次 <br>​						 2）记录当前服务器是第几台服务器<br>如果当前的服务器已经被调用三次，换下一台服务器（i ）<br><br>public class CustomizeRule extends AbstractLoadBalancerRule {
    //当前服务器索引的访问次数
    private  int total=0;
    //当前的服务器索引
    private  int currentIndex = 0;
    @Override
    public void initWithNiwsConfig(IClientConfig iClientConfig) {

    }

    @Override
    public Server choose(Object o) {
        return choose(getLoadBalancer(),o);
    }

    public Server choose(ILoadBalancer lb,Object key) {
        if(lb == null) {
            return null;
        }
        Server server = null;
        //隐形风险：如果一直找不到可用的服务器实例，导致死循环
        while (server==null){
            //获取可用的服务器列表
            List&lt;Server&gt; reachableServers = lb.getReachableServers();
            //获取所有的服务器列表
            List&lt;Server&gt; allServers = lb.getAllServers();
            int upCount = reachableServers.size();
            int serverCount = allServers.size();
            //没有可用的服务器实例，直接返回
            if (upCount==0) {
                return null;
            }
            if(total &lt; 3) {
                server=reachableServers.get(currentIndex);
                if (server==null) {
                    Thread.yield();
                    continue;
                }
                total++;
            } else {
                currentIndex = (currentIndex + 1) % upCount;
                //currentIndex++;
                //if (currentIndex== upCount) {
                //    currentIndex=0;
                //}
                server = reachableServers.get(currentIndex);
                if (server==null) {
                    Thread.yield();
                    continue;
                }
                total =1;
            }


        }
        return server;
    }
}
<br><br>@Configuration
public class AppConfig {

    @Bean
    public IRule iRule(){
        //return new RandomRule();
        return new CustomizeRule();
    }
}
<br><br>OpenFeign是NetFlix开发的声明式、模板化的HTTP客户端，用于HTTP请求调用的轻量级的框架，以Java接口注解的方式调用HTTP请求。OpenFeign支持SpringMVC注解，可以和Eureka整合一起使用<br>使用步骤<br>导入依赖<br>在消费者端编写Openfeign的客户端（接口）<br><br>增加以下依赖<br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>使用@FeignClient注解<br>@Service
//name指定要调用的服务名
@FeignClient(name="bookapp")
public interface UserServiceFeign {

    @RequestMapping(value = "book/{isbn}")
    Book findByIsbn(@PathVariable("isbn") String isbn);
}

<br><br>@RestController
public class UserController {


    @Resource
    UserServiceFeign userServiceFeign;

    @GetMapping("borrow/{isbn}")
    public Book searchBook(@PathVariable("isbn") String isbn) {
        return userServiceFeign.findByIsbn(isbn);
    }


}
<br><br>增加@EnableFeignClient注解<br>@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>fallback和fallbackFactory，主要用于熔断机制，调用失败时，走的回退方法，可以用来抛出异常或者给出默认的数据。<br>decode404:配置响应状态为404时，是否抛出FeignException<br><br>OpenFeign基于JDK的动态代理。<br>@EnableFeignClients：加上该注解，Springboot启动的时候，会导入FeignClientsRegistrar，扫描所有带有@FeignClient注解的接口<br>解析到@FeignClient的配置属性后，扩展Spring Bean Definition的注册逻辑上面，最终注册一个FeignClientFactoryBean，此对象会产生一个代理类对象。<br><br>可以参考在FeignClientProperties中的数据，主要是其内部类FeignClientConfiguration<br>feign:
  client:
    config:
      GOODS:  #指定服务
        connectTimeout: 1000
        readTimeout: 1000
<br><br><br>在微服务的架构当中，原本一个大的服务会拆分成多个小服务单元，服务单元之间无法避免会有相互的依赖关系。由于这种依赖关系，当某一个服务单元出现故障，容易引起故障的蔓延，最终有可能导致整个系统的瘫痪。<br>雪崩效应：当某一个服务单元出现故障，容易引起故障的蔓延，顺着调用链向上传递，最终有可能导致整个系统的瘫痪的现象。<br>产生场景<br>硬件故障：服务器宕机，机房断电，光纤被挖断...<br>流量激增：异常流量激增<br>缓存问题：由于缓存的问题，导致服务提供者的负荷增加了，引起服务的不可用。<br>程序BUG:  程序逻辑错误导致内存泄漏，JVM长时间进行FullGC。<br>同步等待：服务间采用同步调用机制，同步等待导致资源的耗尽。<br>Hystrix的目标：在于通过控制哪些远程访问、服务以及第三方的节点，从而对延迟或者故障提供更强大的容错能力。<br><br>NetFlix公司开源的，用于分布式系统的延迟和容错处理的开源库。用于隔离远程访问、服务以及第三方的库，防止级联失败，从而提升系统的可用性以及容错性。<br>CAP:
C: 一致性。分布式集群中节点（broker）上的数据要保持一致。<br>   A：可用性，要求服务端能够在指定的时间快速响应用户。<br>   P:  分区容错性，当集群或者分布式系统中的某一个节点（服务）出现问题后，整个集群或分布式系统的使用不能收到影响。<br>要么是CP，要么AP<br>服务降级： 假设系统比较忙或者不可用的情况下，给一个友好提示或者默认处理。触发降级的场合：程序运行异常、超时、服务熔断触发服务降级，线程池当中并发量达到阈值也可能导致服务降级。<br>服务熔断：达到最大服务访问量以后，直接拒绝访问，然后调用服务降级的方法给出友好提示。<br>服务限流：秒杀，抢红包等一系列高并发操作，严控一窝蜂的过来拥挤，让大家排队有序进行。<br><br>依赖<br>&lt;dependency&gt;
      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
      &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
 &lt;/dependency&gt;
<br>service中的方法<br>降级方法的参数和返回值要和原来方法一致<br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";
    //用服务名替换具体的服务器的URL
    String host = "http://BOOKAPP";

    @Resource
    RestTemplate restTemplate;

    @HystrixCommand(fallbackMethod = "fallback")
    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }

    public String getServer(){
        String url = host + "/server";
        String server = restTemplate.getForObject(url, String.class);
        return server;
    }

    public Book fallback(String isbn){
        return new Book("XXXX","服务器出现异常","",0.0);
    }


}
<br>启动类<br>增加@EnableHystrix或者@EnableCircuitBreaker注解<br>@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
@EnableHystrix  //启动Hystrix断路器
//@EnableCircuitBreaker   //启用容错保护组件（）
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>在Service类上使用@DefaultProperties注解，指定默认的服务降级的方法。<br>全局降级的方法，不能带有参数。<br>需要降级处理的方法上，不指定降级目标方法（回退方法），但是@HystrixCommand注解需要保留<br><br><br>feign:
  httpclient:
    connection-timeout: 2000  #连接服务端的时间 + 实际读取的时间
  hystrix:
    enabled: true #开启容错保护组件
<br><br>使用@FeignClient的fallback属性，设置成指定的类<br>处理降级的类，需要实现对应的接口<br>@Component
public class UserServiceFeignException implements UserServiceFeign {
    @Override
    public Book findByIsbn(String isbn) {
        return new Book("110","我是服务器，现在挂机中","",0.0);
    }
}
<br><br>使用@FeignClient的fallbackFactory属性，设置成指定的类<br>处理降级的类，实现FallbackFactory接口<br>@Component
public class UserServiceFeignFactory implements FallbackFactory&lt;UserServiceFeign&gt; {
    @Override
    public UserServiceFeign create(Throwable throwable) {
        return new UserServiceFeign() {
            @Override
            public Book findByIsbn(String isbn) {
                return new Book("666","光纤被挖断了","",0.0);
            }
        };
    }
}
<br><br>HystrixCommandProperties：普通参数
HystrixThreadPoolProperties：和线程池相关参数<br><br><br>创建一个web项目，要把web依赖去掉，增加hystrix-dashboard的依赖<br>配置项目增加hystrix.dashboard.proxy-stream-allow-list=*<br>在主启动类上要增@EnableHystrixDash注解<br>配置HystrixMetricsStreamServlet （可以使用配置文件，也可以在启动类当中注册）<br><br>增加两个依赖<br>hystrix-dashboard<br>actuator依赖<br>配置项目<br>management:
  endpoints:
    web:
      exposure:
        include: hystrix.stream
<br>启动项目测试<br>启动dashboard，输入localhost:端口号/hystrix<br>启动被监控项目，在前面的页面窗口，输入  localhost:被监控项目端口号/actuator/hystrix.stream<br><br><br>增加springboot-aop以及actuator依赖<br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-circuitbreaker-resilience4j&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>可用的配置项目：CircuitBreakerConfig当中，可以去参考<br><br><br>Gateway是Spring Cloud的子项目，Spring2.X提供的，Spring1.X用的是zuul（已经停更，进入维护期），提供简单有效的API路由管理方式。<br>Gateway作为zuul的替代品，是Springcloud生态中的网管。是基于WebFlux，高效能的Reactor模式。<br>Gateway的特点：<br>​	支持动态路由：能够匹配路由的任何请求属性<br>​	集成Spring Cloud的服务发现功能<br>​	支持限流功能<br>​	支持路径重写<br>​	提供断言（Predicate）以及过滤器（Filter），可以设置路由的一些条件<br><br>服务网关：路由转发 + 过滤器<br>路由转发：接收客户端的请求，将请求转发到指定的微服务上。<br>过滤器：可以帮助网关实现一些类似于AOP可以完成的一些操作，认证，服务的监控，限流。<br>案例： 有四个微服务，每个微服务都需要权限的认证<br>​          方案一：每个微服务都实现一下权限认证的代码===&gt;基本不会使用<br>​           方案二：将认证服务写成一个公共的服务，每个业务相关的微服务都来调用公共的服务。<br>​            方案三：将认证服务写到网关的过滤器<br><br>路由（Route）：路由是构建网关的基本模块。它由ID,目标URI,一系列的断言和过滤器组成。<br>断言（Predicate）：开发人员可以通过断言的相关设置，匹配HTTP请求中的参数内容，设置访问路由的条件<br>过滤器（Filter）：通过过滤器，可以在路由前后进行一些修改<br><br>创建一个springcloud项目<br>增加网关依赖，eureka客户端<br>配置相应的网关<br><br>spring:
  application:
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/**
      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
server:
  port: 10000
  #作为eureka的客户端的配置
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>断言（Predicates）是一组匹配规则，请求只有和规则相匹配时才可以访问<br>-Path : 匹配路径<br>-After ：  - After=时间 （在某个时间之后可以访问）由于是ZoneDateTime， 时间需要带有时区<br>​		 - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]<br>
<br>Before： - Before=时间 （在某个时间之前可以访问）
<br>-Between: - Before=时间1, 时间2<br>-Cookie,   -Cookie=phone,15911111111  phone为key，15911111111  <br>-Header： 表示请求头当中，需要包含某些内容，请求才可以访问<br>​	-Header=authenticator, 1111<br>-Method: 匹配请求方式，如 -Method=POST,GET<br>-Query：匹配请求的参数   -Query=price,\d+  : 请求当中需要携带price参数，且值必须数字才可以访问<br><br>Spring cloud通过过滤器在请求的前后进行一部分分更新<br>抽象类AbstractGatewayFilterFactory的子类对象，配置的时候，去掉GatewayFilterFactory后缀<br><br>yaml<br>(x)spring:
  application:
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/book/**  #限制访问的路径
            - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]
          filters:
            - AddRequestHeader=username,xiaoming
            - RedirectTo=302,http://www.baidu.com

      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
全局过滤器的顺序
OrderedFilter
<br><br><br>实现GlobalFilter接口，对所有的路由均有效。<br>@Component
public class MyGlobalFilter implements GlobalFilter {

    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //要求访问网关时，必须带有user参数，如果为null，则不放行，拒绝，不为null，则放行
        String user = exchange.getRequest().getQueryParams().getFirst("user");
        if (user == null) {
            System.out.println("===用户参数user没有设置");
            exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);
            exchange.getResponse().setComplete();  //设置拒绝
        }
        return chain.filter(exchange);  //放行
    }
}
<br><br>实现AbstractGatewayFilterFactory，要以GatewayFilterFactory作为类的后缀名<br>在指定路由的filters下定义对应的过滤器即可。<br>//定义过滤器
@Component
public class MyTestGatewayFilterFactory extends AbstractGatewayFilterFactory {
    @Override
    public GatewayFilter apply(Object config) {

        return new GatewayFilter() {
            @Override
            public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
                System.out.println("=========局部过滤器=====================");
                return chain.filter(exchange);
            }
        };
    }
}
<br>配置过滤器<br>spring:
  application:
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/book/**  #限制访问的路径
            - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]
          filters:
            - MyTest
            #- AddRequestHeader=username,xiaoming
            #- RedirectTo=302,http://www.baidu.com

      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
<br><br>Naming Configuration Service： 注册中心 + 配置中心 + 配置总线的组合组件<br>中文官网：<a rel="noopener nofollow" class="external-link" href="https://nacos.io/zh-cn/index.html" target="_blank">https://nacos.io/zh-cn/index.html</a><br>英文spring： spring.io<br>下载：<a rel="noopener nofollow" class="external-link" href="https://github.com/alibaba/nacos" target="_blank">https://github.com/alibaba/nacos</a><br>使用nacos，不需要单独在编写一个nacos服务器端，已经提供。nacos是基于java代码实现。阿里出品。<br><br>增加依赖<br>配置<br>在主启动类增加@EnableDiscoveryClient注解<br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
            &lt;version&gt;2021.0.4.0&lt;/version&gt;
        &lt;/dependency&gt;
		
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
            &lt;version&gt;2021.0.4.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- springcloud 2020.x只用去掉了bootstrap，需要重新加上 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;
            &lt;version&gt;3.0.3&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>bootstrap.yml ：会在application.yml读取之前先读，其中的内容是不会被覆盖<br><br>在nacos配置中心设置配置文件时，文件的dataId由三个部分组成，prefix，profile（dev，test，prod），file-extension（yaml或者properties，根据选择的文件类型来决定）<br>​	prefix-profile.file-extension<br>prefix: 默认为spring.application.name的值(例：项目：nacos-config)，也可以通过配置项spring.cloud.nacos.config.prefix<br>profile: spring.profiles.active对应的环境，如果没有设置多环境，则文件名  prefix.file-extension<br>file-extension: 目前只支持properties和yaml<br>namespace：项目隔离的作用<br><br>Sentinel是alibaba提供的用于实时监控、流量控制、异常熔断等管理工具，它可以于nacos进行组合使用，可以对项目进行图形化的配置和管理。<br>运行启动sentinel，可以通过--server.port指定端口号<br>java -jar sentinel-dashboard-1.8.2.jar --server.port=8081
<br><br><br><img style="zoom:80%;" alt="流控规则" src="\流控规则.png" referrerpolicy="no-referrer">
![Uploading file...4mlyc]()<br>资源名：唯一名称，默认为请求路径<br>针对来源：sentinel可以针对调用者进行限流，不填写则默认为default，对所有来源的总和进行限流，如果设置的话，则设置调用者的服务名。<br>QPS: 每秒钟请求的数量，当每秒钟的请求数量达到阈值的时候，进行限流处理。<br>并发线程数：调用资源的并发线程量达到阈值，进行限流<br>单机阈值/集群阈值/均摊阈值：单机的情况下设置单机阈值，集群的情况可以选择集群阈值或者均摊阈值<br>流控模式：<br>​	直接：达到阈值的时候，进行直接限流（快速失败，warm up，链路）<br>​	关联：当关联的资源达到阈值，就限流我自己。<br>​	链路：当达到阈值的时候，限制某个入口对应链路上的处理（限流）<br>流控效果：<br>​	直接失败：服务降级，提示服务限流的消息<br>​	warm up： 有一个冷加载因子（默认是3），经过预热时常后，达到QPS<br>	@GetMapping("test") // /test
    //@SentinelResource(value = "test",fallback = "fallbackMethod")
    @SentinelResource(value = "test",fallback = "fallbackMethod"
            ,fallbackClass = InfoFallBackComponent.class)
    public String test(){
        System.out.println("test: "  + LocalDateTime.now());
        return "game over";
    }

    //public String fallbackMethod(Throwable e){
    //    return "方法被限流";
    //}
<br><br>Sentinel熔断降级主要是适用某个资源请求处理不稳定的情况下，对此资源进行调用限制。<br>不稳定的因素：调用时间比较常，异常出现的频率高<br><img style="zoom:80%;" alt="熔断规则" src="\熔断规则.png" referrerpolicy="no-referrer"><br>统计1秒种（1000ms）时间内，如果请求的次数达到2次以上（最小请求数），慢调用（请求的时间超过100猫喵）的比例，达到0.5的情况，就会熔断20秒。<br><br>调用后端接口的参数，根据方法上来，0为第一个参数，1为第二个参数。<br>资源名：可以是请求的url，也可以是@SentinelResource的value值。<br>blockHandler对应的方法，除了参数以及返回值之外，还需要增加一个BlockException参数<br>sentinel和openfeign进行整合，如何进行服务降级处理。<br>@GetMapping("/testHotkey")
    @SentinelResource(value = "/testHotkey",blockHandler = "blockHandler")
    public String testHotKey(String p1,String p2) {
        return "success";
    }
    public String blockHandler(String p1, String p2, BlockException ex) {
        return "blockHandler";
    }
]]></description><link>教程\21、spring cloud.html</link><guid isPermaLink="false">教程/21、spring cloud.md</guid><pubDate>Fri, 11 Jul 2025 08:19:20 GMT</pubDate><enclosure url="\流控规则.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\流控规则.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1. Git 概念]]></title><description><![CDATA[ 
 <br><img src="https://cdn.nlark.com/yuque/0/2023/png/39031477/1701250560302-586462bb-4148-433c-b9d8-669b324322c3.png" referrerpolicy="no-referrer"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/39031477/1701250454342-0254d3c3-8cb2-4623-b5a5-f0764b56c517.png" referrerpolicy="no-referrer"><br><br><br>同生活中的许多伟大事件一样，Git诞生于一个极富纷争大创新的年代。Linux内核开源项目有着为数众多的参与者。绝大多数的Linux内核维护工作都花在了提交补丁和保存文档的繁琐事务上（1991~2002年间）。到2002年，整个项目组开始启用分布式版本控制系统BitKeeper来管理和维护代码。<br>到2005年的时候，开发BitKeeper的商业公司同Linux内核开源社区的合作关系结束，他们收回了免费使用BitKeeper的权利。迫使Linux开源社区不得不吸取教训，只有开发一套属于自己的版本控制系统才不至于重蹈覆辙。他们对新的系统订了若干目标：<br>
<br>速度
<br>简单的设计
<br>对非线性开发模式的强力支持（允许上千个并行开发的分支）
<br>完全分布式
<br>有能力高效管理类似Linux内核一样的超大规模项目（速度和数据量）
<br><img align="center" style="zoom:50%;" alt="01.Linux之父" src="\01.Linux之父.png" referrerpolicy="no-referrer"><br><br><br>SVN是集中式版本控制系统，版本库是集中放置在中央服务器的，而干活的时候，用的是自己的电脑，所以首先要从中央服务器哪里得到最新的版本，然后干活，干完后，需要把自己做完的活推送到中央服务器。集中式版本控制系统是必须联网才能工作，如果在局域网还可以，贷款勾搭，速度够快，如果在互联网下，可能网速就没那么快了。<br>集中管理方式在一定程度上看到其他开发人员在干什么，而管理员也可以很轻松掌握每个人的开发权限。集中式版本控制工具的缺点：<br>
<br>
服务器单点故障

<br>
容错性差
<img style="zoom:67%;" alt="02.01SVN" src="\01.SVN.png" referrerpolicy="no-referrer">

<br><br>Git是分布式版本控制系统，它没有中央服务器的，每个人的电脑就是一个完整的版本库，这样，工作就不需要互联网，因为版本都是在自己的电脑上。既然每个人的电脑都有一个完整的版本库，如何多人协作呢？比如说自己在电脑上改了文件A，其他人也在电脑上改了文件A，这是只需要把各自的修改推送给对方，就可以互相看到对方的修改了。<br><img style="zoom: 67%;" alt="02.GIT控制" src="\01.GIT控制.png" referrerpolicy="no-referrer"><br><br>一般工作流程如下：<br>
<br>从远程仓库中克隆Git资源作为本地仓库。
<br>从本地仓库中checkout代码然后进行代码修改。
<br>在提交前先将代码提交到暂存区。
<br>提交修改。提交到本地仓库。本地仓库中保存修改的各个历史版本。
<br>在修改完成后，需要和团队成员共享代码时，可以将代码push到远程仓库。找不到“/02.git常用命令流程图.png”。
<br><br>​		最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。不过，慢慢地有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几个大平台上正常运行了。<br>下载地址：<a rel="noopener nofollow" class="external-link" href="http://git-scm.com/downloads" target="_blank">http://git-scm.com/downloads</a><br><img style="zoom: 67%;" alt="03.Git下载" src="\03.Git下载.png" referrerpolicy="no-referrer"><br>上述路径下载太慢，可以使用国内的镜像<br><a rel="noopener nofollow" class="external-link" href="https://npm.taobao.org/mirrors/git-for-windows/" target="_blank">https://npm.taobao.org/mirrors/git-for-windows/</a><br>
<br>安装Git：默认安装
<br>安装TortoiseGit
<br>"04.TortoiseGit安装01.md" 未创建，点击以创建。<br>找不到“/04.TortoiseGit安装02.png”。<br>
<br>安装TortoiseGit中文语言包
<br>04.TortoiseGit中文语言包.png<br><br><br><br>​		版本库又名仓库。可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来。每个文件的修改、删除都可以被Git跟踪到，以便任何时候可以追踪历史，或者在将来某个时刻可以还原。由于Git是分布式版本管理工具，所以Git不需要互联网也具有完整的版本管理能力。<br>方法一：在repo1文件夹中右击鼠标--》【Git GUI here】--【repository】--【new】<br>找不到“/04.创建版本库.方法一.png”。<br>方法二：在repo1文件夹中右击鼠标--》【Git在这里创建版本库】<br>04.创建版本库.方法二.png<br><br>创建好的目录<br>找不到“/04.git版本库目录.png”。<br>​		.git：本地仓库版本库<br>​		Repo1：工作目录<br>如果想要向本地仓库添加文件，必须放入工作目录中（repo1），否则加不进来。<br>创建文件HelloWorld.txt，右击，点击【TortoiseGit】==》【添加】。<br>04.上传文件.png<br><br>点击【确定】，重启下电脑，HelloWorld.txt会有个小加号。此时加入的是暂存区。<br><br>Git和其他版本控制系统如SVN的一个不同之处就是暂存区的概念。<br>工作区<br>就是你在电脑里能看到的目录。比如上图中的git-repository就是工作区。.git隐藏文件夹是版本库。Git版本库里存了很多东西，最重要的就是暂存区（stage），还有git自动为我们创建的第一个分支master，以及指向master的一个指针叫HEAD<br><img style="zoom: 80%;" alt="04.工作区和暂存区" src="\04.工作区和暂存区.png" referrerpolicy="no-referrer"><br><br><br>在本地仓库目录中，右击鼠标， 在弹出菜单上点击【git提交-&gt;本地仓库】，输入提交日志。点击【提交】。<br>
<br>
弹出菜单
<img style="zoom:80%;" alt="05.提交到本地仓库01" src="\05.提交到本地仓库01.png" referrerpolicy="no-referrer">

<br>
提交找不到“/05.提交到本地仓库02.png”。日志

<br>
提交结果
找不到“/05.提交到本地仓库03.png”。

<br><br>【tortoiseGit】--》版本库浏览器<br><img style="zoom:80%;" alt="06.本地库浏览器" src="\06.本地库浏览器.png" referrerpolicy="no-referrer"><br><br>带有红色感叹号的文件，是被修改过的。<br>找不到“/06.文件修改后提交.png”。<br>修改过的文件提交：选中文件，右击鼠标--》【Git提交--》master】<br><br>
<br>方法一

<br>直接删除文件
<br>右击鼠标--》【Git提交--》master】


<br>方法二

<br>选中文件--》右击鼠标--》【TurtoiseGit】--》删除
<br>右击鼠标--》【Git提交--》master】


<br><br><br>
<br>
​	需要在github上有账户，没有账户需要先注册账户，然后登陆系统。点击【start a project】
找不到“/07.创建远程仓库01.png”。

<br>
设置仓库属性
找不到“/07.创建远程仓库02.png”。
可以使用码云  <a data-tooltip-position="top" aria-label="https://gitee.com/%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%E5%92%8CGithup%E4%B8%80%E6%A0%B7%E7%9A%84%E6%93%8D%E4%BD%9C" rel="noopener nofollow" class="external-link" href="https://gitee.com/%EF%BC%8C%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%E5%92%8CGithup%E4%B8%80%E6%A0%B7%E7%9A%84%E6%93%8D%E4%BD%9C" target="_blank">https://gitee.com/，使用方式和Githup一样的操作</a>

<br><br><br>​		SSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。<br><br>​		需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。<br><br>
<br>在工作目录右击鼠标，点击【Git Bash Here】命令
<br>找不到“/08.创建秘钥.png”。<br>
<br>
输入命令
ssh-keygen -t rsa

找不到“/08.创建秘钥02.png”。

<br>
密钥存储
SSH密钥存储在C盘当前用户的.ssh目录下
找不到“/08.创建秘钥03_秘钥本地存储.png”。

<br><br>
<br>
用户设置
09.设置公钥01.setting.png<br>

<br>
SSH and GPG keys
找不到“/09.设置公钥02.setting.png”。

<br>
New SSH key
将.pub结尾的公钥拷贝到key中，title随便写
找不到“/09.设置公钥03.setting.png”。

<br><br><br>找不到“/10.命令行推送.png”。<br><br>
<br>
工作目录中右击鼠标，点击【Git同步】
找不到“/10.Git同步.png”。

<br>
点击【管理】
<img style="zoom:80%;" alt="10.Git管理-远端01" src="\10.Git管理-远端01.png" referrerpolicy="no-referrer">

<br>
先设置网络中的SSH客户端
<img style="zoom:80%;" alt="10.Git管理03-SSH客户端" src="\10.Git管理03-SSH客户端.png" referrerpolicy="no-referrer">

<br>
设置Git远端
<img style="zoom: 80%;" alt="10.Git管理04-远端" src="\10.Git管理04-远端.png" referrerpolicy="no-referrer">
​	<img style="padding-left:50px;" alt="10.Git管理05-远端" src="\10.Git管理05-远端.png" referrerpolicy="no-referrer">

<br>
点击【推送】
找不到“/10.Git管理05-推送01.png”。
找不到“/10.Git管理05-推送02.png”。

<br>
刷新github的仓库
<img style="zoom:80%;" alt="10.刷新github的仓库" src="\10.刷新github的仓库.png" referrerpolicy="no-referrer">

<br><br>
<br>
设置远端
设置好URL，远端名，点击确定
<img style="zoom:80%;" alt="11.Http01远端设置" src="\11.Http01远端设置.png" referrerpolicy="no-referrer">

<br>
点击推送【或拉取】，需要验证，输入用户名、密码
设置用户名，密码
<img style="zoom:80%;" alt="11.Http03用户名密码" src="\11.Http03用户名密码.png" referrerpolicy="no-referrer">

<br>
正常提交
<img style="zoom:80%;" alt="11.Http04提交成功" src="\11.Http04提交成功.png" referrerpolicy="no-referrer">

<br><br>地址：<a rel="noopener nofollow" class="external-link" href="https://gitee.com" target="_blank">https://gitee.com</a><br><br>
<br>
登录码云，找到仓库，获取到地址
<img style="zoom: 67%;" alt="12.push到码云01" src="\12.push到码云01.png" referrerpolicy="no-referrer">

<br>
设置远端
点击【克隆/下载】，copy出地址，设置Git同步的远端，如下图：
<img style="zoom:80%;" alt="12.push到码云02" src="\12.push到码云02.png" referrerpolicy="no-referrer">

<br>
推送
第一次推送时，需要选中【强制】复选框
<img style="zoom:80%;" alt="12.push到码云03" src="\12.push到码云03.png" referrerpolicy="no-referrer">

<br><br>
<br>
进入仓库页面
找不到“/12.码云仓库管理01.png”。

<br>
点击【管理】
<img style="zoom:80%;" alt="12.码云仓库管理02" src="\12.码云仓库管理02.png" referrerpolicy="no-referrer">

<br><br><br>设置方法：file=&gt; setting =&gt; Version Control	=&gt; Gitee <br><img style="zoom:80%;" alt="13.idea设置码云账户" src="\13.idea设置码云账户.png" referrerpolicy="no-referrer"><br><br>将idea中的项目交给码云托管<br>
<br>
共享到Gitee： VCS=&gt;Import into Version Control =&gt; Share Project on Gitee
找不到“/13.托管项目.png”。

<br>
设置仓库名
找不到“/13.托管项目_仓库名称.png”。

<br>
设置要托管的代码
找不到“/13.托管项目_托管代码.png”。

<br><br>
<br>
add到暂存区
选择代码文件或package（如果package未提交过，需要一起提交），右击鼠标=&gt;Git =》add
找不到“/14.提交代码_add.png”。

<br>
提交到本地库
Git=》Commit Directory
找不到“/14.提交代码_commit.png”。
选择文件后，点击commit

<br>
提交到远程库Gitee
Git=&gt;repository=》push
找不到“/14.提交代码_push代码.png”。

<br><br>方法一：welcome页面上导入==&gt;Get from Version Control<br>方法二：已有项目界面==&gt;VCS ==&gt;Get from Version Control<br>找不到“/14.提交代码_导入Gitee项目.png”。]]></description><link>教程\22、Git基础.html</link><guid isPermaLink="false">教程/22、Git基础.md</guid><pubDate>Wed, 11 Jun 2025 06:45:02 GMT</pubDate><enclosure url="https://cdn.nlark.com/yuque/0/2023/png/39031477/1701250560302-586462bb-4148-433c-b9d8-669b324322c3.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://cdn.nlark.com/yuque/0/2023/png/39031477/1701250560302-586462bb-4148-433c-b9d8-669b324322c3.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mongodb基础]]></title><description><![CDATA[ 
 <br><br><br>MongoDB是一个基于分布式文件存储 [1] 的数据库。由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/C%2B%2B/99272?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/C%2B%2B/99272?fromModule=lemma_inlink" target="_blank">C++</a>语言编写。旨在为WEB应用提供可扩展的高性能数据<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%AD%98%E5%82%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/10864850?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%AD%98%E5%82%A8%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/10864850?fromModule=lemma_inlink" target="_blank">存储解决方案</a>。<br>MongoDB是一个介于<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/1237340?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/1237340?fromModule=lemma_inlink" target="_blank">关系数据库</a>和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。它支持的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1450?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1450?fromModule=lemma_inlink" target="_blank">数据结构</a>非常松散，是类似<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/json?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/json?fromModule=lemma_inlink" target="_blank">json</a>的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/bson?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/bson?fromModule=lemma_inlink" target="_blank">bson</a>格式，因此可以存储比较复杂的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/10997964?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/10997964?fromModule=lemma_inlink" target="_blank">数据类型</a>。Mongo最大的特点是它支持的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/2661811?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/2661811?fromModule=lemma_inlink" target="_blank">查询语言</a>非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。<br>MongoDB是一个非常热门的非关系型数据库，用来做离线数据分析比较多。<br>支持操作系统较多：Linux，MAC, windows<br>提供了多种语言的驱动：java，php，python，Ruby，C++<br><br>直播数据，打赏数据，粉丝数据，收藏数据，浏览数据<br>​	存储方式： 数据库  ，MongoDb<br>​	特点：修改频度很高，比较适合传统数据库和临时存储相结合<br>游戏的装备以及道具数据<br>​	存储方式： 数据库  ，MongoDb<br>​	特点：修改频度很高，比较适合传统数据库和临时存储相结合<br>物联网数据：<br>​	存储： Mongodb<br>​	特点：修改频度很高，只做临时存储<br><br>文档（Document）：Mongodb的基本单元，由JSON键值对（Key-value）组成，类似于关系型数据库当中的一行<br>集合（Collection）：一个集合可以包含多个文档，类似于关系型数据库当中的表<br>数据库（Database）：一个数据库可以包含多个集合，可以在mongodb当中创建多个数据库。<br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;
        &lt;/dependency&gt;
<br><br>server:
  port: 8085
spring:
  application:
    name: mongo
  data:
    mongodb:  #smart为数据库名
      uri: mongodb://localhost:27017/smart
<br><br><br>直接注入MongoTemplate对象，并调用它的方法<br>@RestController
public class DeviceTypeController {

    @Resource
    MongoTemplate mongoTemplate;

    @GetMapping("add")
    public String addDeviceType(){
        DeviceType deviceType = new DeviceType();
        deviceType.setId(111);
        deviceType.setName("办公电脑");
        mongoTemplate.insert(deviceType);
        return "success";
    }


    @GetMapping("save")
    public String saveDeviceType(int id,String name){
        DeviceType deviceType = new DeviceType();
        deviceType.setId(id);
        deviceType.setName(name);
        //如果有数据，则修改，没有则增加
        mongoTemplate.save(deviceType);

        return "success";
    }


    @GetMapping("update")
    public String update(int id,String name){

        Query query = new Query(Criteria.where("id").is(id));
        Update update = new Update().set("name",name);
        mongoTemplate.updateFirst(query,update,DeviceType.class);

        return "update success";
    }

}
<br><br><br>public interface DeviceRepository extends MongoRepository&lt;Device,Integer&gt; {
    List&lt;Device&gt; findByNameLike(String name);

    List&lt;Device&gt; findByNameLikeAndSn(String name,String sn);

}
<br><br>@RestController
@RequestMapping("device")
public class DeviceController {

    @Resource
    DeviceRepository deviceRepository;

    @GetMapping("add/{id}")
    public String addDevice(@PathVariable("id") int id){
        Device device = new Device();
        device.setId(id);
        device.setName("土壤酸碱度传感器111");
        device.setSn("1203");
        deviceRepository.insert(device);
        return "add success";
    }

    //按照id查询
    @GetMapping("findOne/{id}")
    public String findOne(@PathVariable("id") Integer id){
        Optional&lt;Device&gt; optionalDevice = deviceRepository.findById(id);
        if (optionalDevice.isPresent()){
            //获取数据
            System.out.println(optionalDevice.get());
        }

        return "find success";
    }

    //按照id查询
    @GetMapping("findByName/{name}")
    public String findByName(@PathVariable("name") String  name){
        List&lt;Device&gt; lists = deviceRepository.findByNameLike(name);
        lists.stream().forEach(System.out::println);

        return "find success";
    }
}

]]></description><link>教程\23、Mongodb基础.html</link><guid isPermaLink="false">教程/23、Mongodb基础.md</guid><pubDate>Tue, 19 Sep 2023 03:17:15 GMT</pubDate></item><item><title><![CDATA[未命名]]></title><description><![CDATA[ 
 <br>Vicious 笔记]]></description><link>教程\未命名.html</link><guid isPermaLink="false">教程/未命名.md</guid><pubDate>Fri, 29 Dec 2023 09:59:04 GMT</pubDate></item><item><title><![CDATA[未命名 1]]></title><description><![CDATA[ 
 <br>13:50:37.453/V: 开始运行 [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js].
13:50:37.460/D: 今天是：2024-6-20
13:50:37.970/D: 设备未锁定，熄屏
13:50:39.001/D: 开始解锁设备
13:50:39.916/D: 滑动成功
13:50:40.972/D: 解锁完成
13:50:41.981/E: FAILED ASSERTION<br>java.lang.IllegalStateException: FAILED ASSERTION
at org.mozilla.javascript.Kit.codeBug(Kit.java:353)
at org.autojs.autojs.rhino.debug.Dim.interrupted(Dim.java:804)
at org.autojs.autojs.rhino.debug.Dim.handleExceptionThrown(Dim.java:535)
at org.autojs.autojs.rhino.debug.Dim.-ExternalSyntheticLambda0.run(Unknown Source:6)
at android.os.Handler.handleCallback(Handler.java:958)
at android.os.Handler.dispatchMessage(Handler.java:99)
at android.os.Looper.loopOnce(Looper.java:224)
at android.os.Looper.loop(Looper.java:318)
at org.autojs.autojs.engine.LoopBasedJavaScriptEngine.execute(LoopBasedJavaScriptEngine.java:68)
at org.autojs.autojs.engine.LoopBasedJavaScriptEngine.execute(LoopBasedJavaScriptEngine.java:38)
at org.autojs.autojs.execution.LoopedBasedJavaScriptExecution.doExecution(LoopedBasedJavaScriptExecution.java:45)
at org.autojs.autojs.execution.RunnableScriptExecution.execute(RunnableScriptExecution.java:40)
at org.autojs.autojs.execution.RunnableScriptExecution.execute(RunnableScriptExecution.java:34)
at org.autojs.autojs.execution.RunnableScriptExecution.run(RunnableScriptExecution.java:28)
at java.lang.Thread.run(Thread.java:1012)
13:50:41.984/V: [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js] 运行结束 (用时 4.528 秒)<br>13:53:15.931/V: 开始运行 [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js [cache]].
13:53:15.937/D: 今天是：2024-6-20
13:53:16.441/D: 设备未锁定，熄屏
13:53:17.461/D: 开始解锁设备
13:53:18.370/D: 滑动成功
13:53:19.456/D: 解锁完成
13:53:25.468/E: Wrapped java.lang.NullPointerException: Parameter specified as non-null is null: method org.autojs.autojs.runtime.api.AppUtils.launchSettings, parameter packageName (file:///android_asset/modules/app.js#400)
Wrapped java.lang.NullPointerException: Parameter specified as non-null is null: method org.autojs.autojs.runtime.api.AppUtils.launchSettings, parameter packageName
at file:///android_asset/modules/app.js:400:0
at file:///android_asset/modules/app.js:393:0
at killAPP (/data/user/0/org.autojs.autojs6/cache/tmp-scripts/tmp-1718862795475.js:94:0)
at main (/data/user/0/org.autojs.autojs6/cache/tmp-scripts/tmp-1718862795475.js:558:0)
at /data/user/0/org.autojs.autojs6/cache/tmp-scripts/tmp-1718862795475.js:61:0<br>13:53:25.470/V: [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js [cache]] 运行结束 (用时 9.538 秒)<br>13:54:39.683/V: 开始运行 [cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js].
13:55:29.046/D: 今天是：2024-6-20
13:55:29.549/D: 设备未锁定，熄屏
13:55:30.573/D: 开始解锁设备
13:55:31.481/D: 滑动成功
13:55:32.540/D: 解锁完成
13:55:38.546/D: 重开小米社区 避免变数窗口
13:55:38.549/D: 打开小米社区
14:45:13.741/D: 定时结束
14:45:13.740/D: 定时结束
14:45:13.761/V: [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js] 运行结束 (用时 2984.718 秒)<br>14:45:13.766/V: [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js [cache]] 运行结束 (用时 3034.082 秒)<br>13:03:38.103/V: 开始运行 [$cwd/小米社区签到小尘二改密码解锁版v0.7.4beta.js].
13:03:38.108/D: 今天是：2024-6-21
13:03:38.612/D: 设备未锁定，熄屏
13:03:39.631/D: 开始解锁设备
13:03:40.537/D: 滑动成功
13:03:41.617/D: 解锁完成
13:03:42.668/E: Wrapped java.lang.NullPointerException: Parameter specified as non-null is null: method org.autojs.autojs.runtime.api.AppUtils.launchSettings, parameter packageName (file:///android_asset/modules/app.js#400)
Wrapped java.lang.NullPointerException: Parameter specified as non-null is null: method org.autojs.autojs.runtime.api.AppUtils.launchSettings, parameter packageName
at file:///android_asset/modules/app.js:400:0
at file:///android_asset/modules/app.js:393:0
at killAPP (/stora]]></description><link>教程\未命名 1.html</link><guid isPermaLink="false">教程/未命名 1.md</guid><pubDate>Mon, 24 Jun 2024 02:05:46 GMT</pubDate></item><item><title><![CDATA[未命名 2]]></title><description><![CDATA[ 
 ]]></description><link>教程\未命名 2.html</link><guid isPermaLink="false">教程/未命名 2.md</guid><pubDate>Fri, 28 Jun 2024 08:15:28 GMT</pubDate></item><item><title><![CDATA[一、简介]]></title><description><![CDATA[ 
 <br><br><br>了解linux<br>修改虚拟机ip为静态：<br>
<br>vim /etc/sysconfig/network-scripts/ifcfg-ens33

<br>BOOTPROTO="static"
<br>IPADDR="192.168.146.101"
<br>NETMASK=255.255.255.0
<br>GATEWAY=192.168.146.2
<br>DNSI=192.168.146.2


<br>重启网络服务：systemctl restart network
<br><br>软件在windows上开发完成后，把jar或war包交给运维，运维部署到linux或阿里云时，可能会因为环境不同或配置不同，而导致不能正常工作。用docker就可能方便的解决该问题。<br><br>如果到宠物店只买回一条鱼，回家后可能因为环境不适应而死亡，而从宠物店买回的是带鱼缸和鱼这一整套环境就不会出问题。也就是从系统底层至上层整体打包成镜像文件，从而达到完全跨平台的到处运行。<br><br>Docker是一个精简版的虚拟机，只是少了对操作系统和硬件的虚拟，所以启动速度是秒级的,而虚拟机的启动则是分钟级的。<br>Docker是基于Go语言实现的云开源项目，Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。<br>Docker的主要目标是“build，Ship and Run Any App，Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次封装，到处运行”。
将应用运行在Docker容器上面，而Docker容器在任何操作系统上一致的，这就是实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机器上就可以简化操作、一键部署。<br>找不到“/01.docker和虚拟机.png”。<br>找不到“/02.docker和虚拟机.png”。<br><br>docker三要素：镜像、容器、仓库<br>
<br>
镜像：相当于java中的类,如Person。应用程序和配置及依赖打包成一个可运行的环境，这个包就是镜像文件。

<br>
容器：相当于new Person产生对象,容器是以镜像为模板产生，可把容器看成镜像一个简化版的linux环境和若干运行在其中的应用程序。

<br>
仓库：是集中存放镜像的地方。

<br>
仓库注册服务器：放着多个仓库。

<br>找不到“/03.docker架构.jpg”。<br><br><br>#yum install -y yum-utils device-mapper-persistent-data lvm2
yum install -y device-mapper-persistent-data lvm2
<br>lvm2（LogicalVolume Manage，Version2），逻辑卷管理工具。它是Linux环境下对磁盘分区进行管理的一种机制，将一个或多个底层块设备组织成一个逻辑设备。通过LVM管理员可以轻松管理磁盘分区，使用LVM与传统的分区方法相比有很多的优势，如：容量的分配更加灵活、逻辑卷的扩展和缩减更加方便、使用snapshot（快照）来备份数据也非常方便。通过本文你可以快速了解LVM2的使用方法。<br><br>yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
<br>如果安装出错，可以进入到  /etc/yum.repos.d目录下，将dockerxxx.repo相关的文件删除后，再次使用上述命令来指定镜像。<br><br>yum makecache fast   #为加快安装速度，对缓存加速
yum -y install docker-ce
<br>如果 /etc/ yum.repos.d/<br><br>docker version 或  docker --version<br>#简单的版本信息
docker --version
#详细的版本信息
docker version
<br><br>
<br>启动docker:   systemctl start docker
<br>重启:  systemctl restart docker
<br>卸载docker:   yum remove docker
<br>设置开机启动:  systemctl enable docker
<br><br>是一个代理仓库，放了一些镜像，因为中央仓库<a data-tooltip-position="top" aria-label="https://hub.docker.com%E6%98%AF%E5%9B%BD%E5%A4%96%E7%BD%91%E7%AB%99%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%85%A2%EF%BC%8C%E6%9C%89%E4%B8%A4%E4%B8%AA%E4%BA%91%E5%8F%AF%E7%94%A8%EF%BC%8C%E7%BD%91%E6%98%93%E4%BA%91%E5%92%8C%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%9B%B4%E5%85%A8%E9%9D%A2%EF%BC%8C%E5%85%B6%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps://www.aliyun.com/product/acr" rel="noopener nofollow" class="external-link" href="https://hub.docker.com%E6%98%AF%E5%9B%BD%E5%A4%96%E7%BD%91%E7%AB%99%EF%BC%8C%E9%9D%9E%E5%B8%B8%E6%85%A2%EF%BC%8C%E6%9C%89%E4%B8%A4%E4%B8%AA%E4%BA%91%E5%8F%AF%E7%94%A8%EF%BC%8C%E7%BD%91%E6%98%93%E4%BA%91%E5%92%8C%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%EF%BC%8C%E6%9B%B4%E5%85%A8%E9%9D%A2%EF%BC%8C%E5%85%B6%E9%95%9C%E5%83%8F%E5%9C%B0%E5%9D%80%EF%BC%9Ahttps://www.aliyun.com/product/acr" target="_blank">https://hub.docker.com是国外网站，非常慢，有两个云可用，网易云和阿里云，推荐使用阿里云，更全面，其镜像地址：https://www.aliyun.com/product/acr</a><br>获取加速器地址的方法如下：<br>
<br>
注册--&gt;可使用淘宝帐号注册,搜索容器镜像服务

<br>
获取加速器地址：通过网址<a data-tooltip-position="top" aria-label="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors%E8%8E%B7%E5%8F%96" rel="noopener nofollow" class="external-link" href="https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors%E8%8E%B7%E5%8F%96" target="_blank">https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors获取</a>

<br>
配置加速器

<br>
mkdir /etc/docker

<br>
vi /etc/docker/daemon.json

<br>
内容如下：每个帐号都不同，使用下面一个也可以。
{
"registry-mirrors": ["https://c40fbq35.mirror.aliyuncs.com"]
}

<br>
使配置生效：systemctl daemon-reload，systemctl restart docker
#加载文件
systemctl daemon-reload
#重新启动
systemctl restart docker




<br>
helloworld镜像生成容器:docker run hello-world，默认先从本地的镜像中找，没找到就从阿里云中找其镜像并拉取。

<br><br><br>
<br>
docker info---查看docker的总体信息

<br>
docker help---查看docker有哪些命令

<br><br><br>​		镜像是一种轻量级的、可以执行的独立软件包，用来打包软件运行环境和基于运行环境的软件，她包含某个软件锁需要的所有内容，包括代码、运行时库、环境变量和配置文件。<br>​	    在 Docker 中，一个只读层被称为镜像，一个镜像是永久不会变的。由于 Docker 使用一个统一文件系统，Docker 进程认为整个文件系统是以读写方式挂载的。 但是所有的变更都发生顶层的可写层，而下层的原始的只读镜像文件并未变化。由于镜像不 可写，所以镜像是无状态的。<br><img style="zoom:50%;" alt="04.docker-filesystems-multilayer" src="\04.docker-filesystems-multilayer.png" referrerpolicy="no-referrer"><br>​		bootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统，在Docker镜像的最底层是bootfs，这一层和Linux、Unix系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核都在内存中了，此时内存的使用权已经由bootfs转交给内核，此时系统也会卸载bootfs。
​		rootfs（foot file system），在bootfs之上，包含的就是典型的Linux系统中的/dev ,/proc,/bin等标准目录和文件，rootfs就是各种不同的操作系统发行版，比如说Ubuntu，Centos，Redhat等 <br>   镜像是层叠式的，上面的镜像依赖于下面的镜像。镜像是只读的，不能写操作。 联合文件系统<br><img style="zoom:50%;" alt="05.docker-filesystems-multilayer" src="\05.docker-filesystems-multilayer.png" referrerpolicy="no-referrer"><br>
<br>
查看仓库里有什么对应的镜像
docker search  镜像名

<br>
查看镜像

<br>docker images---查看有哪些镜像，repository表示镜像的仓库源，tag是版本，image id是镜像的唯一ID,created是创建时间，size是镜像大小。
<br>docker images -a---查看镜像及中间映像层，也就是一个表面镜像内部还包含了哪些镜像。
<br>docker images -q---只显示镜像ID


<br>
下载镜像
语法： docker pull  镜像名:版本号

<br>docker pull nginx,相当于docker pull nginx:latest下载最新版本。
<br>docker pull tomcat:8.5.32


<br>
删除镜像

<br>docker rmi hello-world---失败，因为提示说该镜像的容器正在运行，
<br>docker rmi -f hello-world- --强制删除


<br><br><br>以centos镜像为例演示<br>
<br>docker pull centos---从阿里上拉取centos镜像
<br>docker run -it centos---启动容器，i为交换模式，t为打开终端，it常常一起使用，exit退出
<br>docker run -it --name mycts centos---启动并指定容器名称，上面没指定都会随机给个名字
<br><br>
<br>docker ps  查看正在运行的容器
<br>docker ps -q  ---只显示容器id
<br>docker ps -a  列表形式查看所有的容器
<br>docker ps -qa   查看所有，包括没有运行的容器
<br><br>
<br>exit---从终端退出并可能停止容器，ctrl+p+q（键盘）退出但容器仍然运行。
<br>docker stop aea7a56b0c7d或容器名---停止容器
<br>docker start 容器名或容器id  重新启动被停止的容器
<br><br>不是停止，停止后容器还在，只是不运行了<br>
<br>docker rm 容器id或名称---注意，必须先关闭容器才能删除，rmi是删除镜像
<br>docker rm -f $(docker ps -aq)---批量删除
<br><br>docker exec -it 容器id bash<br><br>
<br>
从容器中拷贝到宿主机
docker run -it centos

cd /tmp

vi hello.txt

ctrl+p+q

docker ps

docker  cp  容器id:/tmp/hello.txt  /opt


<br>
从宿主机拷贝到容器
docker cp  /opt/a.txt  容器id:/tmp

<br><br><br>
<br>
目录映射：
为方便宿主机与容器间传递数据，产生目录映射，使两者共享同一目录。使用数据卷可将宿主机上的一个目录映射到容器的一个目录中。

<br>
持久化容器数据
容器运行中所产生的数据，如果不通过commit生成新镜像，当容器被删除后数据就丢失了。使用数据卷可在不产生新镜像的前提下保存数据在磁盘上，有点像redis中的持久化。

<br>
部署项目方便

<br>为了部署项目，需要使用到cp命令将宿主机内的war包复制到容器内部。<br>使用数据卷可以在宿主机中操作目录中内容，那么容器内部映射的文件，也会跟着一起改变<br><br>
<br>数据卷可在容器之间共享
<br>修改卷中数据可以直接生效，并且对卷的修改不会引起镜像的更新。
<br>卷的生命周期一直持续到没有容器使用它为止。
<br><br>docker run -di -v /myData:/myContainerData --name myc1  centos<br>docker run -di -v /mydata:/opt --name myc1  centos
<br>参数说明：<br>
<br>-di:产生交互式后台进程
<br>-v:创建一个目录数据卷并挂载到容器里,myData是宿主机中目录，myContainerData是容器中目录
<br>--name:给容器启一名称为myc1
<br>centos：镜像名（如果是其他的，则换其名称）
<br>docker volume prune 清除所有的数据卷<br><br>
<br>vim /myData/a.txt
<br>docker exec -it myc1 bash
<br>cat /myContainerData/a.txt
<br>
<br><br><br><br>
<br>
搜索mysql镜像：docker search mysql

<br>
拉取镜像：docker pull centos/mysql-57-centos7  ，镜像选择的是centos/mysql-57-centos7

<br><br>docker run -di --name=mysql5.7 -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root centos/mysql-57-centos7

docker run -di --name=mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root  mysql
<br>参数说明：<br>
<br>-di:  以守护进程交互式启动容器
<br>--name:  给容器启名为mysql5.7
<br>-p:  端口映射，格式为：宿主机端口：容器端口，为什么要映射？因为容器的ip地址跟windows的ip不在一个网段，无法通信。从win7访问容器就只能通过win7访问宿主机(虚拟机)的ip+映射的端口。
<br>-e:  当从win7远程连接容器mysql时，要设置root帐号的密码，这里设置远程连接密码为root,但要注意：在进入容器内访问时，密码是空的。
<br>最后一个参数：是上面下载的镜像名.
<br><br><br>
<br>
docker exec -it mysql5.7 bash

<br>
mysql -uroot -p  ，密码为空，回车

<br><br>mysql    -uroot    -proot    -h192.168.146.101   ，默认连接的是3306，如果映射的宿主机不是3306，则后面添加   -P3306<br>mysql8.0遇到的问题<br><img alt="image-20221128174837761" src="\C:\\Users\mameiping\AppData\Roaming\Typora\typora-user-images\image-20221128174837761.png" referrerpolicy="no-referrer"><br>2026问题：<br>方案一：<br>my.cnf中增加<br>skip_ssl
<br>方案二：<br>mysql -uroot -p123456 -h192.168.33.10 -P3306 --ssl-mode=DISABLED
<br>2059问题：<br>ALTER USER 'root'@'localhost' IDENTIFIED BY 'password' PASSWORD EXPIRE NEVER;
ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '123456';
FLUSH PRIVILEGES;
<br><br><br>docker search tomcat
<br><br>docker images tomcat
<br><br>最新版本不需要指定版本号<br>#docker pull tomcat:版本号，最新版不需要版本号
docker pull tomcat:8.5
<br><br>docker run -di -p 8080:8080 -v /opt/data:/usr/local/tomcat/webapps/ --name mytomcat  tomcat:8.5
<br><br>http://192.168.33.10:8080/
<br>如果出现404，则是因为版本中的webapps当中没有内容。进行以下将webapps删除，并且将webapps.dist改名为webapps<br>#进入容器，会进入usr/local/tomcat目录
docker exec -it mytomcat /bin/bash
#查看内容，会发现有webapps和webapps.dist
ls -l
#查看webspps当中的内容，会发现是空的,退到上一层目录，移除webapps
cd webapps
ls -l
cd ..
rm -rf webapps
#将webapps.dist变成webapps
mv webapps.dist webapps
<br>再次在浏览器中访问。<br><br>
<br>将window当中打好的war上传到Linux（docker01.war）
<br>
<br>
将war拷贝放入数据卷目录
cp /home/vagrant/docker01.war /opt/data


<br>
<br>测试：<a rel="noopener nofollow" class="external-link" href="http://192.168.33.10:8080/docker01" target="_blank">http://192.168.33.10:8080/docker01</a>
<br><br><br>docker pull nginx<br><br>
<br>
docker run -d --name mynginx1 -p 80:80 nginx bash

<br>
配置文件在/etc/nginx/nginx.conf,默认没有vi命令

<br>
拷贝nginx目录到宿主机：

<br>ctr+p+q
<br>docker ps
<br>docker cp mynginx1:/etc/nginx   /opt/data


<br>
删除容器：docker stop mynginx1--》docker rm mynginx1

<br>
启动容器并添加数据卷：
docker run  -v  /opt/data/nginx:/etc/nginx   -di --name mynginx  -p 80:80 nginx

<br><br><a rel="noopener nofollow" class="external-link" href="http://192.168.146.101/" target="_blank">http://192.168.146.101/</a><br><br><br>docker pull redis<br><br>以aop方式持久化，如果用rdb则不加--appendony yes<br>docker run -d --name myredis -p 6379:6379 redis --appendonly yes<br><br>
<br>进入容器
<br>docker exec -d myredis bash<br>
<br>启动客户端

<br>cd /usr/local/bin
<br>redis-cli


<br><br>官网地址<br><a rel="noopener nofollow" class="external-link" href="https://www.minio.org.cn/" target="_blank">https://www.minio.org.cn/</a><br>什么是MinIO<br>OSS：对象存储的中间件<br>前提<br>1、在<a data-tooltip-position="top" aria-label="https://cloud.tencent.com/product/cvm?from=10680" rel="noopener nofollow" class="external-link" href="https://cloud.tencent.com/product/cvm?from=10680" target="_blank">服务器</a>的安全组和防火墙中放通相对应的端口，操作系统：centos 7.6，需要放通9000端口<br>2、登录自己的Linux系统服务器<br>3、关闭服务器内部的firewalld防火墙<br>4、开启内核端口转发：<br>通过vim /etc/sysctl.conf把里面的net.ipv4.ip_forward = 0修改为net.ipv4.ip_forward = 1后进行保存退出，通过sysctl -p命令使修改后的内核转发文件生效<br>5、下载安装好<a data-tooltip-position="top" aria-label="https://cloud.tencent.com/product/tke?from=10680" rel="noopener nofollow" class="external-link" href="https://cloud.tencent.com/product/tke?from=10680" target="_blank">docker</a><br>6、安装配置好镜像加速源（由于正常拉取镜像是从境外的docker官网拉取，建议设置镜像加速源）<br><br>docker search minio
<br><br>docker pull minio/minio

<br><br>这里的 \ 指的是命令还没有输入完，还需要继续输入命令，先不要执行的意思。
这里的9090端口指的是minio的客户端端口。虽然设置9090，但是我们在访问9000的时候，他会自动跳到9090。<br>MINIO_ACCESS_KEY：登录的用户名<br>MINIO_SECRET_KEY：登录的密码<br>20以后的命令<br>docker run -p 9000:9000 -p 9090:9090 \
 --net=host \
 --name minio \
 -d --restart=always \
 -e "MINIO_ACCESS_KEY=minioadmin" \
 -e "MINIO_SECRET_KEY=minioadmin" \
 -v /opt/minio/data:/data \
 -v /opt/minio/config:/root/.minio \
 minio/minio server \
 /data --console-address ":9090" -address ":9000"

<br>【WARNING: Published ports are discarded when using host network mode
744135519b57a75d58b6c4bac2bee74a83a03b38e146db33426616ce921b49ac】  不影响使用<br><br>http://192.168.33.10:9090/
<br><br>[MinIO上传文件The difference between the request time and the server's time is too large.异常<br># 安装ntp ntpdate
yum -y install ntp ntpdate

#与时间服务器同步时间
ntpdate cn.pool.ntp.org

#将系统时间写入硬件时间
hwclock --systohc
<br><br><br>docker search rabbitmq
<br><br>docker pull rabbitmq
<br><br><br>docker run -d --name rabbitmq \
	-p 5672:5672 -p 15672:15672 \
	-v `pwd`/data:/var/lib/rabbitmq \
	--hostname myRabbit \
	-e RABBITMQ_DEFAULT_VHOST=my_vhost  \
	-e RABBITMQ_DEFAULT_USER=admin -e \
	RABBITMQ_DEFAULT_PASS=admin rabbitmq
<br>-d 后台运行容器；
--name 指定容器名；
-p 指定服务运行的端口（5672：应用访问端口；15672：控制台Web端口号）；
-v 映射目录或文件；
--hostname  主机名（RabbitMQ的一个重要注意事项是它根据所谓的 “节点名称” 存储数据，默认为主机名）；
-e 指定环境变量；
（RABBITMQ_DEFAULT_VHOST：默认虚拟机名；
RABBITMQ_DEFAULT_USER：默认的用户名；
RABBITMQ_DEFAULT_PASS：默认用户名的密码）<br><br>默认用户名和密码都是guest<br>docker run -d --name rabbitmq 	\
      -p 5672:5672 -p 15672:15672   rabbitmq
<br><br>docker exec -it rabbitmq bash
rabbitmq-plugins enable rabbitmq_management
<br><br>http://192.168.33.10:15672
<br><br><br>使用Dockerfile可以根据需求开发一个自定义的镜像，其实就是一个文本文件，由一系列命令和参数构成，Docker可读取这个文件构建一个镜像。<br><br>
<br>
向/opt/data/jdk目录添加jdk压缩文件

<br>
在/opt/data/jdk目录中创建并编辑Dockerfile文件
vim Dockerfile   ，添加下面内容：
FROM centos:7
MAINTAINER aowin
WORKDIR /usr
RUN mkdir /usr/local/java
ADD jdk-8u261-linux-x64.tar.gz /usr/local/java/
ENV JAVA_HOME /usr/local/java/jdk1.8.0_144
ENV JRE_HOME $JAVA_HOME/jre
ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JAR_HOME/lib:$CLASSPATH
ENV PATH $JAVA_HOME/bin:$PATH


<br>
编译并构建镜像，镜像名为jdk1.8
docker build -t='jdk1.8'  ./

<br>
查看镜像
docker images

<br>
通过镜像jdk1.8创建容器myjdk
docker run -it --name myjdk jdk1.8 bash

<br><br><br>在/opt/data/eureka目录中添加eureka-server-1.0.jar<br>​	注意eureka-server打包时，指定的主机和端口号，需要是192.168.146.101:7100<br><br>
<br>docker search jdk   得到ascdc/jdk8镜像，也可使用前面创建的镜像jdk1.8
<br><br>
<br>
在/opt/data/eureka中创建并编辑Dockerfile文件
#基于哪个镜像
FROM ascdc/jdk8
#目录挂载，将本地文件夹挂载到当前容器,这里用不着，了解
VOLUME /tmp
#将文件复制到容器指定目录
ADD eureka-server-1.0.jar /usr/local/java/
#暴露服务的端口
EXPOSE 7100
#设置容器启动后要自动执行的命令
ENTRYPOINT ["java","-jar","/usr/local/java/eureka-server-1.0.jar"]


ENTRYPOINT ：如果有多个ENTRYPOINT ，只有最后一个起作用

<br><br>
<br>
编译并创建镜像
docker build -t='eureka-server' ./

<br>
查看生成的镜像：docker images

<br>
启动容器：

<br>前台启动：docker run -p 7100:7100 eureka-server
<br>后台启动：docker run -di -p 7100:7100 eureka-server


<br>
192.168.146.101:7100

]]></description><link>教程\docker.html</link><guid isPermaLink="false">教程/docker.md</guid><pubDate>Tue, 16 Jan 2024 02:41:45 GMT</pubDate><enclosure url="\04.docker-filesystems-multilayer.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\04.docker-filesystems-multilayer.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[JVM模型]]></title><description><![CDATA[ 
 <br><br><img alt="image-20230819094210868" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308190942168.png" referrerpolicy="no-referrer"><br>补充：本地接口和本地方法栈进行交互<br><br>堆:存放对象，所有线程公有
栈:线程私有，每一个方法执行的时候都公有自己的栈空间。局部变量，操作數，引用，		方法出口信息等
方法区:公有，被虚拟机加载的类信息，静态变量，常量池(jdk1.8后移到堆) ，即时编译器编译后的代码
程序计数器:线程私有，存储执行的方法代码的行号，用来控制跳转，循环，分支，选择等
本地方法栈:执行本地方法<br><br>[类加载过程](<a data-tooltip-position="top" aria-label="http://www.dtmao.cc/NodeJs/78494.html" rel="noopener nofollow" class="external-link" href="http://www.dtmao.cc/NodeJs/78494.html" target="_blank">一文读懂Java类加载全过程，面试必备！ (dtmao.cc)</a>)<br>双亲委派机制的好处有什么:
1:防止类的重复加载
2:沙箱安全机制，防止篡改Java的核心API I
ClassLoader加载的原则:
双亲委派模型
可见性:子类加载器是访问父类加载器加载的类，但是父类加载器是不能访问子类加载器加载的类
唯一:同一个命名空间，- 一个类只会被加载一-次<br><br><br><br>引用计数法:问题，无法处理循环引用<br>根可达:从栈变量，静态变量，常量池。JNI指针(本地方法)等作为root.可以解决循环依赖问题<br><br>分代回收:不同的代里面使用的回收算法是不同的<br>标记清除:<br>​		特点：垃圾区域直接回收<br>​		优缺点:优：算法简单;缺：内存碎片化<br>拷贝：<br>​		特点：将内存分成两份，一般存储数据，另一半留着拷贝用<br>​		优点：效率比较高，没有碎片，<br>​		缺点：内存利用率低<br>标记压缩：<br>​		特点:一边标记一边整理
​				优点I没有碎片，空间利用率也高
​				缺点:算法比较复杂，效率降低<br><br>新生代+老年代+永久代(1.7)/元空间<br>永久代(1.7)/元空间<br>​		逻辑名称：方法区<br>​		存放：静态变量、1.7前的常量、类信息、即时编译代码<br>​		大小：1.7之前要设置大小，1.8不用了(受限于物理内存)<br>调优：基本无视这一块<br>常说的内存：<br>-Xmx和-Xms设置为一样大，目的是避免伸缩（xmx默认1/4物理内存）<br><img alt="image-20230819160721365" src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308191607517.png" referrerpolicy="no-referrer"><br>parallel scavenge<br><br><br>A a = new A();<br>垃圾回收器宁愿抛出00M，也不会回收强引用指向的对象<br><br>当内存足够的时候，不公被回收，如果内存不足，则公被回收<br><br>gc调用则回收<br><br>虚引用也称为幽灵或者幻影应用
特点:
对象上是否有虚引用，不会对对象的生存造成影响
必须和引用队列- -起使用，用于垃圾回收的跟踪<br>​				]]></description><link>教程\jvm.html</link><guid isPermaLink="false">教程/jvm.md</guid><pubDate>Thu, 28 Dec 2023 03:09:33 GMT</pubDate><enclosure url="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308190942168.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://my-picture-aa.oss-cn-nanjing.aliyuncs.com/img/202308190942168.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[补充]]></title><description><![CDATA[ 
 <br><br>
<br>JMM（Java内存模型）：是Java语言在多线程并发情况下对于共享变量读写(实际是共享变量对应的内存操作)的规范，规定了线程的工作内存和主内存之间的交互关系，以及线程之间的可见性和程序的执行顺序，主要是为了解决多线程可见性、原子性的问题，解决共享变量的多线程操作冲突问题。
<br>JVM内存模型：Java虚拟机在运行时对该Java进程占用的内存进行的一种逻辑上的划分，包括方法区、堆内存、虚拟机栈、本地方法栈、程序计数器。这些区块实际都是Java进程在Java虚拟机的运作下通过不同数据结构来对申请到的内存进行不同使用。
<br><br>JVM的组成<br>整个JVM 分为四部分：<br>
<br>
Class Loader 类加载器 : 类加载器的作用是加载类文件到内存

<br>
Execution Engine 执行引擎: 执行引擎也叫做解释器(Interpreter) ，负责解释命令，提交操作系统执行。

<br>
Native Interface 本地接口

<br>
<br>本地接口的作用是融合不同的编程语言为Java 所用，它的初衷是融合C/C++ 程序，Java 诞生的时候是C/C++ 横行的时候，要想立足，必须有一个聪明的、睿智的调用C/C++ 程序，于是就在内存中专门开辟了一块区域处理标记为native 的代码，它的具体做法是Native Method Stack 中登记native 方法，在Execution Engine 执行时加载native libraies 。目前该方法使用的是越来越少了，除非是与硬件有关的应用，比如通过Java 程序驱动打印机，或者Java 系统管理生产设备，在企业级应用中已经比较少见，因为现在的异构领域间的通信很发达，比如可以使用Socket 通信，也可以使用Web Service 等等。
<br>
<br>Runtime data area 运行数据区
<br>
<br>
运行数据区是整个JVM 的重点。我们所有写的程序都被加载到这里，之后才开始运行，Java 生态系统如此的繁荣，得益于该区域的优良自治。
找不到“/JVM模型.png”。

<br><br>
<br>编译器将Java源文件编译成字节码文件
<br>类加载器加载字节码文件到内存
<br>JVM进程解释程序。
<br><img style="zoom: 33%;" alt="01.java程序执行过程" src="\01.java程序执行过程.png" referrerpolicy="no-referrer"><br>所有的程序都要求运行在JVM上，是因为考虑到了可移植性问题 ，但如果真正去执行程序，无法离开操作系统的支持。在 java 中可以使用 native 实现 本地 C 函数的调用，Native Interface，但是这些都是属于程序的辅助手段，而真正的程序运行都在“运行时数据区”之中。<br><br>
<br>程序计数器（Program Counter Register）：线程私有。一小块内存空间，可以看做当前线程所执行的字节码的行号指示器。字节码解释器通过改变计数器的值来实选择下一条需要执行的字节码指令。分支、循环、跳转等都需要依赖计数器来完成。
<br>虚拟机栈（Stack）：线程私有。每个方法在执行的同时都会创建一个帧栈（Stack Frame）。用于存储局部变量表，操作数栈，动态链栈，方法出口等信息。

<br>局部变量表（Local Variables）:方法的局部变量或形参，其以变量槽（solt）为最小单位，只允许保存32为长度的变量，如果超过32位则会开辟两个连续的solt(64位长度，long和double)；
<br>操作树栈（Operand Stack）：表达式计算在栈中完成；
<br>指向当前方法所属的类的运行时常量池的引用（Reference to runtime constant pool）：引用其他类的常量或者使用String 池中的字符串；
<br>方法返回地址（Return Address）：方法执行完后需要返回调用此方法的位置，所以需要再栈帧中保存方法返回地址；


<br>本地方法栈（Native Method Stack）：执行本地方法时使用
<br>堆（Heap）：虚拟机管理的内存中最大的一块。所有线程共享使用。用来存放对象
<br>方法区（Method Area）：各线程共享区域，用来存储已经被虚拟机加载的类信息，静态变量、即时编译器编译后的代码等
<br><img style="zoom: 33%;" alt="02.运行时数据区" src="\02.运行时数据区.png" referrerpolicy="no-referrer"><br><br>hotSpot虚拟机在堆内存中直接保存对象，通过对象类型指针，可以直接进行方法区的调用。<br><img style="zoom:33%;" alt="03.java对象访问模式" src="\03.java对象访问模式.png" referrerpolicy="no-referrer"><br><br><br>javap -v  xxx.class可以看到class类加载后的内容。<br>找不到“/06.类的加载过程.png”。<br> 加载：在硬盘上查找并通过IO读入字节码文件到JVM虚拟机方法区，同时在堆中创建Class对象<br> 验证：校验字节码文件的正确性<br> 准备：为类的静态变量分配内存，并将其初始化为默认值。此阶段仅仅只为静态类变量（即static修饰的字段变量）分配内存，并且设置该变量的初始值（比如static int num = 5，这里只是将num初始化成0,5的值将会在初始化时赋值）；对于final static修饰的变量，编译的时候就会分配了，也不会分配实例变量的内存。<br> 解析：把类中的符号引用（CONSTANT_Class_info、CONSTANT_Fieldref_info）转为直接引用<br> 初始化：执行类构造器&lt; clinit &gt;方法（类构造器不是实例构造器），对类的静态变量初始化为指定的值，执行静态代码块。<br><br>
<br>引导类加载器：负责加载jre/lib目录下的核心类库，比如rt.jar,charsets.jar等
<br>扩展类加载器：负责加载jre/lib/ext目录中的JAR类包
<br>应用程序类加载器：负责加载ClassPath路径（类路径）下的class字节码文件，主要就是加载你自己写的那些类。
<br>自定义加载器
<br>扩展类加载器、应用程序类加载器、自定义加载器是java.lang.ClassLoader的子类实例，自定义类加载器直接继承java.lang.ClassLoader<br><img style="zoom: 80%;" alt="2.加载器" src="\2.加载器.png" referrerpolicy="no-referrer"><br>1.当Application ClassLoader 收到一个类加载请求时，他首先不会自己去尝试加载这个类，而是将这个请求委派给父类加载器Extension ClassLoader去完成。
2.当Extension ClassLoader收到一个类加载请求时，他首先也不会自己去尝试加载这个类，而是将请求委派给父类加载器Bootstrap ClassLoader去完成。
3.如果Bootstrap ClassLoader加载失败(在、lib中未找到所需类)，就会让Extension ClassLoader尝试加载。
4.如果Extension ClassLoader也加载失败，就会使用Application ClassLoader加载。
5.如果Application ClassLoader也加载失败，就会使用自定义加载器去尝试加载。
6.如果均加载失败，就会抛出ClassNotFoundException异常。<br>public static void main(String[] args) {
                //获取引导类加载器
		System.out.println(String.class.getClassLoader());
               //获取扩展类加载器
		System.out.println(sun.net.spi.nameservice.dns.DNSNameService.class.getClassLoader());
                //获取应用类加载器（系统加载器）
		System.out.println(N.class.getClassLoader());

		
		//AppClassLoader 也称为SystemClassLoader
		ClassLoader appClassLoader = ClassLoader.getSystemClassLoader();
		System.out.println(appClassLoader);
//		System.out.println(N.class.getClassLoader().getParent());
	}
<br>ClassLoader有几个原则，分别是：<br>Parent Delegate：双亲委派模型。该原则保证了所有要加载的类，都要经过Boostrap ClassLoader这个老大哥，能防止自定义的类替换掉java核心类，例如String类。<br>Visibility：可见性。子类加载器能够访问父加载器加载的类，反过来父加载器不能访问子加载器加载的类。<br>Unique：唯一性，在同一命名空间内，一个类只会被加载一次。<br>为什么要双亲委派机制：<br>
<br>
避免类的重复加载：当类加载器已经加载了该类时，就没有必要子ClassLoader再加载一次，保证被加载的类的唯一性

<br>
沙箱安全机制：自己写的java.lang.String.class类不会被加载，这样便可以防止核心API库不会被随意篡改。保证了运行的安全性，防止不可信类扮演可信任的类。
06.string.png<br><br><br><br>ast/asset/reportUrlImport/{fileId}<br>1、根据fileId查询文件对象，获取文件路径，读取文件<br>2、读取excel，sheet1页、头行数为1，使用excelReader对象读取excel<br>3、通过输入流，写入到文件系统的指定文件路径中<br>真正的插入在AssetReportUrlExcelDataListener，会执行invoke方法<br>4、插入。如果cId不知道在哪儿进行的初始化已经存在，则删除。继续封装对象并插入assetReportUrlService<br>有一个看不懂的List&lt;Future&gt; re ,不知道re是什么，在哪儿初始化<br>5、插入后。<br>1）如果re不为空，则记录处理结果（成功则succ++，失败则插入handerResult）。<br>2）关闭多线程，在Dap_Sys_File_Extr表中查询传人的文件Id，如果没查到该文件，则插入<br>从数据库查看是否要开启线程（数据库写的为true），并没有进行判断<br>day_sys_param表，记录了一些系统参入，类似与常量类，比如模板文件路径、页面的url、导入资产时是否开启线程等，很杂。<br><br>前端和上面几乎一样，通过if语句判断发送不同请求<br>ast/asset/addbloodimport/{fileId} NestController<br>1、查询文件，根据文件路径创建文件对象<br>2、从第0页开始，头行数为1，读取excel文件，<br>真正的插入在AddBloodListener中，会执行invoke方法<br>在生产库表（数据量很大，测试库380万数据，1.2G)中查看生产元数据（分别按导入数据中的源字段英文名和目标字段英文名查）<br>根据源数据Id和目标数据Id，在血缘表中查找出血缘关系对象列表，如果没有，则创建血缘关系对象并插入到血缘关系<br><br>前端和上面几乎一样，通过if语句判断发送不同请求<br>ast/assetAuthApply/userAuthImport/{fileId}<br>1、读取excel，包含资产序号、部门编号、用户编号、操作类型（资产编号：非空 操作类型：新增、删除）<br>3、根据id查询出对应资产，过滤掉资产权限不是3、4、5级；行内编号用户编号同时为空；用户编号不为空但实际不存在。一切验证完毕后添加到list<br>4、在doAfterAll中处理，删除，则根据资产编号和用户Id，物理删除用户资产权限信息，返回message<br><br>/ast/asset/getMonthPubilshAsset<br>1、获取本月开始和结束的时间，查询本月的资产<br>2、设置响应头，设置文件名，写入文件<br><br>/sys/assetNoThemeLog/export<br>1、获取本月开始和结束时间，查询本月的Dap_asset_No_Theme_Log(用户勾选跳转魔术师，但没有分组的资产）<br>2、<br><br>/ast/assetVisit/exportVisitData<br>1、查询上个月的资产访问次数表，<br>2、设置响应头，设置文件名，写入文件<br><br><br>点击部门触发<br>sys/user/userList,就从用户表中查的数据，做了一下分页和其它操作，重点暂时应该不会在这儿·<br>1、使用TypeCastUtil.populate(targetEntity,sourceMap)将Map中的参数转换为实体类，将对象传入sql进行查询，获得所有该部门的用户<br>2、获取当前部门的父部门，拼接当前用户机构的层级结构<br>需要注意，点击部门后则无法通过再次点击取消选中状态（不取消则部门号一直都在，无法正常搜索用户），需要使用工具点击‘取消选择’才能继续使用<br><br>Controller不在userController中，而是在baseController中，<br>1、设置密码为默认密码，使用Md5加密后再用SHA加密，<br>

<br><br><br>GC（Garbage Collection）是垃圾收集的意思，负责清除对象并释放内存。Java 提供的 GC 功能可以自动检测对象是否超过作用域从而达到自动回收内存的目的，从而防止内存泄漏。<br><br>java中的对象当没有引用变量指向它（它们：互相引用，但是没有栈引用变量）时，虚拟机会在适当时机回收这些对象。<br>finalize方法：在对象在被虚拟机回收前一定会自动调用 其finalize方法<br>System.gc():提醒虚拟机回收内存<br>public class Cat {
	String name;
	
	public Cat(String name) {
		super();
		this.name = name;
	}
	
	public void finalize() throws Throwable {
		System.out.println("finalize");
	}	
}
//=========================================
public static void main(String[] args) {
	Cat cat = new Cat("xiaohua",5);
	cat = null;
	System.gc();
}
<br>手工回收的问题<br>
<br>忘记回收
<br>多次回收
<br><br>
<br>
此部分使用于分代垃圾回收算法---部分垃圾回收器，新的垃圾回收器（G1)已经不再使用这样的分代模型

<br>
新生代 + 老年代 + 永久代（1.7）/元空间（1.8） Metaspace

<br>
永久代/元数据区

<br>永久代/元数据都是用来存储各种Class的对象（loadClass时）
<br>永久代必须指定大小限制，元数据区可以设置，也可以不设置（受限于物理内存）
<br>字符串常量（1.7）是存储在永久代，1.8是存储在堆当中
<br>MethodArea是逻辑概念 ≈ 永久代/元数据


<br>
堆内存逻辑分区（新生代 + 老年代）

<br>
老年代和新生代的比例大致为1:3

<br>
新生代=eden + 2个survior区，eden和survivor 0，survivor1的比例是8:1:1
找不到“/05.堆内存逻辑分区.png”。





<br>
新生代：存活对象少，使用copy算法，效率高

<br>新生代=eden + 2个survior区，YGC回收的时候，大多数的对象会被回收。
<br>对象创建时，需要分配空间，先去检查Eden，如果不够，直接进入老年代。
<br>如何回收

<br>第一次进行YGC（也叫MinorGC）时候，大部分对象（90%）的对象就会被回收，活着的对象放到survivor0区当中，将eden全部释放，不需要压缩。
<br>再次YGC的时候，将Eden和survivor0中活着的对象都copy到survivor1中
<br>再次YGC,Eden + survivor1 ==》survivior0，如此反复
<br>年龄足够（对象的活着计算的次数达到一定程度以后），直接进入老年代
<br>Survivor区装不下，进入老年代




<br>
老年代：垃圾少，一般使用Mark-Compact（标记压缩），G1使用copy

<br>
装大对象以及一直活着的（岁数比较大的）

<br>
老年代满了，进行FGC (Full GC)，也叫MajorGC，会压缩，效率比较低



<br><br>
<br>
引用计数（Reference Count）：无法解决多个引用对象之间循环引用，但是无法引用指向的情况。

<br>
根可达算法
<img style="zoom: 33%;" alt="05.根可达算法" src="\05.根可达算法.png" referrerpolicy="no-referrer">

<br><br><br>
<br>
找出垃圾，标记垃圾区域，直接回收。

<br>
特点：位置不连续，产生碎片
找不到“/05.标记清除算法.png”。

<br><br>
<br>
将内存空间分成两份，只使用一半内存，另一半空余着。垃圾回收时，将活着的对象拷贝到空余的区域，将原来使用的一半全部清空。

<br>
特点：没有碎片，空间利用率比较低
找不到“/05.垃圾回收-拷贝算法.png”。

<br><br>
<br>
一边标记一边整理压缩

<br>
特点：没有碎片，算法效率比较低（查找效率基本相同，压缩的时候效率低）
找不到“/05.垃圾回收-标记压缩算法.png”。

<br><br>基于对对象生命周期分析后得出的垃圾回收算法。把对象分为年青代、年老代、持久代，对不同生命周期的对象使用不同的算法（上述方式中的一个）进行回收。现在的垃圾回收器（从J2SE1.2开始）都是使用此算法的。<br><br>查看垃圾回收器的命令<br>java -XX:+PrintCommandLineFlags -version
<br>找不到“/JDK8默认的垃圾回收器.png”。<br>注意：如上图, JDK8的默认垃圾回收器为Parallel<br>不同的厂商、不同的版本的虚拟机提供的垃圾收集器可能有很大的差别。<br><img style="zoom: 40%;" alt="04.垃圾收集器" src="\04.垃圾收集器.png" referrerpolicy="no-referrer"><br>相关概念：<br>
<br>并行收集：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。
<br>并发收集：指用户线程与垃圾收集线程同时工作（不一定是并行的可能会交替执行）。用户程序在继续运行，而垃圾收集程序运行在另一个CPU上。
<br>吞吐量：即CPU用于运行用户代码的时间与CPU总消耗时间的比值（吞吐量 = 运行用户代码时间 / ( 运行用户代码时间 + 垃圾收集时间 )）。例如：虚拟机共运行100分钟，垃圾收集器花掉1分钟，那么吞吐量就是99%
<br><br>Serial收集器是最基本的、发展历史最悠久的收集器。新生代采用复制算法，老年代采用“标记-整理“算法。<br>特点：单线程、简单高效（与其他收集器的单线程相比），对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程手机效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程，直到它结束（Stop The World）。<br>应用场景：适用于Client模式下的虚拟机。<br>Serial / Serial Old收集器运行示意图<br>找不到“/07.serial.png”。<br><br>ParNew收集器其实就是Serial收集器的多线程版本。<br>除了使用多线程外其余行为均和Serial收集器一模一样（参数控制、收集算法、Stop The World、对象分配规则、回收策略等）。<br>特点：多线程、ParNew收集器默认开启的收集线程数与CPU的数量相同，在CPU非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。<br>　　　和Serial收集器一样存在Stop The World问题<br>应用场景：ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器，因为它是除了Serial收集器外，唯一一个能与CMS收集器配合工作的。<br>ParNew/Serial Old组合收集器运行示意图如下：<br>找不到“/07.parNew.png”。<br><br>与吞吐量关系密切，故也称为吞吐量优先收集器。<br>特点：属于新生代收集器也是采用复制算法的收集器，又是并行的多线程收集器（与ParNew收集器类似）。<br>该收集器的目标是达到一个可控制的吞吐量。还有一个值得关注的点是：GC自适应调节策略（与ParNew收集器最重要的一个区别）<br>GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。<br>Parallel Scavenge收集器使用两个参数控制吞吐量：<br>
<br>XX:MaxGCPauseMillis 控制最大的垃圾收集停顿时间
<br>XX:GCRatio 直接设置吞吐量的大小。
<br><br>Serial Old是Serial收集器的老年代版本。<br>特点：同样是单线程收集器，采用标记-整理算法。<br>应用场景：主要也是使用在Client模式下的虚拟机中。也可在Server模式下使用。<br>Server模式下主要的两大用途（在后续中详细讲解···）：<br>
<br>在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用。
<br>作为CMS收集器的后备方案，在并发收集Concurent Mode Failure时使用。
<br>Serial / Serial Old收集器工作过程图（Serial收集器图示相同）：<br>![07.Serial Old](/07.Serial Old.png)<br><br>是Parallel Scavenge收集器的老年代版本。<br>特点：多线程，采用标记-整理算法。<br>应用场景：注重高吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge+Parallel Old 收集器。<br>Parallel Scavenge/Parallel Old收集器工作过程图：<br>![07.parallel Old](/07.parallel Old.png)<br><br>一种以获取最短回收停顿时间为目标的收集器。<br>特点：基于标记-清除算法实现。并发收集、低停顿。<br>应用场景：适用于注重服务的响应速度，希望系统停顿时间最短，给用户带来更好的体验等场景下。如web程序、b/s服务。<br>CMS收集器的运行过程分为下列4步：<br>初始标记：标记GC Roots能直接到的对象。速度很快但是仍存在Stop The World问题。<br>并发标记：进行GC Roots Tracing 的过程，找出存活对象且用户线程可并发执行。<br>重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。仍然存在Stop The World问题。<br>并发清除：对标记的对象进行清除回收。<br> CMS收集器的内存回收过程是与用户线程一起并发执行的。<br> CMS收集器的工作过程图：<br>找不到“/07.cms.png”。<br>CMS收集器的缺点：<br>
<br>对CPU资源非常敏感。
<br>无法处理浮动垃圾，可能出现Concurrent Model Failure失败而导致另一次Full GC的产生。
<br>因为采用标记-清除算法所以会存在空间碎片的问题，导致大对象无法分配空间，不得不提前触发一次Full GC。
<br><br>G1堆的内存与其他收集器有很大区别，它将整个Java堆划分成多个大小相等的独立区域（Region），虽然还保留着新生代和老年代的概念，但是不再是物理的隔离。它们都是一部分Region的集合。<br>
<br>并行与并发：能够充分利用多CPU、多核环境下的硬件优势，使用多个CPU来缩短Stop The World停顿的时间。
<br>分代收集：分代概念依旧保留，但是它能够使用不同的方式去处理新创建的对象和已经存活一段时间的对象，以及熬过多次GC的旧对象以获得更好的收集效果。
<br>空间整理：整体上看是基于“标记-整理”，局部看是基于“复制”。运行期间不会产生内存空间碎片，收集后可提供规整的可用内存。
<br>可预测的停顿：G1除了追求停顿外，还能建立可预测的停顿模型。
<br><br>对于整个GC流程里，最需要处理的就是年轻代和老年代的内存清理操作，而元空间（永久代）都不在GC范围内.<br>一般流程：<br><img style="zoom: 50%;" alt="04.垃圾回收流程" src="\04.垃圾回收流程.png" referrerpolicy="no-referrer"><br>1：判断Eden区是否有空间
有空间：则将新对象保存在伊甸园区
没有：自动执行一次YGC(Minor GC)操作，将伊甸园区无用的内存空间进行清理。
2: 清理后再次判断Eden区是否有空间
有空间：则将新对象保存在伊甸园区
没有：则进行Survivor区空间判断
3：根据Survivor区空间判断结果，进行不同处理
有空间：则将Eden区的部分对象保存到Survivor区，然后在Eden区保存新对象
没有：则判断老年区
4：对老年区空间进行判断
有空间：将survivor区的对象保存到老年区，再将Eden区的对象保存到Svuvivor区，在Eden区创建对象
没有：则进行FullGC,再次进行判断，有空间，执行对象移动。依旧没有空间，则会产生OutOfMemoryError<br>※：大对象（大量需要连续内存的java对象，例如长字符串或长数组），直接进老年代<br><br>实际上每一块子内存区中都会存在有一部分的可变伸缩区，其基本流程：如果空间不足，在可变的范围之内扩大内存空间，当一段时间之后发现内存空间没有这么紧张的时候，再将可变空间进行释放。<br><img style="zoom: 67%;" alt="04.内存调优" src="\04.内存调优.png" referrerpolicy="no-referrer"><br>
<br>
堆内存的调整参数
在整个堆内存的调整策略之中，一般只会调整两个参数：“-Xmx”(最大内存)、“-Xms”（初始化内存）。如果“-Xmx”(最大内存)、“-Xms”（初始化内存）的差距较大，那么伸缩区的范围则较大，系统的性能就可能造成程序性能下降。可以将“-Xmx”(最大内存)、“-Xms”（初始化内存）设置相同，避免伸缩。
-Xms2048M -Xmx2048M

<br><br>
<br>
新生代内存调整参数
Survivor区会分为两个相等大小的Survivor区，所有使用关键字new新实例化的对象，一定会在伊甸园区进行保存。而对于Survivor区保存的一定是在伊甸园区保存好久，并且经过了好几次的小GC还保存下来的活跃对象。那么这个对象将晋升到Survivor区中，Survivor区一定会有两块大小相等的空间。目的是一块Survivor区未来晋升，另外一块Survivor区为了对象回收。这两块内存空间一定有一块是空的。

<br><br>
<br>
老年代内存调整参数
老年代主要接收由代发送过来的对象，一般情况下，经过了数次Minor GC 之后还会保存下来的对象才会进入到老年代。如果要保存的对象超过了伊甸园区的大小，此对象也将直接保存在老年代之中，当老年代内存不足时，将引发“Full GC”。

<br><br>
<br>
元空间内存调整参数
元空间与永久代最大的区别：永久代保存使用的是JVM的堆内存，而元空间使用的是本机物理内存，所以元空间的大小受到本机物理内存大小的限制。

<br><br>
<br>
<br><br><br>M m=new M();<br>这里的u就是强引用，垃圾回收器永远不会回收强引用所指向的对象，虚拟机宁愿抛出OOM(内存溢出)异常，也不会回收强引用所指向的对象，所以可能会导致内存泄漏，过多的内存泄漏会产生内存溢出。<br>public class M {
	public static void main(String[] args) {
		M m = new M();
        System.gc();//不会被回收==
		m=null;	//解除引用关系
		System.gc();//此时会被回收
	}
	@Override
	protected void finalize() throws Throwable {
		// 不推荐重写
		System.out.println("aaa");
		super.finalize();
	}

}
<br><br>
<br>特点：当空间足够时，即使发生了gc,也不会回收软引用对象，当内存不够时gc,才回收。
<br>示例
<br>public class N {
	public static void main(String[] args) {
		N n = new N();
		SoftReference&lt;N&gt; sf = new SoftReference&lt;&gt;(n);
		n=null;
		System.gc();
		System.out.println(sf.get()); //不会被回收
		
		try {
			//默认最大堆空间600多M,通过Run as--&gt;Run configurations--&gt;Arguments--&gt;
			//	VM Arguments--&gt;填写参数:-Xms10M -Xmx10M，
			//这里参数1表示最小堆内存，参数2表示最大堆内存。
			SoftReference&lt;byte[]&gt; sfb = new SoftReference&lt;&gt;(new byte[1024*1024*10]);
		} catch(Throwable ex) {
			System.out.println("内存溢出，在溢出前已经发生了gc,回收了软引用对象："+ex.getMessage());
		}
		System.out.println(sf.get());
	}

}
<br>
<br>应用场景
<br>适合做缓存，用来描述一些有用但并不是必需的对象，比如图片缓存。
假如有一个应用需要读取大量的本地图片，如果每次读取图片都从硬盘读取，则会严重影响性能，但是如果全部加载到内存当中，又有可能造成内存溢出，此时使用软引用可以解决这个问题。如何实现？HashMap中key为图片路径，value为一个弱引用的图片数据<br><br>
<br>特点：gc时就必然回收，不管内存是否够用
<br>示例
<br>public class O {
	public static void main(String[] args) {
		O o= new O();
		WeakReference&lt;O&gt; wo = new WeakReference&lt;&gt;(o);
		o=null;
		System.out.println(wo.get());
		System.gc();
		System.out.println(wo.get());//被回收
	}
}
<br>
<br>应用场景
<br>用来描述非必需对象的，同上，更容易回收掉。<br>
<br>
ThreadLocal

<br>代码示例

public class Test {
ThreadLocal&lt;User&gt; t1=new ThreadLocal&lt;&gt;();
ThreadLocal&lt;User&gt; t2=new ThreadLocal&lt;&gt;();
public static void main(String[] args)throws Exception {
		Test t=new Test();
		new Thread(()-&gt;{
			User u1=new User("a1");
			User u2=new User("a2");
			t.t1.set(u1);
			t.t2.set(u2);
			System.out.println(Thread.currentThread().getName()+",t1的value:"+t.t1.get()+",t2的value:"+t.t2.get());
		},"线程一").start();
		new Thread(()-&gt;{
			t.t1.set(new User("a1"));
			t.t2.set(new User("a2"));
			System.out.println(Thread.currentThread().getName()+",t1的value:"+t.t1.get()+",t2的value:"+t.t2.get());
		},"线程二").start();
		Thread.sleep(500);
		t.t1=null;//gc时，回收t1指向的local
	}  


<br>set源码

public void set(T value) {
  Thread t = Thread.currentThread();
  //通过当前线程对象获得当前线程唯一的一个Map，map内可添加多个键值对，key是this,就是当前的ThreadLocal对象，value就是设置的值，虽然一个local中只能添加一个值，但一个线程却可以拥有很多个local,每个local都是当前线程的一个key.
  ThreadLocalMap map = getMap(t);
  if (map != null)
  	map.set(this, value);
  else
  	createMap(t, value);
}


<br>ThreadLocal中的key为弱引用，目的是防止local本身对象的内存泄漏。在map.set方法中

tab[i] = new Entry(key, value);-----》这里tab[i]是强引用
static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; {
  Object value;
  Entry(ThreadLocal&lt;?&gt; k, Object v) {
  super(k);//key,也就是当前local被包装成了弱引用，也就是当发生tl=null时，local不会因为entry中被key强引用而无法被gc回收，当local被回收后，t.t1就是null,所以map中对应的key也是null,当对线程内部的map进行get或set或remove操作时，会自动清除map中key为null的entry.
  value = v;
}
}


<br>关系图

找不到“picture\JVM-ThreadLocal之弱引用.png”。

<br>local仍然会内存泄漏:value会泄漏

向local中添加了数据u后，如果把u=null,依然无法回收u对象，导致内存泄漏，使用remove后才可回收

<br><br>用PhantomReference来实现，也被称为幽灵引用或幻影引用，是最弱的引用，不能通过这个引用访问对象，可以用来确保对象执行finalize()后，来实现某些机制，比如垃圾回收的跟踪。垃圾回收时会被回收掉。<br>用来管理直接内存的。<br>
<br>
特点

<br>对象是否有虚引用存在，不会对其生存构成影响
<br>他必须和引用队列一起使用，用于跟踪垃圾回收过程
<br>当gc回收一个被虚引用持有的对象后，jvm会立刻（没有重写finallize）或在发生下一次gc时(重写了finallize方法)把虚引用放入队列中，从而gc会进一步回收被该虚引用持有的对象所指向的堆外内存。也就是说，使用虚引用的目的是为了回收堆内对象所引用的堆外对象
<br>为了使对象保持不变，所以get方法返回null


<br>
示例

<br>public class P {
	@Override
	protected void finalize() throws Throwable {
		System.out.println("----88-----");
		super.finalize();
	}
	
	static ReferenceQueue&lt;P&gt; rq = new ReferenceQueue&lt;&gt;();
	public static void main(String[] args) {
		 P p = new P();        
		 ReferenceQueue&lt;Object&gt; rq = new ReferenceQueue&lt;&gt;();
		 PhantomReference&lt;P&gt; pr = new PhantomReference&lt;&gt;(p, rq);
		 
		 System.out.println(pr.get());//获取不到
		 p=null;
		 
		 List&lt;byte[]&gt;list=new ArrayList&lt;&gt;();
		 new Thread(()-&gt;{
	    	while(true){
	    		try {//不停的申请内存，目的是为了引起垃圾回收
	    			list.add(new byte[1024*1024*4]);
				} catch (Throwable e) {
					break;
				}
	    		System.out.println(pr.get());
	    	}
	    	//P如果重写了finallize,则上面gc时，会先执行P的finallize方法，导致P对象没有被回收。
	    	//只是被标记为finallize状态，等待下次gc后，才会把虚引用pr放入队列中
	    	try {//必须休眠一下，保证Ｐ对象的finallize方法执行完毕，如果没执行完就再次gc，还可能不回收。
				Thread.sleep(100);
			} catch (Exception e) {}
	    	System.gc();
	    }).start();
	    
	    new Thread(()-&gt;{
	    	while(true){
	    		if(rq.poll()!=null){
	    			System.out.println("虚引用对象被gc回收了");
	    			break;
	    		}
	    	}
	    }).start();
	}
}
]]></description><link>教程\JVM调优.html</link><guid isPermaLink="false">教程/JVM调优.md</guid><pubDate>Fri, 06 Jun 2025 06:54:58 GMT</pubDate><enclosure url="\01.java程序执行过程.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\01.java程序执行过程.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Linux概述]]></title><description><![CDATA[ 
 <br><br><br>操作系统是实现控制和管理计算机软硬件资源的系统软件。它可以有效地组织多个程序的运行，方便用户操作。常见的操作系统：windows,mac,linux,OS/2,以及各种嵌入式操作系统。目前操作系统的分类：批处理操作系统，分时操作系统，实时操作系统，网络操作系统和分布式操作系统。<br>操作系统的性能指标：吞吐量，资源利用率，公平性，实时性，可靠性以及安全性。<br>操作系统功能：<br>​	存储管理：内存分配，地址映射，内存的保护以及扩充<br>​	进程管理：进程调度，进程控制，进程之间的通信<br>​	文件管理：文件存储空间管理、文件操作、目录、读写权限等<br>​	设备管理：缓冲设备、设备分配、设备驱动<br>​	用户接口：图形用户接口，命令行接口<br><br>Linux，全称GNU/Linux，是一种免费使用和自由传播的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%B1%BBUNIX/9032872?fromModule=lemma_inlink" target="_blank">类UNIX</a>操作系统，其内核由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%9E%97%E7%BA%B3%E6%96%AF%C2%B7%E6%9C%AC%E7%BA%B3%E7%AC%AC%E5%85%8B%E7%89%B9%C2%B7%E6%89%98%E7%93%A6%E5%85%B9/1034429?fromModule=lemma_inlink" target="_blank">林纳斯·本纳第克特·托瓦兹</a>（Linus Benedict Torvalds）于1991年10月5日首次发布，它主要受到<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Minix/7106045?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Minix/7106045?fromModule=lemma_inlink" target="_blank">Minix</a>和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" target="_blank">Unix</a>思想的启发，是一个基于<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/POSIX/3792413?fromModule=lemma_inlink" target="_blank">POSIX</a>的多用户、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%A4%9A%E4%BB%BB%E5%8A%A1/1011764?fromModule=lemma_inlink" target="_blank">多任务</a>、支持<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%A4%9A%E7%BA%BF%E7%A8%8B/1190404?fromModule=lemma_inlink" target="_blank">多线程</a>和多<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/CPU/120556?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/CPU/120556?fromModule=lemma_inlink" target="_blank">CPU</a>的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" target="_blank">操作系统</a>。它支持<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/32%E4%BD%8D/5812218?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/32%E4%BD%8D/5812218?fromModule=lemma_inlink" target="_blank">32位</a>和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/64%E4%BD%8D/2262282?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/64%E4%BD%8D/2262282?fromModule=lemma_inlink" target="_blank">64位</a>硬件，能运行主要的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Unix/219943?fromModule=lemma_inlink" target="_blank">Unix</a>工具软件、应用程序和网络协议。<br>在国内用的比较多的版本：Ubuntu，Centos，RedHat<br><br>linux系统以文件为基础，系统子目录当中的文件主要是保证系统的正常运行。<br>/，/home  /usr  /var  /bin /sbin /etc  /dev  /lib<br>/ : linux系统的根目录（主目录） <br>/home ：用户目录，linux当中每增加一个用户，都会在此目录下相应地增加一个文件，文件名和用户名相同（root除外），给每个用户自己的空间<br>/root： root用户的目录<br>/usr：通常用来安装各种软件的地方<br>/var：通常用来放置一些变化的文件<br>/var/log： 存放系统的日志文件<br>/bin  /sbin: 用于存放linux的系统命令和工具<br>/etc: 系统配置文件所在的位置<br>/dev：存放linux当中的所有设备文件<br>/lib，/lib64:  存放操作系统的库文件<br>/mnt:  外部设备的挂载点<br>/opt：目录是一种用于安装第三方软件的约定目录<br>/run:一个运行时临时文件系统，用于存储在系统运行期间创建的临时文件<br>/proc:目录下的文件和子目录代表系统中运行的实际进程和系统内核的状态<br>/srv:用于存放特定服务相关的数据、配置文件和其他资源。<br>Linux系统是区分大小写，Linux文件没有扩展名<br><br><br>tab补全：linux当中的命令比较多，无法记全的情况下，可以使用tab键进行提示。当只有一个匹配命令时，tab键可以帮助不全，当有个匹配，双按tab，会提示命令。<br>当命令的参数或者option信息不清楚，可以使用man命令或者help进行帮助查看。<br>​	 man  命令（man ls）<br>​	命令 --help<br><br><br>主目录和工作目录：每一个用户都有自己的主目录，这个是管理员在创建用户的时候指定的。用户在自己的home目录当中可以进行各种操作，用户对自己的主目录拥有最大的权限。<br>工作目录：指当前所在的位置，进入linux之后，用户始终都会有一个工作目录。可以使用cd命令切换工作目录。<br>​		可以使用pwd命令查看当前所在的工作目录的完整路径。<br><br>几个特殊路径：<br>​	cd  / :进入根目录<br>​	cd ~: 进入当前用户的主目录<br>​	cd .. :返回到上一级目录<br>​	cd -: 返回上一次所在目录<br>绝对路径： 从文件的根目录开始的路径，始终以 /开头<br>相对路径：从当前的工作目录开始的路径，要和工作目录结合起来，才能确定所在的位置。<br>ls：列举指定目录中的文件和目录<br>mkdir：创建新目录<br>rmdir：删除指定的目录（必须是空目录，如果不是空，可以先删除此目录中的对象，再删除，还可以使用rm命令）<br><br>touch：创建空文件
cp：复制文件。可将文件复制到不同的目录，也可将指定目录中的文件复制到其他位置
mv：将文件或目录移动至一个新的位置
rm:   删除文件或目录
ln ： 创建链接（类似与windows的快捷方式）
whereis：查找文件。可以查找文件的源、二进制文件或手册
which: 查找二进制文件
find：查找文件
location：查找文件
grep ：所有文本<br><br>用touch命令可以创建一个没有任何内容的空文件。<br>touch file01
<br><br>类似与DOS命令中的copy
语法：cp 选项  源文件或目录   目标文件或目录
可以将文件复制到不同的目录，也可以将指定目录中的文件复制到其他位置。
常用参数
-a：相当与-dpr参数
-d：保留链接
-f：强制复制，覆盖目标文件
-i：覆盖时询问用户
-p：保留修改时间和访问权限
-r，-R：递归复制（目录到目录）
-l：创建链接
-v：显示过程<br>#当前文件夹下复制一个文件
cp 3.txt 4.txt 
#将当前目录下的txt复制到根目录下
cp *.txt / 
#将data目录（文件）复制到2目录下 
cp -r data data1/  
#将hello文件复制到/opt目录下
cp -p hello.java /opt/hello.java
<br><br>将文件或目录移到一个新的位子。也可以用来修改文件名称
mv  选项   源文件或目标  目标文件或目录
常用参数：
-i：交互方式操作，如果mv操作将导致对已存在文件的覆盖，此时系统询问是否重写，要求用户回答y或n
-f：禁止交互操作。覆盖时不会提示。<br>mv -i  hello.java  hello1.java
<br><br>​	rm [选项] 文件
​	常用参数：
​	-i : 为了避免误删除文件，可以使用此项，进行用户确认删除
​	-f:  强制删除，使用该选项后将不提示所删除的文件
​	-v:  显示文件的删除速度
​	-r:  删除某个目录以及其中所有的文件和子目录。<br>#删除文件
rm aa
#删除目录
rm -rf a
<br>在Linux中可以创建链接文件，当使用rm删除链接文件时，只是删除该链接文件，实际的文件仍旧继续存在。<br><br>​	Linux中的链接类似于windows的快捷方式，分两种：软连接和硬链接。
​	创建软链接，只是在指定的位置上生成一个镜像，不会占用磁盘空间。
​     	语法： ln  -s   目标文件  链接文件名
​	创建硬链接，将在指定的位置上生成一个和源文件大小相同的文件。
​      	语法：    ln   目标文件  链接文件名
​	无论是软链接还是硬链接，链接文件和目录文件都将保持同步变化。
​	不能创建目录的硬链接。<br>#创建软链接
ln -s hello  hellolink
#查找文件
find -name hello
<br><br>whereis用来查找程序的源、二进制文件或手册。
whereis 选项 文件名
常用选项
-b：搜索文件的二进制部分
-m：搜索文件的手册部分
-s：搜索文件的源部分。<br>不带选项，查找二进制文件和手册的位置<br>whereis ls
<br><br>which 选项 文件名
常用选项
-n：指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。
-p：与-n参数相同，但此处包含文件路径
-w：指定输出时栏位的宽度
-V：显示版本信息<br>which  -V ls
<br><br>可以按照文件名、文件类型、用户等去查找。
find  路径  选项  [-print] [-exec –ok command] {};
常用选项
-name filename :查找名为filename的文件
-perm：按执行权限来查找
-user username：按照文件的所属用户来查找
-group  groupname：按照组来查找
-size n[c] 查长度为n块（n字节）的文件。<br>#根据文件名查找
find /home -name 123.sh
#根据文件大小查找 (+大于 -小于)
find /home -size +20000
#根据文件所有者查找：查找所有者为jp的文件
find /home -user jp
<br><br>locate：从已经创建好的一个索引数据库中查找。比find命令的查找速度更快。
locate 选项  文件名
-b, --basename -- 仅匹配路径名的基本名称
-c, --count -- 只输出找到的数量
-d, -- 数据库路径 -- 使用 DB PATH 指定的数据库，而不是默认数据库 /var/lib/mlocate/mlocate.db
-q, -- 安静模式，不会显示任何错误讯息。
一般不使用参数。<br>locate 与 find 不同: find 是去硬盘找，locate 只在 /var/lib/slocate 资料库中找。
locate 的速度比 find 快，它并不是真的查找，而是查数据库，一般文件数据库在 /var/lib/slocate/slocate.db 中，所以 locate 的查找并不是实时的，而是以数据库的更新为准，一般是系统自己维护，也可以手工升级数据库 ，命令为：updatedb<br>常见问题：
无法执行 stat () `/var/lib/mlocate/mlocate.db': 没有那个文件或目录
解决方案：
执行：updatedb命令<br>[root@centos601 桌面]# locate /etc/sh
locate: can not stat () `/var/lib/mlocate/mlocate.db': 没有那个文件或目录
[root@centos601 桌面]# update locate
bash: update: command not found
[root@centos601 桌面]# updatedb
[root@centos601 桌面]# locate /etc/sh
/etc/shadow
/etc/shadow-
/etc/shells
<br><br>对查找目标中的具体内容进行查找，是一个强大的文本搜索工具。它是一个管道命令，和其它命令结合使用。
工作方式：在一个或多个文件中搜索字符串模板，可以使用正则表达式进行搜索。<br>在linux或unix系统中，|就是管道命令，把上一个命令的结果交给管道命令（|）后面的命令处理<br>#查找/etc/hosts中包含localhost4的内容
cat /etc/hosts | grep localhost4
<br><br><br>cat：将文件中的内容输出到设备上，若是多个文件，则按顺序输出。
cat   选项  文件名
常用选项<br>
<br>-n：由1开始对所有输出的行数编号
<br>-b：和-n相似，只是对于空白行不进行编号
<br>-s：若遇到连续两行以上的空白行，就替换成一行空白行输出。
若准备将多个文件合并为一个文件，则使用以下方式
Cat  选项  文件名1  文件名2…… &gt; 新文件
<br>#将/etc/hosts文件中的内容输出到/opt/a文件中
cat /etc/hosts &gt; /opt/a
#查看/opt/a文件的内容
cat /opt/a
<br><br>more分屏显示 ，可以和其它命令结合使用，也可以单独使用。在 more 这个程序的运行过程中，你有几个按键可以按的：<br>
<br>空白键 (space)：代表向下翻一页；
<br>Enter         ：代表向下翻『一行』；
<br>/字串         ：代表在这个显示的内容当中，向下搜寻『字串』这个关键字；
<br>:f            ：立刻显示出档名以及目前显示的行数；
<br>q             ：代表立刻离开 more ，不再显示该文件内容。
<br>b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。
<br>more /etc/profile
cat day522 | more
<br><br>less分屏显示 ，可以和其它命令结合使用，也可以单独使用。less运行时可以输入的命令有：<br>
<br>空白键    ：向下翻动一页；
<br>[page down]：向下翻动一页；
<br>[page up]  ：向上翻动一页；
<br>/字串     ：向下搜寻『字串』的功能；
<br>?字串     ：向上搜寻『字串』的功能；
<br>n         ：重复前一个搜寻 (与 / 或 ? 有关！)
<br>N         ：反向的重复前一个搜寻 (与 / 或 ? 有关！)
<br>q         ：离开 less 这个程序；
<br>more /etc/profile
<br><br>语法：head [-n number] 文件 <br>head -n 3 /etc/profile
<br><br>语法：tail [-n number] 文件 ，常用来读取日志文件<br>​      -f : 循环读取  tail  -f  文件名<br>​     -n ：数字  读取最后几行<br>tail -n 10 /etc/profile
#循环读取
ping 192.168.66.211 &gt; ping.log &amp;
tail -f ping.log
<br><br>在Linux中，用户和组的相关信息保存在对应的文件中，一共有三个文件，分别是passwd、shadow和group<br>
<br>
passwd文件

<br>用户信息文件  /etc/目录下。	
<br>系统中的每一个合法用户账号对应于该文件中的一行记录。
<br>每一行由7个部分组成：注册名:口令：用户标识号：组标识号：备注：用户主目录：命令解释程序

<br>注册名：登陆账户，不能重复，区分大小写。
<br>口令：登陆系统的口令。若第一个字符是“*”，表示禁止该账号登陆。
<br>用户标志号：Linux中唯一的用户标识
<br>组标志号：当行用户的默认工作组标记
<br>备注：保存一些用户的信息
<br>用户主目录：个人用户的主目录，该用户登陆后，将该目录作为用户的工作目录
<br>命令解释程序：当前用户登陆系统时运行的程序名称，通常是一个shell程序的全路径名。




<br>
shadow文件

<br>保存用户的口令。/etc/目录下
<br>该文件不能被普通用户读取，只有超级用户root才有权读取。


<br>
group文件

<br>保存在/etc/group当中
<br>每一行数据内容 用户组名称：用户组密码：用户组标识号：用户列表


<br><br>
<br>添加组：groupadd
groupadd  policeman 
<br>查看组：通过vi或cat命令
vi  /etc/group
cat /etc/group
<br>删除组：groupdel
groupdel policeman
<br>将现有用户增加到组中
usermod  -g  组名  用户名
<br>从组中删除用户
gpasswd -d 用户名 组名
<br>查看当前用户所在组：groups
<br><br>
<br>创建用户：useradd
useradd 用户名：创建一个新的用户
useradd 用户名 -g 组名	：添加用户，并加入到某个组当中
useradd –m –g 组名 用户名：创建一个新的用户并创建家目录，指定组
<br>修改用户：usermod
usermod -g 组名 用户名 ：修改用户信息
<br>创建密码：password
passwd 用户名 ：为用户创建密码
<br>删除用户：userdel
userdel 用户名	：删除用户名
userdel -r 用户名	：删除用户以及用户主目录

<br>su   用户名称 切换用户


<br><br>修改 /etc/sudoers文件，给对应的用户增加root权限，用户在执行命令式，使用sudo 命令 即可执行管理员的所有权限。<br>## Allow root to run any commands anywhere 
root	ALL=(ALL) 	ALL
#给huangyy增加root权限
huangyy ALL=(ALL) 	ALL
<br><br>Linux的文件类型大致可以分为5种：
普通文件：用于存储数据、程序等信息的文件。文本文件和二进制文件。
目录文件：由文件系统中的一个目录项组成的文件。用户进行只能对其进行读取，不能进行修改
设备文件：用于与IO设备提供连接的文件，可以分为字符设备文件和块设备文件。每一种I/O设备对应于一个设备文件，存放于/dev/目录中。
链接文件：通过链接文件中指向文件的指针来实现对文件的访问。
管道文件：用于进程间传递数据。Linux对管道的操作与对普通文件的操作相同。<br>drwx r-xr-x  test :  第一组 rwx表示test文件的用户所有者(vagrant,vagrant所在的组vgroup（v1,v2,v3,vagrant）)的权限<br>​							r-x(黑色) : 文件所有者的同组其他用户的权限（v1,v3,v2）<br>​                                     r-x: vgroup组以外的其他用户的权限							<br>找不到“/权限1.png”。<br>操作权限分为三种：
R：读取权限  （４），如果是目录，用户可以浏览目录
W ：写权限　（２），如果是目录，用户可以删除、移动目录内的文件
X: ：执行权限（１），如果是目录，则表示可进入此目录，如果是bash命令，则表示可以执行<br><img style="zoom:50%;" alt="权限2" src="\权限2.png" referrerpolicy="no-referrer"><br><br>使用chmod命令可以修改文件的权限。通过权限字母和操作符表达式的方法来设置权限
语法：chmod [用户类型] [+|-|=] [权限字符] 文件名
u=用户权限  g=组权限  o=不同组其他
+：添加权限；-：取消权限 =：赋予给定权限并取消其他所有权限。
权限字符：可以使用r、w、x组合，也可以使用s
使用数字来设置权限
chmod [数字组合] 文件名
用3位八进制数来表示文件的3类用户的权限组合
例如751：表示用户权限为rwx，当前用户组权限：r-x  其他用户组权限为--x<br>#赋予abc权限rwxr-xr-x
chmod 755 abc
#同上
chmod u=rwx,g=rx,o=rx abc
#给abc增加组写权限
chmod go+w abc
#给abc去除用户执行权限，增加当前组写权限
chmod u-x,g+w abc
#给所有用户添加读的权限
chmod a+r abc
<br><br>使用chown命令可以修改文件的所有者和组，只有root用户可以更改用户的所有者。只有root用户或文件所有者可以更改文件的组，如果是文件所有者但不是root用户，则只能将组改为当前用户所在组。
语法：chown 所有者:组 文件<br>#修改文件所有者为xiaohuang
chown xiaohuang  hello.java
<br><br>在Linux中，每个执行的程序都称为一个进程。每一个进程都分配一个ID号。每一个进程，都会对应一个父进程。而这个父进程可以复制多个子进程。
每个进程都可能以两种方式存在的，前台与后台。所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于在屏幕上无法看到的进程，通常使用后台方式执行。一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中，直到关机才结束。<br><br>ps命令是用来查看系统中，有哪些正在执行，以及它们执行的状况。可以不加任何参数。
显示详细的进程信息(终端上的所有进程，包括其它用户)：ps -a
以用户的格式显示进程信息：ps -u
显示后台进程运行参数：px –x
查看更全面信息   ps -aux<br>USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root        485  0.0  0.0      0     0 ?        S    Nov02   0:00 [ext4-dio-unwrit]
root        593  0.0  0.0  11248  1372 ?        S&lt;s  Nov02   0:00 /sbin/udevd -d
root       1800  0.1  0.4 260836  8524 ?        Sl   Nov02   0:20 /usr/sbin/vmtoolsd
root       2044  0.0  0.0  27596   832 ?        S&lt;sl Nov02   0:00 auditd
rpc        2179  0.0  0.0  18980   876 ?        Ss   Nov02   0:00 rpcbind
dbus       2199  0.0  0.1  32556  2088 ?        Ssl  Nov02   0:00 dbus-daemon --system
root       2213  0.0  0.2  84960  4864 ?        Ss   Nov02   0:00 NetworkManager --pid-file=/var/run/NetworkManager/NetworkManager.pid
root       2220  0.0  0.1  58120  2608 ?        S    Nov02   0:00 /usr/sbin/modem-manager
rpcuser    2237  0.0  0.0  23352  1380 ?        Ss   Nov02   0:00 rpc.statd
<br>USER：用户
PID: 进程的ID
PPID:父进程的ID
%CPU:进程占用的CPU百分比
%MEM：进程占用的内存百分比
VSZ:使用的虚拟内存量（KB)
RSS：该进程占用的固定内存量（KB)
STAT:进程的状态。
TTY:该进程在哪个终端上运行，若与终端无关，则显示？ 若为pst/0等，则表示由网络连接主机进程。
TIME:使用CPU的时间<br>其中STAT常见的值如下：<br><br><br>对于前台进程，在推出程序后该进程将自动结束。在前台进程运行过程中，也可按快捷键Ctrl + C 退出。
对于后台进程，需要使用kill命令来终止。<br>信号量：15，9，默认为15 ，告诉进程需要终止，并不一定立刻终止，如果是9，表示强制终止进程<br>#终止pid为4217的进程
kill -9  4217
<br><br>查看系统当前正在执行的进程的相关信息，包括进程id，内存的使用率，CPU的占有率等（动态，实时）<br>load average: 0.00, 0.01, 0.04，分别表示最近一分钟，五分钟，以及十五分钟的负载状况。<br>是否load average大于1就是系统负载比较高。不一定。要看CPU的核数和线程数，如果是单核cpu，值等于1就是满负荷，如果是四核，八核，负载大于1说明负载不算太高。<br>-c: 显示完整的进程命令
-s:  保密模式
-p PID 指定进程显示
-n &lt;次数&gt; 执行循环显示次数
-H 显示线程数
<br><br>可以将命令的最后加上“&amp;”，使得程序放到后台运行。<br>基本用于需要一直运行的服务类进程，比如说tomcat，nginx，mysql<br><br>centos7中采用以下命令对防火墙进行处理。<br>
<br>查看防火墙状态：firewall-cmd --state
<br>停止防火墙： systemctl stop firewalld.service
<br>启动防火墙： systemctl start firewalld.service
<br>重启防火墙： systemctl restart firewalld.service
<br>永久关闭防火墙：systemctl disable firewalld.service
<br>永久关闭后重启：systemctl enable firewalld.service
<br>查看开机防火墙：systemctl is-enabled firewalld.service
<br>端口操作：<br>
<br>开启端口：firewall-cmd --zone=public --remove-port=80/tcp --permanent
<br>刷新：firewall-cmd --reload
<br>查看端口状态：firewall-cmd --zone=public --query-port=80/tcp 

<br>yes表示端口开放，no表示端口不开放


<br>关闭端口：firewall-cmd --zone=public --remove-port=80/tcp --permanent
<br>[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
no
[root@centos701 etc]# firewall-cmd --zone=public --add-port=80/tcp --permanent
success
[root@centos701 etc]# firewall-cmd --reload
success
[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
yes  
[root@centos701 etc]# firewall-cmd --zone=public --remove-port=80/tcp --permanent
success
[root@centos701 etc]# firewall-cmd --reload
success
[root@centos701 etc]# firewall-cmd --zone=public --query-port=80/tcp
no


<br><br>logout：注销系统
login：回到登录界面
shutdown –h now	：立刻关机
shutdown +5	：5分钟后关机
shutdown 10:30：在10：30关机
shutdown –r now	：立刻关闭系统并重启
reboot	：重新启动系统<br><br>vi编辑器是Linux下最有名的编辑器，也是我们学习linux必须掌握的工具，在unix下也可以进行程序的开发。
开发步骤：
vi  文件名
输入i，进入插入模式，
输入Esc键
输入冒号:,再输入wq，保存并退出，如果不保存退出，则输入q!<br>基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 <br><img style="zoom: 50%;" alt="vim工作模式" src="\vim工作模式.png" referrerpolicy="no-referrer"><br><br>用户刚刚启动 vi/vim，便进入了命令模式。此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。以下是常用的几个命令：<br>
<br>i, I字符 ：切换到输入模式，以输入字符。i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』
<br>a, A字符 ：进入输入模式(Insert mode)，a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』
<br>o, O字符 ：进入输入模式(Insert mode)，这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！
<br>r, R：进入取代模式(Replace mode)，r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止
<br>x字符 ：删除当前光标所在处的字符。
<br>:字符 ：切换到底线命令模式，以在最底一行输入命令。
<br>若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。<br><br>在命令模式下按下i就进入了输入模式。在输入模式中，可以使用以下按键：<br>
<br>字符按键以及Shift组合，输入字符大小写转换
<br>ENTER：回车键，换行
<br>BACK SPACE：退格键，删除光标前一个字符
<br>DEL：删除键，删除光标后一个字符
<br>方向键：在文本中移动光标
<br>HOME/END：移动光标到行首/行尾
<br>Page Up/Page Down：上/下翻页
<br>Insert：切换光标为输入/替换模式，光标将变成竖线/下划线
<br>ESC：退出输入模式，切换到命令模式
<br><br>在命令模式下按下:（英文冒号）就进入了底线命令模式。底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。按ESC键可随时退出底线命令模式。
在底线命令模式中，基本的命令有（已经省略了冒号）：<br>
<br>q 退出程序，如果文件内容被修改了，会出现错误，要求使用“!”强制退出。
<br>q! ：强制退出vim，并且不保存文件
<br>w： 保存文件
<br>wq：将修改过的文件存储，并且离开vim
<br>set nu:在文件中每行加入行号
<br>set nonu：取消行号
<br>输入数字：直接输入数字再按enter，就可以将光标定位到改行行首。
<br>/字符串：利用/字符串来查找特定的内容，如果查找不是想要的的，可以按“n”键盘继续查找。
<br>?字符串：同/字符串
<br><br>命令模式下：<br>​	x：删除当前字符<br>​	3x: 删除当前光标开始的3个字符，如果想要删除n个字符，将3替换成n<br>​	X：删除当前光标的前一个字符<br>​	dd: 删除当前行<br>​	dj：删除上一行<br>​	dk：删除下一行<br>​	3d：删除当前行开始往后的3行<br>底线模式下<br>​	:5, 10d: 将5~10的数据删除掉<br>​	:5,$d: 将5行以后的数据全部删除掉<br><br>行拷贝：<br>​	yy：拷贝当前行<br>​	nyy：拷贝当前行开始的n行，5yy，从当前行开始拷贝5行的数据<br>​	p：再当前光标后粘贴<br>​	shift +p：在当前行前面进行粘贴<br>​	:1,5 co 20: 将1~5行copy放到20行之后<br>部分拷贝<br>​	yw：拷贝一个单词<br>​	2yl：拷贝当前光标开始的2个字符<br>​	3yh：拷贝当前光标前面的3个字符（不包括光标的相关字符）<br><br>tar：将指定目录中的所有文件和目录全部进行备份
gzip和gunzip：压缩和解压缩文件
Zip和unzip：压缩文件和解压文件<br><br>tar 是用来建立，还原备份文件的工具程序，它可以加入，解开备份文件内的文件。<br>-A或--catenate 新增文件到已存在的备份文件。
-c或--create 建立新的备份文件。
-C&lt;目的目录&gt;或--directory=&lt;目的目录&gt; 切换到指定的目录。
-f&lt;备份文件&gt;或--file=&lt;备份文件&gt; 指定备份文件。
-v或--verbose 显示指令执行过程。
-x或--extract或--get 从备份文件中还原文件。
-z或--gzip或--ungzip 通过gzip指令处理备份文件。
-Z或--compress或--uncompress 通过compress指令处理备份文件。
--delete 从备份文件中删除指定的文件。
--exclude=&lt;范本样式&gt; 排除符合范本样式的文件。<br>实际使用时经常联合多个选项一起使用，例如<br>-zcvf 创建一个压缩文件<br>
-zxvf   还原并解压缩文件  <br>#归档文件，将tmp文件夹打包成tmp.tgz
tar -zcvf tmp.tgz tmp
#归档文件，排除tmp目录中的w文件，压缩文件名为tmp.tgz,压缩打包放入tmp
tar --exclude=tmp/w  -zcvf tmp.tgz tmp

#创建tmp01目录，并将tmp.tgz解压缩到tmp01目录中。
mkdir tmp01
tar -zxvf tmp.tgz -C tmp01

#将tmp打包成u1.tar
tar -cf u1.tar tmp
#将tmp01打包成u2.tar
tar -cf u2.tar tmp01
#将u1.tar的内容追加到u2.tar当中（u2当中包含tmp和tmp01）
tar -A u1.tar -vf  u2.tar

<br><br>gzip<br>gzip命令用于压缩文件。gzip是个使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出".gz"的扩展名。常用选项如下：<br>
<br>-d或--decompress或----uncompress 　解开压缩文件。
<br>-f或--force 　强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。
<br>-l或--list 　列出压缩文件的相关信息。
<br>-v或--verbose 　显示指令执行过程。
<br>-V或--version 　显示版本信息。
<br>gunzip命令<br>gunzip命令用于解压文件。gunzip是个使用广泛的解压缩程序，它用于解开被gzip压缩过的文件，这些压缩文件预设最后的扩展名为".gz"。事实上gunzip就是gzip的硬连接，因此不论是压缩或解压缩，都可通过gzip指令单独完成。常用选项如下：<br>
<br>-c或--stdout或--to-stdout 　把解压后的文件输出到标准输出设备。
<br>-f或-force 　强行解开压缩文件，不理会文件名称或硬连接是否存在以及该文件是否为符号连接。
<br>-l或--list 　列出压缩文件的相关信息。
<br>-v或--verbose 　显示指令执行过程。
<br>#压缩hello.java文件
gzip -vf hello.java
#将hello.java.gz解压缩
gunzip -vf hello.java.gz
<br><br>linux 下提供了 zip 和 unzip 程序，zip 是压缩程序，unzip 是解压程序。<br>zip命令的常用选项<br>
<br>-g 将文件压缩后附加在既有的压缩文件之后，而非另行建立新的压缩文件。
<br>-q 不显示指令执行过程。
<br>-r 递归处理，将指定目录下的所有文件和子目录一并处理。
<br>-S 包含系统和隐藏文件。
<br>-v 显示指令执行过程或显示版本信息。
<br>unzip常用的选项<br>#将所有的jpg文件压缩成一个z.zip文件
zip z.zip *.jpg
#解压文件
unzip all.zip
<br><br>将jdk的linux安装文件放入到linux的某个目录下<br>解压<br>tar -zxvf  jdkxxx.tar.gz 
<br>设置环境变量<br>在/etc/profile的最后增加以下内容<br>JAVA_HOME=/usr/jdk1.8.0_261
CLASSPATH=.:$JAVA_HOME/lib
PATH=$PATH:$JAVA_HOME/bin

export JAVA_HOME CLASSPATH  PATH
<br>重新加载配置文件<br>source /etc/profile
<br>进行测试<br>java或者java命令就可以测试]]></description><link>教程\Linux课件.html</link><guid isPermaLink="false">教程/Linux课件.md</guid><pubDate>Fri, 11 Aug 2023 03:29:39 GMT</pubDate><enclosure url="\权限2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\权限2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Mysql的逻辑架构]]></title><description><![CDATA[ 
 <br><br>找不到“/01.架构.png”。<br>日志<br>
<br>
重做日志（redo log）持久性、原子性

<br>
回滚日志（undo log)原子性
一致性（通过锁、mvcc来约束）

<br>
二进制日志（bin log），对数据库的任何变化（创建表，更新数据库，对行数据进行增删改）

<br>
错误日志（error log）

<br>
慢查询日志（slow query log）

<br>
一般查询日志（general log）

<br>
中继日志（relay log）

<br><br><br>show processlist 或者show full processlist查看数据库的连接状况<br><br>show engines;  查看所有引擎
show variables like '%storage_engine%';
<br><br>查看sql的时候，只显示两位的有效小数。0.02sec，如果需要更精确的时间，可以使用show profiles查看sql的执行周期。<br><br>show variables like '%profiling%';
<br><br>set profiling =1;
<br><br>show profiles
#进一步查看具体sql的执行步骤 2为show profiles查询出来的queryID
show profile cpu,block io for query 2;
<br><br>global：全局设置，需要重新打开新的窗口。<br><br>show variables like '%slow_query%';
<br><br>set global slow_query_log =1;
<br><br>show variables like '%long_query%'; 
<br>设置慢查询时间<br>set global long_query_time=2;
<br>安装版的日志文件：c:/programData/mysql/mysql版本/xxx.log<br><br><br><br><br>#查看支持的引擎
show engines;
#查看默认的引擎
show variables like '%engine%';
<br><br><br>索引是基于数据库表创建的，它包含表中的某些列以及记录的值（具体是什么值，要看引擎以及索引的种类）。Mysql的官方定义：索引是帮助mysql实现高效获取数据的数据结构。<br>索引：排好序的，能够快速查找数据的数据结构。通过对数据建立索引形成目录，在mysql当中，非主键索引（非聚簇索引），是在特定的数据之外，需要单独去维护的数据结构。索引是一个单独的文件，需要占用物理空间。<br><br>在存储数据的时候，会把数据按照指定的方式组织成某种数据结构（B+树），查询的时候，可以利用该数据结构的特点来提升查询的速度。<br><br>提升查询的效率，降低IO的成本<br>可以利用索引对数据进行排序，降低数据排序的成本，降低CPU的消耗。<br><br>索引实际也可以看作一张表，保存了主键和索引字段，需要占用空间。<br>索引会带来额外的维护成本（增加，删除，修改都需要维护索引表），降低写操作的效率。<br><br>根据列的多少：单值和复合（联合）索引<br>根据是否主键： 主键索引（聚簇索引）以及非主键索引（非聚簇索引、普通索引）<br>是否唯一： 唯一索引，索引列的值必须不能重复（唯一），但是允许有NULL值。（除了null之外的都不能重复）<br>hash索引：采用hash算法，只有在memory引擎的时候才会使用<br>全文索引：5.6以后的版本支持，类似solr，es，把一篇篇文章存储在某一列上，搜索的时候使用全文索引<br><br><br>一起创建索引，复合索引用逗号隔开。<br>create table user (
   id   int primary key auto_increment ,
   name   varchar(30),
   sex    char(1),
   phone   varchar(12),
   email   varchar(50),
   index user_phone(phone)
);
<br><br>create  [unique]  index 索引名 on 表名(索引列名[,索引列名])<br>ALTER TABLE 表名 ADD [UNIQUE]  INDEX  索引名(列名)<br>create index user_email on user(email)
ALTER TABLE user ADD UNIQUE INDEX user_email(email)
<br><br>show index from user
<br><br>drop index 索引名 on table名
<br><br><br>InnoDB:<br>​	主键索引（聚簇索引）：非叶子节点，只包含主键的值，叶子节点包含主键以及所在行的所有数据。索引和数据是一起存储的，整张表就是一个主键索引，表在磁盘上的存储呈现的就是树状结构。这种将数据和索引放在一起的存储方式的索引又称为聚簇索引。<br>​	非主键索引（非聚簇索引，普通索引）：非叶子节点，只存储索引列的值，叶子节点包含改行的主键值和索引列的值。<br>如何查找：如果是利用的主键查询，直接在主键索引表，根据主键的值，快速定位到数据。如果不是主键查询，而是和索引列相关的查询，可以先查索引表，快速拿到数据（只有索引列 + id的情况下）。如果有其他列，则可以通过id，再次通过主键索引获取数据。<br>通过索引获取主键id，再根据主键获取数据的过程，称之为回表。<br>MyISAM引擎:<br>​	主键索引（聚簇索引）：非叶子节点存储依旧是主键值，叶子节点存储的是主键值和该行所在的物理地址。<br>​              非主键索引：和InnoDB是相同<br><br>B+树的插入数据可能会引起数据页的分裂，删除数据可能会引起列的合并，两者都是比较耗时的IO操作。所以比较好的方式就是顺序去插入数据。因为再插入数据的时候，主键值是自动增长的，不需要修改B+树当中已经排好序的节点，提升数据写操作的效率。<br><br>模拟SQL优化器执行sql语句，从而让开发人员知道sql执行的具体信息，分成那几步，是否使用了索引，是否可以再次进行优化。<br>查看执行计划：explain 语句<br>找不到“/../../../../../../images/02.查询计划.png”。<br>id：select查询的序列号，表示select的子句操作表的顺序。<br>​	id值相同，可以认为是一组操作，所有组当中，id值越大，越优先执行。id值越少越好<br>select_type: 查询的类型，主要用来区分普通查询，联合查询还是子查询等<br>​	SIMPLE: 简单的select，查询当中不包括子查询或者union<br>​	PRIMARY: 复杂查询中，最外层的查询被标记为PRIMARY<br>​	UNION:  包含UNION查询，UNION之后的查询，会被标记成UNION，如果From子句中包含子查询，外层select会被标记成DERIVED.<br>​	SUBQUERY: 在select或者where子句当中包含子查询<br>​	DEPENDENT SUBQUERY:  在select或者where子句当中包含子查询，子查询是基于外层的。<br>​	DERIVED: 在from子句当中如果包含子查询的话，有可能被标记为衍生，mysql会将执行结果放在临时表里面<br>type：<br>​	const: 常量查询 ，通过索引一次比对就查询到，一般出现primary key或者unique索引。where条件当中出现主键条件或者unique条件。<br>​	eq_ref:  关联查询当中，唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。<br>​	ref：非唯一性索引扫描，返回匹配某个单独值的所有行。<br>​	range: 只检索给定范围的行。如果条件当中出现between，&gt;,&lt; 等范围条件的时候，如果利用索引扫描的效果比全表扫描要好的话，优化器会优先选择索引中范围查询。<br>​	index：使用了索引，但是没有用索引进行过滤。可能使用索引进行了分组排序。<br>​	all:  全表扫描。本次查询优化器选择不使用索引。<br>possible_keys: 优化器根据查询语句，认为可能命中的索引。但是不一定会命中<br>key: 实际查询中命中索引<br>Extra：辅助说明信息<br>​	Using index：索引覆盖<br>​	Using index condition：索引条件下推<br>​	Using where : 使用了where条件进行过滤<br>​	Using filesort：优化器不使用索引，而是使用cpu进行扫描比较（想办法根据业务看看能否进行优化）<br>​	Using temporary：使用了临时表来保存中间结果，常见于order by， group by以及union可能会出现。<br>​	Using join buffer：关联查询当中经常出现，使用了缓存。<br><br><br>建立复合索引的时候，最常使用的条件列放在最左侧<br>name,phone,email<br>name<br>name phone<br>name phone email<br>如果查询条件当中没有name条件的话，则索引无效。在设计复合索引的时候，要注意此原则<br><br>查询的列在索引表中都能够获取的话，则不需要进行回表处理，我们称之为索引覆盖（Using index）。当优化sql的时候，尽可能满足此原则。<br><br>在mysql5.6之前没有这个功能，为了提升性能，避免不必要的回表，Mysql5.6之后就有了索引下推。<br>一般出现复合索引的部分条件，或者是范围查询的时候。<br>select @@optimizer_switch; 可以查看索引下推的设置项目  index_condition_pushdown<br>set  optimizer_switch=' index_condition_pushdown=off' --关闭<br><br>某些列的数据量比较大的话，建立索引的话，所占的内存空间也比较多。可以使用列的部分值作为索引。为了时间和空间的平衡，可以将列的部分属性（一般都是前面部分）定义成索引。<br>缺点：order by 和group by无法命中索引<br><br>--索引失效
explain select * from employee where substring(name,1,5)= 'Anita'; 
--employee的departmentid的外键索引失效
explain select * from employee where departmentid not in (select departmentid from department where departmentid &gt;30 and departmentid &lt;40);
--索引失效
explain select * from employee where departmentid not in (20,40,50,77);
 explain select * from employee where departmentid  &gt;=10  and departmentid &lt;=30;
<br>过滤字段上使用函数，可能会导致索引失效<br>违法最左原则<br>in或者not in有可能会导致索引失效、范围查询(&gt;,&lt;,&gt;= ,&lt;= )会导致索引失效<br>不等于（!=, &lt;&gt;）会导致索引失效<br>like (百分号在前  like  ''%abc') 可能会导致索引失效<br>字符类型的数据，保存的是数字类的数据，查询的时候，如果不使用单引号，则会导致索引失效。更新的话，可能导致全表都被锁。<br><br>查询的频率是远远高于写操作。<br>数据量太小，不需要建索引<br>查询中与其他表相关联，且作为被驱动表，建立索引<br>唯一约束的字段需要建索引<br>经常用来排序和分组的字段<br>外连接的时候，选择小表作为驱动表，大表作为被驱动表。两个大数据量的表不建议使用外连接查询。<br><br><br>第一范式：每个列都是不可拆分（ 学生设计表的时候，院系专业都放在一个字段当中，违反了第一范式）<br>第二范式：非主键列完全依赖于主键（设计员工表时，将部门名，部门所在的地区信息都放在员工表，违反了第二范式）<br>第三范式：非主键完全依赖于主键，不依赖于其他非主键<br><br>自然主键和代理主键<br>自然主键：充当主键的字段是有一点的含义，是属于记录的重要组成部分。比如说学生的学号，员工在公司中的工号<br>代理主键：充当主键的字段本身不具有自然属性，比如说sequence（oracle），自增长组件（mysql）<br>推荐使用代理主键<br><br>常用的字符集是UTF-8, 建议使用的UTF8mb4。<br><br><br>减少select  的使用，一条记录的数据列比较多的时候，界面又不需要那么多列，可以不使用select去查询<br>尽量去使用limit<br><br>索引对null列会产生额外的空间来保存，而且查询的时候，使用is null 或者is not null会导致索引失效。在设计表的时候，尽量让字段都not null，设置默认值<br><br>Limit偏移量较大的时候，查询的效率比较低。<br>可以记住上一页最后一条记录的id，下次查询的时候，直接根据此ID来进行查询<br><br>限制每张表上的索引数量，建议单张表的索引不超过5个<br>1：索引可以增加查询的效率，但是会降低增删改（写操作）的效率<br>2：mysql优化器在选择如何使用索引时，要根据信息，对每一种案例进行评估，以生成最好的执行计划。如果有多个索引都可以用于查询，就会增加mysql优化器在生成执行计划时的时间，也会降低系统的查询性能。<br><br>order by和group by字段上建立索引<br>order by 尽量要不全部升序，要不就是全部降序。<br>group by的使用原则和order by一致<br><br>被驱动表建立索引<br>在业务允许的情况下，尽量使用小表作为驱动表，大表作为被驱动表<br>尽量不要使用子查询，如果用，尽量不要使用子查询作为被驱动表（子查询结果是没办法建索引）<br>当外关联的两个表的数据量都很大的时候，可以考虑单个表数据取出，在java或者C#的代码中进行合并处理<br>范围查询，尽量不要使用not in 和not exists，可以使用 left join  ...  on where xxx  is  null<br><br>mysql的锁分为行级锁和表级锁<br>表级锁，需要通过代码去执行，行级锁是mysql的innodb的默认锁级别，当产生写操作的时候，mysql会自动帮我们增加行级锁。<br><br>分为读锁和写锁，读锁是共享锁，写锁是排他锁<br>lock table 表名  read/write<br>   读锁：大家可以共享读，但是谁也不能写<br>​    写锁：自己可以读写，别人不能操作<br><br>行锁： 当进行写操作的时候，mysql数据自动增加行级锁，超时或者提交回滚之后会进行锁的释放。<br>行锁可能会引起范围锁。<br>写操作的时候，如果因为索引的失效，可能会导致表锁（务必小心）。<br>innodb_lock_wait_timeout 行锁的等待的时间，可以将时间调小，避免长时间阻塞，特殊情况下，也可以将时间调大，避免发生大的回滚（批处理操作的时候）<br>找不到“/../../../../../../images/01.架构.png”。]]></description><link>教程\Mysql补充.html</link><guid isPermaLink="false">教程/Mysql补充.md</guid><pubDate>Wed, 23 Aug 2023 00:44:24 GMT</pubDate></item><item><title><![CDATA[Obsidian]]></title><description><![CDATA[ 
 <br><br>Obsidian git仓库]]></description><link>教程\README.html</link><guid isPermaLink="false">教程/README.md</guid><pubDate>Fri, 25 Jul 2025 05:42:05 GMT</pubDate></item><item><title><![CDATA[分库分表]]></title><description><![CDATA[ 
 <br><br><br><br>提升性能、增加可用性<br>提升性能<br>如果单表数据量过大，当数据量超过一定量级后，无论是查询还是更新，在经过添加索引等纯数据库层面的传统优化手段之后，还是可能存在性能问题。这时候就需要去换个思路来解决问题。比如从数据生产源头、数据处理源头入手，既然数据量很大，那我们就来个分而治之，化整为零。这就产生了分表，把数据按照一定的规则分成多张表，突破单表环境下的数据存取性能瓶颈。<br>如果表的数据量超过一千万行，即使SQL使用了索引，查询也是会明显变慢。这是因为索引一般是B+树结构，数据千万级别的话，B+树的高度会增高，查询就会变慢。以MySQL的InnoDB为例，InnoDB存储引擎最小储存单元是页，一页大小固定是16KB，使用该引擎的表为索引组织表。B+树叶子存的是数据，内部节点存的是键值和指针。索引组织表通过非叶子节点的二分查找法以及指针确定数据在哪个页中，进而再去数据页中找到需要的数据。<br>增加可用性<br>单个数据库如果发生意外，很可能会丢失所有数据。尤其是云时代，很多数据库跑在虚拟机上，如果虚拟机/宿主机发生意外，可能造成无法挽回的损失。因此，除了传统的Master-Slave、Master-Master等部署层面解决可用性问题的方案外，我们也可以考虑从数据分片层面在一定程度上解决此问题。<br><br>如果B+树的高度为2，即有一个根节点和若干个叶子节点，则这棵B+树的存放总记录数为：根节点指针数 * 单个叶子节点记录行数。<br>假设一行记录的数据大小为1KB，那么单个叶子节点可以存的记录数 =16KB/1KB =16。非叶子节点内可以存放多少指针呢？假设主键ID为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节，所以就是一个键值指针占用8+6=14字节，一个内部节点中存储的指针个数为 16KB/14B = 16  1024B / 14B = 1170。因此，一棵高度为2的B+树，能存放 1170  16 = 18720 条这样的数据记录。同理一棵高度为3的B+树，能存放 1170 1170 16 = 21902400，大概两千万左右的记录。<br>B+树高度一般为1-3层，如果到了4层，查询时会增加查磁盘的次数，数据寻找就会变慢。因此如果单表数据量太大，SQL查询变慢，就需要考虑分表了。<br><br>将一个数据库拆分成多个数据库<br>一种是多个数据库具有同等能力<br>一种是主备模式<br><br>水平拆分：将表中的数据按照一定的规则进行拆分，比如按照年份，日期，主键值范围等<br>垂直拆分：将字段比较多的表拆成多个字段比较少的表，一般不建议做垂直拆分，这种拆分应该在需求定义的时候已经规划<br><br><br>虽然数据分片解决了性能、可用性以及单点备份恢复等问题，但分布式的架构在获得收益的同时，也引入了新的问题。面对如此散乱的分片之后的数据，应用开发工程师和数据库管理员对数据库的操作变得异常繁重就是其中的重要挑战之一。<br><br>数据库被切分后，不能再依赖数据库自身的自增主键生成机制，因为多实例之间不感知彼此的ID，会出现ID重复。常用的分布式ID解决方案有：UUID、基于数据库自增单独维护一张全局ID表、互斥号段模式、Redis单线程自增、雪花算法（Snowflake）等。<br><br>在单库未拆分之前，我们可以很方便地使用join操作关联多张表查询数据，但是经过分库分表后，关联表可能不在一个数据库实例中，如何使用join呢？通常有以下几种解决方案。<br>数据复制：将需要关联的表通过数据库提供的复制机制，整合到同一个实例中。
字段冗余：把需要关联的字段放入主表中，避免join操作。
数据抽象：通过ETL工具将数据汇总聚合，生成新表。
全局表：把一些基础表在每个数据库中都放一份。
应用层组装：将基础数据查出来（即所谓两次查询），通过应用程序计算组装<br><br>单数据库可以用本地事务，使用多数据库就只能通过分布式事务解决了。常用解决方案有两阶段提交（2PC）和柔性事务（BASE）等。<br><br>在使用SQL时order by、limit等关键字和聚合函数需要特殊处理。一般来说采用分片的思路，先在每个分片上执行相应的排序和函数，然后将各个分片的结果集进行汇总并再次计算，得到最终结果<br><br>传统数据库软件开发中，主键自动生成技术是基本需求。而各个数据库对于该需求也提供了相应的支持，
比如MySQL 的自增键，Oracle 的自增序列等。数据分片后，不同数据节点生成全局唯一主键是非常棘手
的问题。同一个逻辑表内的不同实际表之间的自增键由于无法互相感知而产生重复主键。虽然可通过约
束自增主键初始值和步长的方式避免碰撞，但需引入额外的运维规则，使解决方案缺乏完整性和可扩展
性。
目前有许多第三方解决方案可以完美解决这个问题，如UUID 等依靠特定算法自生成不重复键，或者通过
引入主键生成服务等。为了方便用户使用、满足不同用户不同使用场景的需求，Apache ShardingSphere
不仅提供了内置的分布式主键生成器，例如UUID、SNOWFLAKE，还抽离出分布式主键生成器的接口，
方便用户自行实现自定义的自增主键生成器。     <br><br>UUID是指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。通常平台会提供生成的API。按照制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片ID码和随机数。<br>UUID由以下几部分的组合：<br>
<br>当前日期和时间，UUID的第一个部分与时间有关，如果你在生成一个UUID之后，过几秒又生成一个UUID，则第一个部分不同，其余相同
<br>时钟序列
<br>全局唯一的IEEE机器识别号，如果有网卡，从网卡MAC地址获得，没有网卡以其他方式获得
<br>缺点：<br>不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
ID作为主键时在特定的环境会存在一些问题，比如做DB主键或者索引的场景下，UUID就非常不适用<br><br>SnowFlake 算法，是 Twitter 开源的分布式id 生成算法。其核心思想就是：使用一个 64 bit 的 long 型的数字作为全局唯一 id。在分布式系统中的应用十分广泛，且ID 引入了时间戳，可以保证所有生成的ID按时间趋势递增整个分布式系统内不会产生重复ID<br>sharding-jdbc 中雪花算法生成的主键主要由 4部分组成，1bit符号位、41bit时间戳位、10bit工作进程位以及 12bit 序列号位。<br>缺点：<br>依赖机器时钟，如果机器时钟回拨，会导致重复ID生成<br> 在单机上是递增的，但是由于设计到分布式环境，每台机器上的时钟不可能完全同步，有时候会出现不是全局递增的情况（此缺点可以认为无所谓，一般分布式ID只要求趋势递增，并不会严格要求递增～90%的需求都只要求趋势递增）<br><br>当使用数据库来生成ID性能不够要求的时候，我们可以尝试使用Redis来生成ID。这主要依赖于Redis是单线程的，所以也可以用生成全局唯一的ID。可以用Redis的原子操作 INCR和INCRBY来实现。redis incr操作最大支持在64位有符号的整型数字。<br>缺点：<br>redis 宕机后不可用，RDB重启数据丢失会重复ID<br>自增，数据量易暴露。<br><br>例如美团的uid生成，其实就是采用修改的自增长主键来进行处理的。需要zookeeper注册中心<br><a rel="noopener nofollow" class="external-link" href="https://tech.meituan.com/2017/04/21/mt-leaf.html" target="_blank">https://tech.meituan.com/2017/04/21/mt-leaf.html</a><br><br><img alt="image-20220831083333869" src=".\file:\\C:\\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220831083333869.png" referrerpolicy="no-referrer"><br><br>SQL解析》查询优化》SQL路由》SQL改写》SQL执行==》结果归并<br>
<br>SQL解析
分为词法解析和语法解析。 先通过词法解析器将 SQL 拆分为一个个不可再分的单词。再使用语法解析器对 SQL 进行理解，并最终提炼出解析上下文。 解析上下文包括表、选择项、排序项、分组项、聚合函数、分页信息、查询条件以及可能需要修改的占位符的标记。
<br>执行器优化
合并和优化分片条件，如 OR 等。
<br>SQL路由
根据解析上下文匹配用户配置的分片策略，并生成路由路径。目前支持分片路由和广播路由。
<br>SQL改写
将 SQL 改写为在真实数据库中可以正确执行的语句。SQL 改写分为正确性改写和优化改写。
<br>SQL执行
通过多线程执行器异步执行。
<br>结果归并
将多个执行结果集归并以便于通过统一的 JDBC 接口输出。结果归并包括流式归并、内存归并和使用装饰者模式的追加归并这几种方式。
<br><br><br>用于单分片键的标准分片场景，对应StandardShardingStrategy，提供对SQL语句中的=, &gt;, &lt;, &gt;=, &lt;=, IN和BETWEEN AND的分⽚操作⽀持。
shardingColumn: # 分片列名称
shardingAlgorithmName: # 分片算法名称<br><br>用于多分片键的复合分片场景，对应ComplexShardingStrategy复合分⽚策略。提供对SQL语句中的=, &gt;, &lt;, &gt;=, &lt;=, IN和BETWEEN AND的分⽚操作⽀持。
shardingColumns: 分片列名称，多个列以逗号分隔
shardingAlgorithmName: # 分片算法名称<br><br>Hint 分片策略，对应HintShardingStrategy，通过Hint指定分⽚值⽽⾮从SQL中提取分⽚值的⽅式进⾏分⽚的策略。<br>​	shardingAlgorithmName: # 分片算法名称<br><br>不分片<br><br><br>类型：MOD<br>可配置属性：sharding‐count  （int）分片数量<br><br>类型：HASH_MOD<br>可配置属性：sharding‐count  （int）分片数量<br><br>VOLUME_RANGE<br>可配置属性：<br>​	range‐lower：（long）  范围下界，超过边界的数据会报错<br>​	range‐upper：（long）  范围上界，超过边界的数据会报错<br>​	sharding‐volume：（int）  分片容量		<br><br>注意shardingsphere的每个版本差异较大，尤其是5.x和4.x，使用的时候要注意<br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;2.1.4&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
            &lt;artifactId&gt;shardingsphere-jdbc-core-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;5.1.0&lt;/version&gt;
        &lt;/dependency&gt;
<br><br><br>分别创建ds_0和ds_1两个数据库<br>SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for `t_stu_0`
-- ----------------------------
DROP TABLE IF EXISTS `t_stu_0`;
CREATE TABLE `t_stu_0` (
  `stu_id` bigint(20) NOT NULL,
  `stu_name` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`stu_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
<br><br>server:
  port: 8080
mybatis:
  type-aliases-package: wanho.boot18shardingjdbc.domain
  mapper-locations: classpath:mappers/*.xml
spring:
  shardingsphere:
    datasource:
      names: ds0,ds1
      ds0:
        type: com.zaxxer.hikari.HikariDataSource  #com.alibaba.druid.pool.DruidDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        jdbcUrl: jdbc:mysql://localhost:3306/ds_0?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8
        username: root
        password: root
      ds1:
        type: com.zaxxer.hikari.HikariDataSource  #com.alibaba.druid.pool.DruidDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        jdbcUrl: jdbc:mysql://localhost:3306/ds_1?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8
        username: root
        password: root
    rules:
      sharding:
        tables:
          t_stu:  # actual-data-nodes数据节点配置，采用Groovy表达式 t_user_0,t_user_1
            actual-data-nodes: ds$-&gt;{0..1}.t_stu_0  
        default-database-strategy:
          standard:  #用于使用单一键作为分片键的=、IN、BETWEEN AND、&gt;、&lt;、&gt;=、&lt;= 进行分片的场景。
            sharding-algorithm-name: inline
            sharding-column: stu_id
#          complex:  #复合键盘使用的场合
#            sharding-algorithm-name: inlinw
#            sharding-columns: stu_id,stu_name
        sharding-algorithms:
          inline:
            type: HASH_MOD
            props:
              sharding-count: "2"  #必须写成带引号的形式，内部要转换成int
    props:
      sql-show: true
<br><br>public interface StuDao {
    @Insert("insert into t_stu(stu_id,stu_name) value(#{stu_id},#{stu_name})")
    void insert(Stu stu);
}
<br><br>@RestController
public class StuController {
    @Resource
    StuDao stuDao;
    @GetMapping("/saveStu")
    @Transactional
    public String saveStu(){
        stuDao.insert(new Stu(new Random().nextInt(10000),"888"));
        stuDao.insert(new Stu(new Random().nextInt(10000),"999"));
        stuDao.insert(new Stu(new Random().nextInt(10000),"aaa"));
        return "success";
    }
}
<br><br>多个数据库采用XA两段式强事务<br><br>注意shardingsphere-jdbc-core-spring-boot-starter的版本为5.1.0的时候，事务的版本必须是5.0.0，否则会抛出<br>异常：shardingsphere com.atomikos.icatch.jta.JtaTransactionServicePlugin.beforeInit()V<br>&lt;dependency&gt;
    &lt;groupId&gt;org.apache.shardingsphere&lt;/groupId&gt;
    &lt;artifactId&gt;shardingsphere-transaction-xa-core&lt;/artifactId&gt;
    &lt;version&gt;5.0.0&lt;/version&gt;
&lt;/dependency&gt;
<br><br>@Transactional
@ShardingSphereTransactionType(TransactionType.XA)：指定使用XA事务<br>@RestController
public class StuController {
    @Resource
    StuDao stuDao;
    
    @GetMapping("/saveStu")
    @Transactional
    @ShardingSphereTransactionType(TransactionType.XA)
    public String saveStu(){
      
        stuDao.insert(new Stu(new Random().nextInt(10000),"888"));
        stuDao.insert(new Stu(new Random().nextInt(10000),"999"));
        //int y=10/0;
        stuDao.insert(new Stu(new Random().nextInt(10000),"aaa"));
        return "success";
    }
}

<br><br><br>SET FOREIGN_KEY_CHECKS=0;

-- ----------------------------
-- Table structure for `t_user_0`
-- ----------------------------
DROP TABLE IF EXISTS `t_user_0`;
CREATE TABLE `t_user_0` (
  `user_id` varchar(50) NOT NULL,
  `user_name` varchar(30) DEFAULT NULL,
  PRIMARY KEY (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;


DROP TABLE IF EXISTS `t_user_1`;
CREATE TABLE `t_user_1` (
  `user_id` varchar(50) NOT NULL,
  `user_name` varchar(30) DEFAULT NULL,
  PRIMARY KEY (`user_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;

-- ----------------------------
-- Records of t_user_1
-- ----------------------------

<br><br>server:
  port: 8080
mybatis:
  type-aliases-package: wanho.boot18shardingjdbc.domain
  mapper-locations: classpath:mappers/*.xml
spring:
  shardingsphere:
    datasource:
      names: ds0
      ds0:
        type: com.zaxxer.hikari.HikariDataSource  #com.alibaba.druid.pool.DruidDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        jdbcUrl: jdbc:mysql://localhost:3306/ds_0?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8
        username: root
        password: root
    rules:
      sharding:
        tables:
          t_user:
            actual-data-nodes: ds0.t_user_$-&gt;{0..1}  #数据节点配置，采用Groovy表达式
            table-strategy: # 配置策略
              standard:  # 用于单分片键的标准分片场景
                sharding-column: user_id
                sharding-algorithm-name: user-inline  # 分片算法名字，必须是中横线分隔，不可以是下划线
        sharding-algorithms:
          user-inline:
            type: HASH_MOD
            props:
              sharding-count: "2"  #必须写成带引号的形式，内部要转换成int
    props:
      sql-show: true
<br><br>public interface UserDao {

    @Insert("insert into t_user(user_id,user_name) " +
            "value(#{user_id},#{user_name})")
    void insert(User user);

    @Select("select * from t_user")
    List&lt;User&gt; selectAll();
}
<br><br>@RestController
public class UserController {
    @Resource
    UserDao userDao;

    @GetMapping("/save")
    @Transactional
    public String save(){
        User user = new User(UUID.randomUUID().toString(),"111");
        userDao.insert(user);

        User user1 = new User(UUID.randomUUID().toString(),"222");
        userDao.insert(user1);

        User user2 = new User(UUID.randomUUID().toString(),"3333");
        userDao.insert(user2);
        return "success";
    }

    @GetMapping("/list")
    public List&lt;User&gt; list(){
        List&lt;User&gt; users = userDao.selectAll();
        return users;
    }
}
<br><br>主启动类上增加@EnableTransactionManagement 注解（本地可选）<br>在对应的方法上使用@Transactional注解<br><br><br>实现StandardShardingAlgorithm接口<br>public class CustomizeAlgorithms implements StandardShardingAlgorithm&lt;String&gt;{

    @Override
    public String doSharding(Collection&lt;String&gt; collection, PreciseShardingValue&lt;String&gt; preciseShardingValue) {
       //获取到分片列的值
        String id = preciseShardingValue.getValue();
        String index = String.valueOf(id.hashCode()%2);
        String tableReal = preciseShardingValue.getLogicTableName().concat("_").concat(index);
        System.out.println(tableReal);
        return tableReal;
    }

    @Override
    public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; collection, RangeShardingValue&lt;String&gt; rangeShardingValue)
    {
        return collection;
    }

    @Override
    public void init() {
    }
   
    @Override
    public String getType() {
        return "CUSTOMIZE_TYPE";
    }
}
<br><br>在resources目录下创建META-INF/services目录，并且创建org.apache.shardingsphere.sharding.spi.ShardingAlgorithm文件，将类的全名称放入其中<br>xxx.alg.CustomizeAlgorithms
<br><br>spring:
  shardingsphere:
    datasource:
      names: ds0
      ds0:
        type: com.zaxxer.hikari.HikariDataSource  #com.alibaba.druid.pool.DruidDataSource
        driverClassName: com.mysql.cj.jdbc.Driver
        jdbcUrl: jdbc:mysql://localhost:3306/ds_0?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8
        username: root
        password: root
    rules:
      sharding:
        tables:
          t_user:
            actual-data-nodes: ds0.t_user_$-&gt;{0..1}  #数据节点配置，采用Groovy表达式
            table-strategy: # 配置策略
              standard:  # 用于单分片键的标准分片场景
                sharding-column: user_id
                sharding-algorithm-name: t-stu-alg  # 分片算法名字※※※※※
        sharding-algorithms:
          t-stu-alg:    #※※※※※※※※※
            type: CUSTOMIZE_TYPE   #自定义类中getType返回的值※※※※※※※※
            props:
              strategy: standard
              algorithm-class-name: xxx.alg.CustomizeAlgorithms  #全类名※※※※※※※※※※※
    props:
      sql-show: true
      
<br><br>//问题：产生的全部都是偶数
SnowflakeKeyGenerateAlgorithm algorithm = new SnowflakeKeyGenerateAlgorithm();
System.out.println((Long)algorithm.generateKey());
System.out.println((Long)algorithm.generateKey());
System.out.println((Long)algorithm.generateKey());
]]></description><link>教程\shardingjdbc.html</link><guid isPermaLink="false">教程/shardingjdbc.md</guid><pubDate>Mon, 15 Jan 2024 00:59:21 GMT</pubDate><enclosure url="C:\\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220831083333869.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="C:\\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220831083333869.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Spring cloud]]></title><description><![CDATA[ 
 <br><br>Spring Cloud是一个基于Spring boot实现的微服务架构开发工具,微服务架构是SOA架构的发展。它为微服务架构中提供配置管理、服务治理、智能路由、断路器以及集群状态管理等等。Spring cloud是基于HTTP协议的架构。<br>Springboot只用来开发单个服务<br>Springcloud可以开发多个服务<br>核心组件：<br>​	注册中心：Eureka ，Nacos，Consul<br>​	负载均衡：Ribbon，sentinel， loadbalancer<br>​	容错保护：Hystrix，resilience4j，sentinel<br>​	服务调用：feign，openfeign<br>​	网关：Zuul，Gateway<br>​	配置中心：config，Nacos<br><br>有一个服务（提供者），提供图书的检索功能。<br>有另外一个服务（消费者），需要买书时，按照编号查看书的信息。<br><br>创建普通maven工程base00-common，并编写实体类<br>@Data
@NoArgsConstructor
@AllArgsConstructor
public class Book {
    String isbn;
    String name;
    String author;
    double price;
}
<br><br>创建一个spring boot的web工程，并增加base00-common的依赖<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base00-common&lt;/artifactId&gt;
	&lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;
<br><br>@Service
public class BookService {

    static Map&lt;String,Book&gt; map = new HashMap&lt;&gt;();
    static {
        map.put("SB1001",new Book("SB1001","随便","佚名",50));
        map.put("SB1002",new Book("SB1002","浮士德","歌德",60));
        map.put("SB1003",new Book("SB1003","我们仨","杨绛",25));
    }


    public Book findByIsbn(String isbn) {
        //查询数据库
        return map.get(isbn);
    }
}
<br><br>@Resource
BookService bookService;

@GetMapping("book/{isbn}")
public Book findBookByIsbn(@PathVariable("isbn") String isbn){
	return bookService.findByIsbn(isbn);
}
<br><br>创建一个普通springboot的web工程，并增加base00-common的依赖<br>用户服务<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base00-common&lt;/artifactId&gt;c
	&lt;version&gt;1.0&lt;/version&gt;
&lt;/dependency&gt;c
<br><br>@Bean
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }
<br><br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";

    @Resource
    RestTemplate restTemplate;

    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }
}
<br><br>@RestController
public class UserController {

    @Resource
    UserService userService;

    @GetMapping("borrow/{isbn}")
    public Book searchBook(@PathVariable("isbn") String isbn) {
        return userService.searchBook(isbn);
    }
}
<br><br>是Spring cloud中的一个服务治理模块。<br>NetFlix公司一系列开源产品中的其中之一，它的主要作用是服务的注册和发现。<br>服务器端：也称为服务注册中心，提供服务的注册和发现。Eureka支持高可用的配置，当集群当中有节点（分片）出现故障时，Eureka会自动进入自我保护模式，它允许故障期间提供服务的发现和注册，当故障分片（节点）恢复后，集群的其他节点（分片）会把数据同步过来。<br>客户端：主要包含服务的生产者和服务消费者。服务的提供者要和服务器端维持心跳，来更新它的服务租约。可以将服务器端的注册信息缓存到本地，并周期性的更新服务状态。<br>找不到“/eureka.png”。<br><br>创建一个普通springboot工程base01-eureka，注意不要选择web依赖，增加Eureka服务端依赖<br><br>&lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.7.9&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;net.wanho&lt;/groupId&gt;
    &lt;artifactId&gt;base01-eureka&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
    &lt;name&gt;base01-eureka&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;spring-cloud.version&gt;2021.0.6&lt;/spring-cloud.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;
<br><br>server:
  port: 7100
spring:
  application:
    name: eureka-server
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
      #是否从注册中心拉取信息，本身就是注册中心，不需要拉取信息
    fetch-registry: false
    #当前工程是否要到注册中心去注册， 本身就是注册中心，所以不需要
    register-with-eureka: false
  instance:
    hostname: localhost
<br><br>增加@EnableEurekaServer注解<br>@SpringBootApplication
@EnableEurekaServer  //启用Eureka的服务器端
public class Base01EurekaApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01EurekaApplication.class, args);
    }

}

<br><br>在原来的base01-provider上进行修改<br><br>在各自的节点内，增加以下相关内容，注意不要覆盖<br>&lt;properties&gt;
        &lt;spring-cloud.version&gt;Hoxton.SR9&lt;/spring-cloud.version&gt;
    &lt;/properties&gt;
    
    &lt;dependencies&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;
        &lt;/dependency&gt;
        
    &lt;/dependencies&gt;
     &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
                &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
                &lt;version&gt;${spring-cloud.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
            
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

<br><br>server:
  port: 8090
spring:
  application:
    name: bookapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>增加@EnableEurekaClient注解或者@EnableDiscoveryClient <br>@SpringBootApplication
@EnableEurekaClient  //启用Eureka的客户端
//@EnableDiscoveryClient  //使用于Eureka以及其他非Eureka的卡护短
public class Base01ProviderApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ProviderApplication.class, args);
    }

}

<br><br>在原来的base01-consumer上进行修改<br><br>参考服务提供者<br><br>server:
  port: 8081
spring:
  application:
    name: userapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>增加@EnableEurekaClient注解<br>@SpringBootApplication
@EnableEurekaClient
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>增加负载均衡<br>@Bean
@LoadBalanced  //启用ribbon的负载均衡
public RestTemplate restTemplate(){
    return new RestTemplate();
}
<br><br>用服务名替换原来的具体节点URL<br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";
    //用服务名替换具体的服务器的URL
    String host = "http://BOOKAPP";

    @Resource
    RestTemplate restTemplate;
 
    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }
}
<br><br>使用eureka.instance.prefer-ip-address=true显示ip<br>eureka.instance.ip-address=127.0.0.1来指定ip地址<br>server:
  port: 8070
spring:
  application:
    name: bookapp
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
  instance:
    prefer-ip-address: true
    ip-address: 127.0.0.1
<br><br>默认情况下，Eureka client是可以刷新的。当刷新客户端时，客户端暂时从服务器中取消注册，可能在短暂的时间内不提供给定的服务实例。设置配置：eureka.client.refresh.enable=false ，则不刷新客户端<br><br>默认情况下，Eureka服务器端在一定的时间内如没有接收某个服务端实例的心跳，EurekaServer将会注销该实例。当网络发生故障的时候，微服务就可能无法正常通信。Eureka通过自我保护来解决这个，在短时间内失去过多的客户端的时候，进入自我保护模式，一但进入该模式，就会保护服务列表，不再删除服务注册列表中的数据。当故障恢复以后，退出自我保护模式。<br><br><br>客户端的负载均衡器，进程内部的负载均衡器。默认的策略是轮询，还有一个是随机。可以自定义策略。<br>使用方式，在RestTemplate对象上加入@LoadBalanced<br><br>定义一个类（不能使用@Configuration注解），在此类当中增加一个@Bean注解的方法。返回RactorLoadbalancer接口的对象。<br>在配置类或者主启动类上使用@@LoadBalancerClients或者@LoadBalancerClient，指定上述定义的类为配置类<br><br>注意：千万不要增加@Configuration注解<br>public class LoadBalancerConfig {

    @Bean
    ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
                                                            LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new RandomLoadBalancer(loadBalancerClientFactory
                .getLazyProvider(name, ServiceInstanceListSupplier.class),
                name);
    }
}
<br><br>@SpringBootApplication
@EnableEurekaClient
//配置单个服务的负载均衡策略
//@LoadBalancerClient(value = "GOODS",configuration = LoadBalancerConfig.class)
//多个服务，采用同一个策略
@LoadBalancerClients(defaultConfiguration = LoadBalancerConfig.class)

//@LoadBalancerClients(value = {@LoadBalancerClient(value = "GOODS",configuration =LoadBalancerConfig.class )}
//                , defaultConfiguration = LoadBalancerConfig.class)
public class Base01OrderApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01OrderApplication.class, args);
    }


    @Bean
    @LoadBalanced
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>需求：使用轮询方式访问服务器，每个服务器访问三次之后换下一个服务器<br>需要两个属性：1）用来记录当前的服务器被调用了几次 <br>​						 2）记录当前服务器是第几台服务器<br>如果当前的服务器已经被调用三次，换下一台服务器（i ）<br><br>public class MyRRLoadBalancer implements ReactorServiceInstanceLoadBalancer {
    private static final Log log = LogFactory.getLog(RoundRobinLoadBalancer.class);
    final AtomicInteger position;
    final String serviceId;
    ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider;
    int count=0;
    int MAX=3;

    public MyRRLoadBalancer(String serviceId, ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider) {
        this((new Random()).nextInt(1000),serviceId,serviceInstanceListSupplierProvider);
    }

    public MyRRLoadBalancer(int position, String serviceId, ObjectProvider&lt;ServiceInstanceListSupplier&gt; serviceInstanceListSupplierProvider) {
        this.position = new AtomicInteger(position);;
        this.serviceId = serviceId;
        this.serviceInstanceListSupplierProvider = serviceInstanceListSupplierProvider;
    }

    public Mono&lt;Response&lt;ServiceInstance&gt;&gt; choose(Request request) {
        ServiceInstanceListSupplier supplier = (ServiceInstanceListSupplier)this.serviceInstanceListSupplierProvider.getIfAvailable(NoopServiceInstanceListSupplier::new);
        return supplier.get(request).next().map((serviceInstances) -&gt; {
            return this.processInstanceResponse(supplier, serviceInstances);
        });
    }

    private Response&lt;ServiceInstance&gt; processInstanceResponse(ServiceInstanceListSupplier supplier, List&lt;ServiceInstance&gt; serviceInstances) {
        Response&lt;ServiceInstance&gt; serviceInstanceResponse = this.getInstanceResponse(serviceInstances);
        if (supplier instanceof SelectedInstanceCallback &amp;&amp; serviceInstanceResponse.hasServer()) {
            ((SelectedInstanceCallback)supplier).selectedServiceInstance((ServiceInstance)serviceInstanceResponse.getServer());
        }

        return serviceInstanceResponse;
    }

    private Response&lt;ServiceInstance&gt; getInstanceResponse(List&lt;ServiceInstance&gt; instances) {
        if (instances.isEmpty()) {
            if (log.isWarnEnabled()) {
                log.warn("No servers available for service: " + this.serviceId);
            }

            return new EmptyResponse();
        } else if (instances.size() == 1) {
            return new DefaultResponse((ServiceInstance)instances.get(0));
        } else {
            int pos;
            if(count&lt;MAX) {
               pos =  this.position.get();
            } else {
               pos = this.position.incrementAndGet() &amp; 2147483647;
               count=0;
            }
            ServiceInstance instance = (ServiceInstance)instances.get(pos % instances.size());
            count++;
            return new DefaultResponse(instance);
        }
    }
}
<br><br>public class LoadBalancerConfig {

    //@Bean
    //ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
    //                                                        LoadBalancerClientFactory loadBalancerClientFactory) {
    //    String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
    //    return new RandomLoadBalancer(loadBalancerClientFactory
    //            .getLazyProvider(name, ServiceInstanceListSupplier.class),
    //            name);
    //}

    @Bean
    ReactorLoadBalancer&lt;ServiceInstance&gt; randomLoadBalancer(Environment environment,
                                                            LoadBalancerClientFactory loadBalancerClientFactory) {
        String name = environment.getProperty(LoadBalancerClientFactory.PROPERTY_NAME);
        return new MyRRLoadBalancer(name,loadBalancerClientFactory
                .getLazyProvider(name, ServiceInstanceListSupplier.class)
                );
    }
}
<br><br>Ribbon是NetFlix发布的客户端负载均衡器，主要是用来控制HTTP和TCP客户端的行为。为Ribbon配置了服务提供者的地址列表后，Ribbon就可以基于某种负载均衡算法，自动地帮助服务消费者去请求对应的服务实例。Ribbon提供很多的负载均衡策略：轮询，随机，最少使用等。<br>Nginx和Ribbon的区别：<br>Nginx：是集中式的负载均衡设备（软件），Ribbon是进程内的负载均衡器，只是一个类库，集成在消费方的进程当中，消费方通过它来获取服务提供者的位置。<br>Nignx是服务器端负载均衡器，客户端的请求都是交给Nginx，然后由Nginx进行转发。<br>Ribbon：在调用微服务接口的时候，会在注册中心上获取注册的服务列表，缓存到本地。<br><br>@Configuration
public class AppConfig {

    @Bean
    public IRule iRule(){
        return new RandomRule();
    }
}

<br><br>RoundRobinRule：轮询，尝试超过10次以后，直接不提供服务。<br>RandomRule: 随机策略<br>Retry：先按照轮询的策略获取服务，如果服务失败，则在指定的时间内进行重试，获取可用的服务<br>WeightedResponseTimeRule：是对轮询策略的扩展，每30秒钟计算一次服务器的响应时间，以响应时间作为权重，响应时间越短，响应速度越快的服务器被选中的概率越大。<br>BestAvailableRule：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，在可用列表中选择一个并发量最小的服务实例。<br>AvailabilityFilteringRule：：先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，再选择一个相对并发量较小的实例。<br>ZoneAvoidanceRule：根据服务提供者实例的所在区域以及响应的可用性选择服务器。<br><br>需求：使用轮询方式访问服务器，每个服务器访问三次之后换下一个服务器<br>需要两个属性：1）用来记录当前的服务器被调用了几次 <br>​						 2）记录当前服务器是第几台服务器<br>如果当前的服务器已经被调用三次，换下一台服务器（i ）<br><br>public class CustomizeRule extends AbstractLoadBalancerRule {
    //当前服务器索引的访问次数
    private  int total=0;
    //当前的服务器索引
    private  int currentIndex = 0;
    @Override
    public void initWithNiwsConfig(IClientConfig iClientConfig) {

    }

    @Override
    public Server choose(Object o) {
        return choose(getLoadBalancer(),o);
    }

    public Server choose(ILoadBalancer lb,Object key) {
        if(lb == null) {
            return null;
        }
        Server server = null;
        //隐形风险：如果一直找不到可用的服务器实例，导致死循环
        while (server==null){
            //获取可用的服务器列表
            List&lt;Server&gt; reachableServers = lb.getReachableServers();
            //获取所有的服务器列表
            List&lt;Server&gt; allServers = lb.getAllServers();
            int upCount = reachableServers.size();
            int serverCount = allServers.size();
            //没有可用的服务器实例，直接返回
            if (upCount==0) {
                return null;
            }
            if(total &lt; 3) {
                server=reachableServers.get(currentIndex);
                if (server==null) {
                    Thread.yield();
                    continue;
                }
                total++;
            } else {
                currentIndex = (currentIndex + 1) % upCount;
                //currentIndex++;
                //if (currentIndex== upCount) {
                //    currentIndex=0;
                //}
                server = reachableServers.get(currentIndex);
                if (server==null) {
                    Thread.yield();
                    continue;
                }
                total =1;
            }


        }
        return server;
    }
}
<br><br>@Configuration
public class AppConfig {

    @Bean
    public IRule iRule(){
        //return new RandomRule();
        return new CustomizeRule();
    }
}
<br><br>OpenFeign是NetFlix开发的声明式、模板化的HTTP客户端，用于HTTP请求调用的轻量级的框架，以Java接口注解的方式调用HTTP请求。OpenFeign支持SpringMVC注解，可以和Eureka整合一起使用<br>使用步骤<br>导入依赖<br>在消费者端编写Openfeign的客户端（接口）<br><br>增加以下依赖<br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>使用@FeignClient注解<br>@Service
//name指定要调用的服务名
@FeignClient(name="bookapp")
public interface UserServiceFeign {

    @RequestMapping(value = "book/{isbn}")
    Book findByIsbn(@PathVariable("isbn") String isbn);
}

<br><br>@RestController
public class UserController {


    @Resource
    UserServiceFeign userServiceFeign;

    @GetMapping("borrow/{isbn}")
    public Book searchBook(@PathVariable("isbn") String isbn) {
        return userServiceFeign.findByIsbn(isbn);
    }


}
<br><br>增加@EnableFeignClients注解<br>@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>fallback和fallbackFactory，主要用于熔断机制，调用失败时，走的回退方法，可以用来抛出异常或者给出默认的数据。<br>decode404:配置响应状态为404时，是否抛出FeignException<br><br>OpenFeign基于JDK的动态代理。<br>@EnableFeignClients：加上该注解，Springboot启动的时候，会导入FeignClientsRegistrar，扫描所有带有@FeignClient注解的接口<br>解析到@FeignClient的配置属性后，扩展Spring Bean Definition的注册逻辑上面，最终注册一个FeignClientFactoryBean，此对象会产生一个代理类对象。<br><br>可以参考在FeignClientProperties中的数据，主要是其内部类FeignClientConfiguration<br>feign:
  client:
    config:
      GOODS:  #指定服务
        connectTimeout: 1000
        readTimeout: 1000
<br><br><br>在微服务的架构当中，原本一个大的服务会拆分成多个小服务单元，服务单元之间无法避免会有相互的依赖关系。由于这种依赖关系，当某一个服务单元出现故障，容易引起故障的蔓延，最终有可能导致整个系统的瘫痪。<br>雪崩效应：当某一个服务单元出现故障，容易引起故障的蔓延，顺着调用链向上传递，最终有可能导致整个系统的瘫痪的现象。<br>产生场景<br>硬件故障：服务器宕机，机房断电，光纤被挖断...<br>流量激增：异常流量激增<br>缓存问题：由于缓存的问题，导致服务提供者的负荷增加了，引起服务的不可用。<br>程序BUG:  程序逻辑错误导致内存泄漏，JVM长时间进行FullGC。<br>同步等待：服务间采用同步调用机制，同步等待导致资源的耗尽。<br>Hystrix的目标：在于通过控制哪些远程访问、服务以及第三方的节点，从而对延迟或者故障提供更强大的容错能力。<br><br>NetFlix公司开源的，用于分布式系统的延迟和容错处理的开源库。用于隔离远程访问、服务以及第三方的库，防止级联失败，从而提升系统的可用性以及容错性。<br>CAP:
C: 一致性。分布式集群中节点（broker）上的数据要保持一致。<br>   A：可用性，要求服务端能够在指定的时间快速响应用户。<br>   P:  分区容错性，当集群或者分布式系统中的某一个节点（服务）出现问题后，整个集群或分布式系统的使用不能收到影响。<br>要么是CP，要么AP<br>服务降级： 假设系统比较忙或者不可用的情况下，给一个友好提示或者默认处理。触发降级的场合：程序运行异常、超时、服务熔断触发服务降级，线程池当中并发量达到阈值也可能导致服务降级。<br>服务熔断：达到最大服务访问量以后，直接拒绝访问，然后调用服务降级的方法给出友好提示。<br>服务限流：秒杀，抢红包等一系列高并发操作，严控一窝蜂的过来拥挤，让大家排队有序进行。<br><br>依赖<br>&lt;dependency&gt;
      &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
      &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;
 &lt;/dependency&gt;
<br>service中的方法<br>降级方法的参数和返回值要和原来方法一致<br>@Service
public class UserService {

    //服务提供者的服务URL
    //String host = "http://localhost:8080";
    //用服务名替换具体的服务器的URL
    String host = "http://BOOKAPP";

    @Resource
    RestTemplate restTemplate;

    @HystrixCommand(fallbackMethod = "fallback")
    public Book searchBook(String isbn){
        System.out.println("用户查找图书");
        String url = host + "/book/" + isbn;
        Book book = restTemplate.getForObject(url, Book.class);
        return book;
    }

    public String getServer(){
        String url = host + "/server";
        String server = restTemplate.getForObject(url, String.class);
        return server;
    }

    public Book fallback(String isbn){
        return new Book("XXXX","服务器出现异常","",0.0);
    }


}
<br>启动类<br>增加@EnableHystrix或者@EnableCircuitBreaker注解<br>@SpringBootApplication
@EnableEurekaClient
@EnableFeignClients
@EnableHystrix  //启动Hystrix断路器
//@EnableCircuitBreaker   //启用容错保护组件（）
public class Base01ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base01ConsumerApplication.class, args);
    }

    @Bean
    @LoadBalanced  //启用ribbon的负载均衡
    public RestTemplate restTemplate(){
        return new RestTemplate();
    }

}
<br><br>在Service类上使用@DefaultProperties注解，指定默认的服务降级的方法。<br>全局降级的方法，不能带有参数。<br>需要降级处理的方法上，不指定降级目标方法（回退方法），但是@HystrixCommand注解需要保留<br><br><a data-tooltip-position="top" aria-label="https://blog.csdn.net/2301_79354153/article/details/134642873" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/2301_79354153/article/details/134642873" target="_blank">OpenFeign设置Hystrix详解</a><br><br>feign:
  httpclient:
    connection-timeout: 2000  #连接服务端的时间 + 实际读取的时间
  hystrix:
    enabled: true #开启容错保护组件
<br><br>使用@FeignClient的fallback属性，设置成指定的类<br>处理降级的类，需要实现对应的接口<br>@Component
public class UserServiceFeignException implements UserServiceFeign {
    @Override
    public Book findByIsbn(String isbn) {
        return new Book("110","我是服务器，现在挂机中","",0.0);
    }
}
<br><br>使用@FeignClient的fallbackFactory属性，设置成指定的类<br>处理降级的类，实现FallbackFactory接口<br>@Component
public class UserServiceFeignFactory implements FallbackFactory&lt;UserServiceFeign&gt; {
    @Override
    public UserServiceFeign create(Throwable throwable) {
        return new UserServiceFeign() {
            @Override
            public Book findByIsbn(String isbn) {
                return new Book("666","光纤被挖断了","",0.0);
            }
        };
    }
}
<br><br>HystrixCommandProperties：普通参数
HystrixThreadPoolProperties：和线程池相关参数<br><br><br>创建一个web项目，要把web依赖去掉，增加hystrix-dashboard的依赖<br>配置项目增加hystrix.dashboard.proxy-stream-allow-list=*<br>在主启动类上要增@EnableHystrixDash注解<br>配置HystrixMetricsStreamServlet （可以使用配置文件，也可以在启动类当中注册）<br><br>增加两个依赖<br>hystrix-dashboard<br>actuator依赖<br>配置项目<br>management:
  endpoints:
    web:
      exposure:
        include: hystrix.stream
<br>启动项目测试<br>启动dashboard，输入localhost:端口号/hystrix<br>启动被监控项目，在前面的页面窗口，输入  localhost:被监控项目端口号/actuator/hystrix.stream<br><br><br>增加springboot-aop以及actuator依赖<br>&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-circuitbreaker-resilience4j&lt;/artifactId&gt;
&lt;/dependency&gt;
<br><br>可用的配置项目：CircuitBreakerConfig当中，可以去参考<br><br><br>Gateway 是 Spring Clo·1111ud 的子项目，Spring2.X 提供的，Spring1.X 用的是 zuul（已经停更，进入维护期），提供简单有效的 API 路由管理方式。<br>Gateway作为zuul的替代品，是Springcloud生态中的网管。是基于WebFlux，高效能的Reactor模式。<br>Gateway的特点：<br>​	支持动态路由：能够匹配路由的任何请求属性<br>​	集成Spring Cloud的服务发现功能<br>​	支持限流功能<br>​	支持路径重写<br>​	提供断言（Predicate）以及过滤器（Filter），可以设置路由的一些条件<br><br>服务网关：路由转发 + 过滤器<br>路由转发：接收客户端的请求，将请求转发到指定的微服务上。<br>过滤器：可以帮助网关实现一些类似于AOP可以完成的一些操作，认证，服务的监控，限流。<br>案例： 有四个微服务，每个微服务都需要权限的认证<br>​          方案一：每个微服务都实现一下权限认证的代码===&gt;基本不会使用<br>​           方案二：将认证服务写成一个公共的服务，每个业务相关的微服务都来调用公共的服务。<br>​            方案三：将认证服务写到网关的过滤器<br><br>路由（Route）：路由是构建网关的基本模块。它由ID,目标URI,一系列的断言和过滤器组成。<br>断言（Predicate）：开发人员可以通过断言的相关设置，匹配HTTP请求中的参数内容，设置访问路由的条件<br>过滤器（Filter）：通过过滤器，可以在路由前后进行一些修改<br><br>创建一个springcloud项目<br>增加网关依赖，eureka客户端<br>配置相应的网关<br><br>spring:
  application:
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/**
      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
server:
  port: 10000
  #作为eureka的客户端的配置
eureka:
  client:
    service-url:
      defaultZone: http://localhost:7100/eureka
    register-with-eureka: true
    fetch-registry: true
<br><br>断言（Predicates）是一组匹配规则，请求只有和规则相匹配时才可以访问<br>-Path : 匹配路径<br>-After ：  - After=时间 （在某个时间之后可以访问）由于是ZoneDateTime， 时间需要带有时区<br>​		 - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]<br>
<br>Before： - Before=时间 （在某个时间之前可以访问）
<br>-Between: - Before=时间1, 时间2<br>-Cookie,   -Cookie=phone,15911111111  phone为key，15911111111  <br>-Header： 表示请求头当中，需要包含某些内容，请求才可以访问<br>​	-Header=authenticator, 1111<br>-Method: 匹配请求方式，如 -Method=POST,GET<br>-Query：匹配请求的参数   -Query=price,\d+  : 请求当中需要携带price参数，且值必须数字才可以访问<br><br>Spring cloud通过过滤器在请求的前后进行一部分分更新<br>抽象类AbstractGatewayFilterFactory的子类对象，配置的时候，去掉GatewayFilterFactory后缀<br><br>yaml<br>(x)spring:
  application:
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/book/**  #限制访问的路径
            - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]
          filters:
            - AddRequestHeader=username,xiaoming
            - RedirectTo=302,http://www.baidu.com

      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
全局过滤器的顺序
OrderedFilter
<br><br><br>实现GlobalFilter接口，对所有的路由均有效。<br>@Component
public class MyGlobalFilter implements GlobalFilter {

    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        //要求访问网关时，必须带有user参数，如果为null，则不放行，拒绝，不为null，则放行
        String user = exchange.getRequest().getQueryParams().getFirst("user");
        if (user == null) {
            System.out.println("===用户参数user没有设置");
            exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);
            exchange.getResponse().setComplete();  //设置拒绝
        }
        return chain.filter(exchange);  //放行
    }
}
<br><br>实现AbstractGatewayFilterFactory，要以GatewayFilterFactory作为类的后缀名<br>在指定路由的filters下定义对应的过滤器即可。<br>//定义过滤器
@Component
public class MyTestGatewayFilterFactory extends AbstractGatewayFilterFactory {
    @Override
    public GatewayFilter apply(Object config) {

        return new GatewayFilter() {
            @Override
            public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
                System.out.println("=========局部过滤器=====================");
                return chain.filter(exchange);
            }
        };
    }
}
<br>配置过滤器<br>spring:
  application:	
    name: base03-gateway
  cloud:
    gateway:
      routes:
        - id: gt-bookapp  #id值需要位置
#          uri: http://localhost:8070
          uri: lb://bookapp  #lb为固定值，表示负载均衡，bookapp为服务名
          predicates:
            - Path=/book/**  #限制访问的路径
            - After=2021-11-24T11:35:57.557+08:00[Asia/Shanghai]
          filters:
            - MyTest
            #- AddRequestHeader=username,xiaoming
            #- RedirectTo=302,http://www.baidu.com

      discovery:
        locator:
          enabled: true #开启从注册中心动态创建路由的功能，利用微服务名进行路由
<br><br>Naming Configuration Service： 注册中心 + 配置中心 + 配置总线的组合组件<br>中文官网：<a rel="noopener nofollow" class="external-link" href="https://nacos.io/zh-cn/index.html" target="_blank">https://nacos.io/zh-cn/index.html</a><br>英文spring： spring.io<br>下载：<a rel="noopener nofollow" class="external-link" href="https://github.com/alibaba/nacos" target="_blank">https://github.com/alibaba/nacos</a><br>使用nacos，不需要单独在编写一个nacos服务器端，已经提供。nacos是基于java代码实现。阿里出品。<br><br>增加依赖<br>配置<br>在主启动类增加@EnableDiscoveryClient注解<br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
            &lt;version&gt;2021.0.4.0&lt;/version&gt;
        &lt;/dependency&gt;
		
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
            &lt;version&gt;2021.0.4.0&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- springcloud 2020.x只用去掉了bootstrap，需要重新加上 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-starter-bootstrap&lt;/artifactId&gt;
            &lt;version&gt;3.0.3&lt;/version&gt;
        &lt;/dependency&gt;
<br><br>bootstrap.yml ：会在application.yml读取之前先读，其中的内容是不会被覆盖<br><br>在nacos配置中心设置配置文件时，文件的dataId由三个部分组成，prefix，profile（dev，test，prod），file-extension（yaml或者properties，根据选择的文件类型来决定）<br>​	prefix-profile.file-extension<br>prefix: 默认为spring.application.name的值(例：项目：nacos-config)，也可以通过配置项spring.cloud.nacos.config.prefix<br>profile: spring.profiles.active对应的环境，如果没有设置多环境，则文件名  prefix.file-extension<br>file-extension: 目前只支持properties和yaml<br>namespace：项目隔离的作用<br><br>Sentinel是alibaba提供的用于实时监控、流量控制、异常熔断等管理工具，它可以于nacos进行组合使用，可以对项目进行图形化的配置和管理。<br>运行启动sentinel，可以通过--server.port指定端口号<br>java -jar sentinel-dashboard-1.8.2.jar --server.port=8081
<br><br><br><img style="zoom:80%;" alt="流控规则" src="\流控规则.png" referrerpolicy="no-referrer"><br><img alt="流控规则.png" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/%E6%B5%81%E6%8E%A7%E8%A7%84%E5%88%99.png" referrerpolicy="no-referrer"><br>资源名：唯一名称，默认为请求路径<br>针对来源：sentinel可以针对调用者进行限流，不填写则默认为default，对所有来源的总和进行限流，如果设置的话，则设置调用者的服务名。<br>QPS: 每秒钟请求的数量，当每秒钟的请求数量达到阈值的时候，进行限流处理。<br>并发线程数：调用资源的并发线程量达到阈值，进行限流<br>单机阈值/集群阈值/均摊阈值：单机的情况下设置单机阈值，集群的情况可以选择集群阈值或者均摊阈值<br>流控模式：<br>​	直接：达到阈值的时候，进行直接限流（快速失败，warm up，链路）<br>​	关联：当关联的资源达到阈值，就限流我自己。<br>​	链路：当达到阈值的时候，限制某个入口对应链路上的处理（限流）<br>流控效果：<br>​	直接失败：服务降级，提示服务限流的消息<br>​	warm up： 有一个冷加载因子（默认是3），经过预热时常后，达到QPS<br>	@GetMapping("test") // /test
    //@SentinelResource(value = "test",fallback = "fallbackMethod")
    @SentinelResource(value = "test",fallback = "fallbackMethod"
            ,fallbackClass = InfoFallBackComponent.class)
    public String test(){
        System.out.println("test: "  + LocalDateTime.now());
        return "game over";
    }

    //public String fallbackMethod(Throwable e){
    //    return "方法被限流";
    //}
<br><br>Sentinel熔断降级主要是适用某个资源请求处理不稳定的情况下，对此资源进行调用限制。<br>不稳定的因素：调用时间比较常，异常出现的频率高<br><img style="zoom:80%;" alt="熔断规则" src="\熔断规则.png" referrerpolicy="no-referrer"><br>统计1秒种（1000ms）时间内，如果请求的次数达到2次以上（最小请求数），慢调用（请求的时间超过100猫喵）的比例，达到0.5的情况，就会熔断20秒。<br><br>调用后端接口的参数，根据方法上来，0为第一个参数，1为第二个参数。<br>资源名：可以是请求的url，也可以是@SentinelResource的value值。<br>blockHandler对应的方法，除了参数以及返回值之外，还需要增加一个BlockException参数<br>sentinel和openfeign进行整合，如何进行服务降级处理。<br>@GetMapping("/testHotkey")
    @SentinelResource(value = "/testHotkey",blockHandler = "blockHandler")
    public String testHotKey(String p1,String p2) {
        return "success";
    }
    public String blockHandler(String p1, String p2, BlockException ex) {
        return "blockHandler";
    }
]]></description><link>教程\spring cloud.html</link><guid isPermaLink="false">教程/spring cloud.md</guid><pubDate>Fri, 01 Mar 2024 03:27:11 GMT</pubDate><enclosure url="\流控规则.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\流控规则.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Springboot基础]]></title><description><![CDATA[ 
 <br><br><br>Springboot是Spring家族的一部分。<br>随着功能的复杂度增加，Spring的配置也会变得越来越复杂，配置带来的烦恼越来越来。Springboot伴随着配置的烦恼就出现，主要使得编码更加简单，配置也简单，还提供监控以及相关部署的辅助功能。Springboot的出现主要是为了解决Spring新项目的搭建和开发过程，使用特定的约定方式来进行配置，从而使开发人员不再需要定义模板化的配置，不再需要配置web.xml, SpringMVC.xml以及application.xml。<br>Springboot是基于Spring进行开发的，简化了Spring的配置和开发过程，通过集成大量的框架，减少依赖包之间的冲突，可以减少引用的不稳定而引起的问题。<br><br>1：可以创建独立的Spring程序，并且是基于Maven和Gradle<br>2：内嵌Servlet容器（tomcat，jetty以及undertow），可以不依赖容器直接运行<br>3：提供可以自动配置的starter项目模型（POM），可以避免各种maven导入依赖包的冲入。<br>4：尽可能地自动配置Spring容器，采用“约定优先于配置”的策略，在指定的结构中添加相关的设计内容。<br>5：基本不用xml文件，web项目也不需要配置web.xml<br>6：提供了一些辅助功能，比如指标，健康检查等<br><br>Spring项目（能用spring的地方就能用springboot）<br>J2EE/web项目<br>微服务<br><br>Springboot可以认为是Spring以及SpringMVC的合体升级版。可以不学习springMVC直接学习springboot。<br>Springboot简化架构的依赖和配置过程，但是在web开发成面，仍然沿用的是SpringMVC的开发方式，SpringMVC当中最重要组件就是Controller，Springboot的web开发依旧是以Controller为重点。<br><br><br><a rel="noopener nofollow" class="external-link" href="https://start.spring.io/" target="_blank">https://start.spring.io/</a><br><img alt="官网方式配置" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240220164528686.png" referrerpolicy="no-referrer"><br><br><br><br><br>集成spring-boot-dependencies，定义了依赖的版本号，解决maven（gradle）的版本冲突问题<br>定义了Java的版本号<br>定义字符编码为UTF-8<br>定义打包操作的位置<br>定义资源过滤<br>定义自动化插件<br><br><br>default: <a rel="noopener nofollow" class="external-link" href="https://start.spring.io" target="_blank">https://start.spring.io</a><br>aliyun:   <a rel="noopener nofollow" class="external-link" href="https://start.aliyun.com" target="_blank">https://start.aliyun.com</a><br><br><br><br>需要确认maven的环境变量<br>进入项目目录，运行下述命令<br>mvn spring-boot:run
<br><br>无论是web还是非web项目，都可以打成jar包运行<br>在控制台<br>进入项目目录<br>使用mvn package 进行打包<br>使用cd target 进入target目录<br>使用java命令执行jar<br>cd  项目目录
mvn package
cd target
java  -jar  xxx.jar
<br><br><br>YAML:不是一种标记语言，用来表现数据的。扩展名: yaml或者yml<br>springboot中常见的配置文件就是yaml和propertis.<br><br>key:空格value，表示一个键值对<br>以缩进控制层级关系，缩进只能使用空白符，不能使用tab，同一个层次左边对齐。<br><br>字面量：单个不能再拆分的值（字符串，数字，布尔）<br>​	字符串：默认情况下既不需要使用单引号，也不需要使用双引号，如果有特殊的转义字符，需要使用单引号或者双引号<br>​	双引号：包含的转义字符有效"abc\ndef"，输出的时候，abc和def是在两行上显示<br>​	单引号：包含的转义字符无效，按照原有字符输出，‘abc\ndef’ 输出‘abc\ndef’<br>数组和list<br>​	单行配置方式： names:[zhangsan,lisi,wangwu]<br>​	多行配置方式：使用中横线表示数组的元素<br>menu:
	children:
		- menu1
		- menu2
<br>对象和map<br>​	单行配置方式： clsInfo: {name: java173, id: 100}<br>​	多行配置方式：<br>​		以缩进的形式来表现<br>​		clsInfo:<br>​				name:  java173<br>​				id: 100<br><br>student:
  name: zhangsan
  sex: 男
  prof: "计算机工程系\n 软件工程专业"
  finished: false
  subjects: [java,web,c,'c#']
  scores:
    - 90
    - 80
    - 100
  teacher: {id: 1003, name: 张恨水}
  girlfriend:
    name: 张宇
    age: 18
<br><br><br>使用在读取单个，简单数据类型的数据<br>@Data
@Component
public class Student {

    @Value("${student.name}")
    private String name;
    @Value("${student.sex}")
    private String sex;
}
<br><br>主要用于简单数据类型数据的获取<br>@Component
@Data
public class SeniorStudent {
    private String name;
    private String prof;
    @Resource
    private Environment environment;

    public void setBeanProperties(){
        this.name = environment.getProperty("name");
        this.prof=environment.getProperty("prof");
        System.out.println(environment.getProperty("student.name"));
        System.out.println(environment.getProperty("student.prof"));
    }
}
<br><br><br>@Data
@Component
//prefix:只能使用中横线 以及 小写字母（数字）
//不能使用大写字母i
@ConfigurationProperties(prefix = "student")
public class CollegeStudent {
    String name;
    String sex;
    boolean finished;
    String prof;
    String[] subjects;
    List&lt;Integer&gt; scores;
    Teacher teacher;
    GirlFriend girlfriend;
}
<br><br>Relaxed Binding: 松散绑定，绑定的属性不严格要求和配置文件当中一致。<br>@ConfigurationProperties的prefix（value）只能使用中横线和小写字母（数字），中横线不能是开头<br>配置文件则可以是大写字母，小写字母，中横线，下划线或者空格<br>配置<br>tomcatServer:
  host-name: localhost
  host_ip: 192.168.66.211
  HOST_PORT: 8090
  "HOST DESC": tomcat server descript
<br>绑定<br>@Data
@Component
@ConfigurationProperties(prefix = "tomcat-server")
public class TomcatServer {
    private String hostName;
    private String hostIp;
    private int hostPort;
    private String hostDesc;
}

<br><br>读取非application.properties的属性文件的数据。<br>Springboot提供@PropertySource和@PropertySources注解，用来读取此类配置文件当中的数据<br><br>在resources目录下增加一个jdbc.properties文件<br>db.driver=com.mysql.cj.jdbc.Driver
db.url=jdbc:mysql://localhost:3306/sb
db.username=root
db.password=1111
<br><br>@Data
@Component
@ConfigurationProperties(value = "db")
//@PropertySource(value = "classpath:jdbc.properties",encoding = "utf-8")
@PropertySources(@PropertySource(value = "classpath:jdbc.properties",encoding = "utf-8"))
public class DBServer {
    String driver;
    String url;
    String username;
    String password;
}
<br><br>此注解的作用：用来导入Spring原生的xml配置文件。此注解只能放在主启动类上。<br>一般用在spring项目到springboot的移植上面。<br>@SpringBootApplication
@ImportResource(locations = "classpath:bean.xml")
public class Base01ConfigApplication {

    public static void main(String[] args) {
        ApplicationContext ctx = SpringApplication.run(Base01ConfigApplication.class, args);
        //Student bean = ctx.getBean(Student.class);
        //System.out.println(bean);

        //SeniorStudent seniorStudent = ctx.getBean(SeniorStudent.class);
        //System.out.println(seniorStudent);
        //seniorStudent.setBeanProperties();

        CollegeStudent student = ctx.getBean(CollegeStudent.class);
        System.out.println(student);

        TomcatServer tomcatServer = ctx.getBean(TomcatServer.class);
        System.out.println(tomcatServer);

        DBServer dbServer = ctx.getBean(DBServer.class);
        System.out.println(dbServer);

        SpringBean bean = ctx.getBean(SpringBean.class);
        System.out.println(bean);

    }

}
<br><br><br>Springboot当中默认的静态资源位置可以如下几个：<br>classpath:/META-INF/resources/<br>classpath: /resources/<br>classpath:/static/<br>classpath:/public/<br>可以在配置文件当中使用spring.web.resource.static-locations来进行配置，指定特殊的位置<br>spring:
  web:
    resources:
      static-locations: classpath:/templates/
<br><br>对于JQuery这类的资源，已经有人帮我们打好jar包，可以直接利用<br>使用：引入依赖，和普通js一样使用script标签引入<br><br>&lt;dependency&gt;
    &lt;groupId&gt;org.webjars&lt;/groupId&gt;
    &lt;artifactId&gt;jquery&lt;/artifactId&gt;
    &lt;version&gt;3.6.4&lt;/version&gt;
&lt;/dependency&gt;
<br><br>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;Title&lt;/title&gt;
    &lt;script src="webjars/jquery/3.6.4/jquery.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;button id="testJquery"&gt;test&lt;/button&gt;
    &lt;script&gt;
        $(function () {
            $("#testJquery").click(()=&gt;{
                alert("jquery有效")
            })
        })
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
<br><br><br>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;Title&lt;/title&gt;
    &lt;script src="webjars/jquery/3.6.4/jquery.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;button id="testJquery"&gt;test&lt;/button&gt;
    &lt;script&gt;
        $(function () {
            $("#testJquery").click(()=&gt;{
                $.ajax({
                    url:'testAjax',
                    type:'get',
                    success: function (data) {
                        console.log(data)
                    }
                })
            })
        })
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
<br><br>@RestController
public class AjaxController {

    @GetMapping("testAjax")
    public Map&lt;String,String&gt; doTest(){
        Map&lt;String, String&gt; map = new HashMap&lt;&gt;();
        map.put("name","xiaoming");
        map.put("age","13");
        return map;
    }

}
<br><br>在Spring当中如果进行文件上传的话，需要增加commons-fileupload依赖，同时配置multipartResolver<br>在Springboot当中进行文件上传，不需要程序员手动增加commons-fileupload，而是由springboot自动装配了，我们只需要设置multipartResolver（默认时1MB，大部分情况下都需要修改）<br><br>spring:
  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 50MB
      location: d:/temp
app:
  upload:
    direct: d:/upload
     
<br><br>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;Title&lt;/title&gt;
    &lt;script src="webjars/jquery/3.6.4/jquery.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;input type="file" id="file01"&gt;
    &lt;button id="upload"&gt;upload&lt;/button&gt;
    &lt;script&gt;
        $(function () {
            $("#upload").click(()=&gt;{
                //
                var form = $("&lt;form&gt;&lt;/form&gt;")[0];
                var formData = new FormData(form);
                formData.append("file",$("#file01")[0].files[0])
                $.ajax({
                    url:'upload',
                    type:'post',
                    data: formData,
                    async:false,
                    cache: false,
                    processData: false,
                    contentType: false,
                    success(data){
                        alert(data);
                    }
                })
            })
        })
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
<br><br>@RestController
public class UploadController {

    @Value("${app.upload.direct}")
    String dir;

    @PostMapping("upload")
    public String doUpload(MultipartFile file) throws IOException {
        //判断上传的目录是否存在，如果不存在，则创建
        File destDirFile = new File(dir);
        if (!destDirFile.exists()) {
            destDirFile.mkdirs();
        }
        //上传文件
        File destFile = new File(dir,file.getOriginalFilename());
        file.transferTo(destFile);
        return "文件上传成功";
    }
}

<br><br>Springboot当中，配置Servlet对象，可有两种方式：<br>1：在配置类当中，使用ServletRegistrationBean，更使用第三方提供的Servlet组件<br>2：使用@WebServlet + @ServletComponentScan注解。@ServletComponentScan必须放在主启动类上，指定其basePackage属性，如果servlet的package是主启动类所在的package或者其子package，则可以省略此属性。<br><br><br>public class SchoolServlet extends HttpServlet {

    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().write("&lt;html&gt;&lt;body&gt; &lt;h3&gt;school title&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;");
        resp.getWriter().close();
    }
}

<br><br>@Configuration
public class ServletConfig {

    @Bean
    public ServletRegistrationBean registrationBean(){
        ServletRegistrationBean&lt;SchoolServlet&gt; bean = new ServletRegistrationBean();
        bean.setName("schoolServlet");
        bean.setServlet(new SchoolServlet());
        bean.addUrlMappings("/school");
        return bean;
    }
}
<br><br><br>@WebServlet("/student")
public class StudentServlet extends HttpServlet {
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        resp.getWriter().write("student java178");
        resp.getWriter().close();
    }
}
<br><br>添加@ServletComponentScan注解<br>@SpringBootApplication
@ServletComponentScan
public class Base02WebApplication {

    public static void main(String[] args) {
        SpringApplication.run(Base02WebApplication.class, args);
    }

}
<br><br>Springboot也可能用Filter。创建Filter依旧是实现javax.servlet.Filter接口，并将过滤器注册到容器当中。<br>1：使用@WebFilter + @ServletComponentScan注解<br>2：使用FilterRegistrationBean方式来配置<br><br>//@WebFilter("/*")
public class CharacterFilter implements Filter {
    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {

        System.out.println("过滤器执行");
        servletRequest.setCharacterEncoding("UTF-8");
        servletResponse.setCharacterEncoding("UTF-8");
        filterChain.doFilter(servletRequest,servletResponse);
    }
}
<br><br>@Configuration
public class FilterConfig {

    @Bean
    public FilterRegistrationBean filterRegistrationBean(){
        FilterRegistrationBean bean = new FilterRegistrationBean();
        bean.setName("characterFilter");
        bean.setFilter(new CharacterFilter());
        bean.addUrlPatterns("/*");
        //bean.setOrder(2);
        return bean;
    }
}

<br><br>定义实现HandlerInterceptor接口，注册使用接口 WebMvcConfigurer<br>@Configuration
public class WebConfig implements WebMvcConfigurer {

    //user/m1, user/m2,user/m3
    //拦截user下面除了m3之外的所有的请求
    //@Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new MessageInterceptor())
                .addPathPatterns("/user/**")
                .excludePathPatterns("/user/m3");
    }


}
<br><br>1：在指定的控制器上增加@CrossOrigin注解<br>2：使用CorsFilter过滤器<br>3：使用WebMvcConfigurer接口，实现addCorsMappings。此种方式，如果项目当中有拦截器，有可能导致冲突，跨域无效。<br><br> @Bean
    public CorsFilter corsFilter(){
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
        CorsConfiguration config = new CorsConfiguration();
        config.addAllowedMethod("*");
        config.addExposedHeader("*");
        config.addAllowedOriginPattern("*");
        //是否允许设置Cookie信息
        config.setAllowCredentials(true);
        source.registerCorsConfiguration("/**",config);
        return new CorsFilter(source);
    }
<br><br>@Configuration
public class WebConfig implements WebMvcConfigurer {

    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping("/**")
                .allowedOriginPatterns("*")
                .allowedMethods("*")
                .allowedHeaders("*")
                .allowCredentials(true);
    }
}
<br><br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;2.3.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;
<br><br>配置数据库以及mybatis的相关特性<br>spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/school?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
mybatis:
  mapper-locations: classpath:mappers/*.xml
  type-aliases-package: net.wanho.base03mybatis.entity
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    map-underscore-to-camel-case: true
<br><br>在每一个mapper接口上使用@Mapper注解<br>在主启动类上增加@MapperScan(basePackage="")<br><br><br><br><br>默认的连接池：hikaripool，如果需要调整成druid，需要添加相关依赖以及配置<br>druid提供了一个管理界面，可以查看连接池的运行状况。<br><br>&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.2.16&lt;/version&gt;
&lt;/dependency&gt;
<br><br>server:
  port: 8080
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/school?serverTimezone=Asia/Shanghai&amp;useSSL=false
    username: root
    password: root
    type: com.alibaba.druid.pool.DruidDataSource
    druid:
      max-active: 8
      min-idle: 2
      max-wait: 1000
      max-evictable-idle-time-millis: 2000000 #长连接时间（半个小时~7个小时之间） 
mybatis:
  mapper-locations: classpath:mappers/*.xml
  type-aliases-package: net.wanho.base03mybatis.entity
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    map-underscore-to-camel-case: true
<br><br>@Configuration
public class AppConfig {

    @Bean
    public ServletRegistrationBean registrationBean(){
        ServletRegistrationBean bean = new ServletRegistrationBean();
        bean.setName("druid");
        bean.setServlet(new StatViewServlet());
        bean.addUrlMappings("/druid/*");
        bean.addInitParameter("loginUsername","admin");
        bean.addInitParameter("loginPassword","admin");
        //拒绝访问的IP
        bean.addInitParameter("deny","192.168.66.10");
        return bean;
    }
}
<br><br>Springboot的自动配置原理：基于SPI机制。Springboot的主启动类上包含一个注解@SpringbootApplication，此注解由三个功能性注解组成，@SpringbootConfiguration，@ComponentScan，@EnableAutoConfiguration。@SpringbootConfiguration标记主启动类也是配置类，@ComponentScan指定扫描包的位置，没有指定basepackage的情况下，其实就是使用此注解的类所在包以及子包。@EnableAutoConfiguration启用自动配置，利用SPI机制，确定哪些需要进行自动配置，并且根据指定的条件进行注入。<br><br><br>此注解主要是用来导入java的类，可以是本工程当中的类，也可以是第三方的类，并且创建其对象，放入容器当中<br>使用方式：<br>​	直接导入类<br>​	导入ImportSelector接口的实现类<br>​	导入ImportBeanDefinitionRegistrar接口的实现类<br>具体代码请参考Spring笔记<br><br>//@SpringBootConfiguration是springboot2.x出现的新注解，作用和springboot1.x的@Configuration注解是一样的，标记此注解的类是一个配置类
@SpringBootConfiguration
@EnableAutoConfiguration
//和spring当中的配置&lt;context conponent-scan basepackages=""/&gt;作用是相同。
//标记工程扫描的路径，不指定basepackages的情况下，则为标记此注解的类所在的package以及子package
@ComponentScan(
    excludeFilters = {@Filter(
    type = FilterType.CUSTOM,
    classes = {TypeExcludeFilter.class}
), @Filter(
    type = FilterType.CUSTOM,
    classes = {AutoConfigurationExcludeFilter.class}
)}
)
public @interface SpringBootApplication {
    @AliasFor(
        annotation = EnableAutoConfiguration.class
    )
    ...
   }
<br><br>//添加此注解的类所在的package以及子package作为自动配置的包进行扫描
//导入AutoConfigurationPackages.Registrar，读取@SpringbootApplication注解中的扫描路径，
// 如果没有配置，则默认当前类下
@AutoConfigurationPackage
//利用SPI机制，加载META-INF/spring.factories以及
// META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports
//当中的类
@Import({AutoConfigurationImportSelector.class})
public @interface EnableAutoConfiguration {
    String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration";

    Class&lt;?&gt;[] exclude() default {};

    String[] excludeName() default {};
}

<br>自动配置的条件<br>@ConditionalOnClass：当前的classpath下有指定的类才进行加载
@ConditionalOnMissingClass：当前的classpath下没有指定的类才进行加载
@ConditionalOnBean：当前的容器当中有指定的类的对象才进行加载
@ConditionalOnMissingBean：当前的容器当中没有指定的类的对象才进行加载
@ConditionalOnProperty：环境条件注解，配置文件中指定与此prefix相同的配置项时，才会进行加载
@ConditionalOnResource：当包含指定的资源文件时进行加载
@ConditionalOnWebApplication：当前的工程是web工程时进行加载
@ConditionalOnExpression：负荷指定的SPEL表达式才进行加载。
<br><br>SPI(Service Provider Interface),服务提供接口，是JDK内置的一种服务提供发现机制。SPI是一种动态替换发现机制，基于一种非常优秀的解耦思想。它是一种扩展机制，是JDK提供给“服务提供厂商”或者“插件开发者”使用的接口<br>简单来说：由服务的提供方定义一个接口规范，由不同的服务提供商进行实现。调用方能够通过某种机制来发现服务的提供方，并且有能力通过接口来调用服务。它强调的是服务的调用者对服务实现的一种规范（约束），服务的提供者根据这些约束来实现服务，可以被调用者发现。<br>应用案例：数据库驱动，Slf4j日志<br>案例：空调的遥控器能做的事情：空调型号，开关处理，调节温度，变更模式（制冷，制热、通风）<br><img alt="SPI机制" src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/SPI%E6%9C%BA%E5%88%B6.png" referrerpolicy="no-referrer"><br><br>1: 工程一，定义一个接口/抽象类<br>2：工程二，工程三<br>​	实现接口<br>​	实现方的META-INF/services目录下，创建一个接口的全限定名的名称的文件，内容是提供接口的实现类的全限定名<br>4：工程四：作为服务的调用方，使用java.util.ServiceLoader去动态加载具体的实现类到JVM当中<br><br>package net.wanho;

/**
 * @author 马美平
 * @Date 2023/5/23
 **/
public interface AirConditioner {

    /**
     * 获取空调类型
     * @return
     */
    String getType();

    /**
     * 开关处理
     */
    void turnOnOff();

    /**
     * 调节温度
     * @param temperature
     */
    void adjustTemperature(int temperature);

    /**
     * 改变模式
     * @param modeId
     */
    void changeMode(int modeId);
}

<br><br>增加接口工程airconditioner的依赖，并实现AirConditioner接口<br>/**
 * @author 马美平
 * @Date 2023/5/23
 **/
public class FloorAirConditioner implements AirConditioner {

    @Override
    public String getType() {
        return "柜式空调";
    }

    @Override
    public void turnOnOff() {
        System.out.println("柜式空调-开关处理");
    }

    @Override
    public void adjustTemperature(int temperature) {
        System.out.println("柜式空调-调节温度");
    }
    @Override
    public void changeMode(int modeId) {
        System.out.println("柜式空调-改变模式");
    }
}

<br><br>增加接口工程airconditioner的依赖，并实现AirConditioner接口<br>public class WallAirConditioner implements AirConditioner {
    @Override
    public String getType() {
        return "挂式空调";
    }

    @Override
    public void turnOnOff() {
        System.out.println("挂式空调-开关处理");
    }

    @Override
    public void adjustTemperature(int temperature) {
        System.out.println("挂式空调-调节温度");
    }

    @Override
    public void changeMode(int modeId) {
        System.out.println("挂式空调-调节模式");
    }
}

<br><br>添加工程airconditioner-wall和工程airconditioner-floor的依赖，利用ServiceLoader发现实现类<br>/**
 * @author 马美平
 * @Date 2023/5/23
 **/
public class AirSpi {
    public static void main(String[] args) {
        new AirSpi().turnOnOff("挂式空调");
    }

    public void turnOnOff(String type) {
        ServiceLoader&lt;AirConditioner&gt; load = ServiceLoader.load(AirConditioner.class);

        for(AirConditioner airConditioner: load) {
            System.out.println("检测到：" + airConditioner.getClass().getName());
            if (type.equals(airConditioner.getType())) {
                //调用指定类型的空调
                airConditioner.turnOnOff();
            }
        }
    }
}

<br><br>加载 META-INF/spring.factories以及META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports中配置的类，并且进行bean的配置<br><br>默认按照文件名进行顺序加载，如果想要修改加载顺序，则可以使用@AutoConfigureBefore或者@AutoConfigureAfter进行修改，还可以利用@AutoConfigureOrder指定加载顺序，数字越小，越被优先注入。<br>如果有依赖关系的，springboot会自动先配置被依赖的对象，然后再配置外层对象。<br><br>定义一个带有School类的starterr，在应用工程当中，如果没有school对象，则加载类，并创建对象加入到容器当中。<br>Spring官方starter都是spring-boot-starter-xx命名<br>第三方的框架（组件） xx-spring-boot-starter<br>groupid: net.wanho<br>artifactId: school-spring-boot-starter<br>创建工程<br>添加依赖<br> &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;
        &lt;/dependency&gt;
&lt;!--    编译时会自动创建相关的json和properties文件--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-autoconfigure-processor&lt;/artifactId&gt;
        &lt;/dependency&gt;
&lt;!--插件依赖要删除，不然会报错--&gt;
<br>自动配置类<br>@Configuration
@ConditionalOnMissingBean(School.class)
@EnableConfigurationProperties(SchoolProperties.class)
public class SchoolAutoConfiguration {
    @Resource
    SchoolProperties schoolProperties;
    @Bean
    public School school() {
        School school = new School();
        school.setAddress(schoolProperties.getAddress());
        school.setName(schoolProperties.getName());
        school.setDescription(schoolProperties.getDescription());
        System.out.println(school);
        return school;
    }
}
<br>定义school<br>@Data
public class School {
    String name;
    String address;
    String description;
}
<br>定义配置文件<br>@Component
@Data
@ConfigurationProperties(prefix = "wanho.school")
public class SchoolProperties {
    String name;
    String address;
    String description;
}
<br>定义spring.factories<br>org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
  net.wanho.config.SchoolAutoConfiguration
<br>使用maven的install安装到本地仓库<br>定义测试工程，引入依赖，自动创建对象<br>如何动态配置属性<br><br><br>配置redis的属性<br>配置RedisTemplate<br><br>有些特殊的业务，需要在项目启动之后立刻执行。<br><br>@Component
public class SpringUtils implements ApplicationListener&lt;ContextRefreshedEvent&gt; {

    @Resource
    DictTypeService dictTypeService;

    @Override
    public void onApplicationEvent(ContextRefreshedEvent event) {
        //防止重复调用
        if(event.getApplicationContext().getParent()==null) {
            dictTypeService.initDictCache();
        }

    }
}
<br><br>@Component
public class SpringCommandLineRunner implements CommandLineRunner {
    @Resource
    DictTypeService dictTypeService;

    @Override
    public void run(String... args) throws Exception {
        dictTypeService.initDictCache();
    }
}
<br><br>@Component
public class SpringApplicationRunner implements ApplicationRunner {

    @Resource
    DictTypeService dictTypeService;
    @Override
    public void run(ApplicationArguments args) throws Exception {
        dictTypeService.initDictCache();
    }
}
<br><br><br>&lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;
        &lt;/dependency&gt;
<br><br>compiler.automake.allow.when.app.running 打勾<br><img alt="image-20230525135359144" src=".\file:\\C:\\Users\mameiping\AppData\Roaming\Typora\typora-user-images\image-20230525135359144.png" referrerpolicy="no-referrer"><br>]]></description><link>教程\Springboot基础.html</link><guid isPermaLink="false">教程/Springboot基础.md</guid><pubDate>Wed, 30 Apr 2025 06:40:48 GMT</pubDate><enclosure url="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240220164528686.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://raw.githubusercontent.com/ydh1cnn6/pic/master/image-20240220164528686.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[什么是Vagrant]]></title><description><![CDATA[ 
 <br><br>Vagrant是一个工具，用于创建和部署虚拟化环境，它可以和VirtualBox以及vmware一起整合使用。<br>以VirtualBox为例，VirtualBox会开发一个创建虚拟机的接口，Vagrant会利用此接口来创建虚拟机，并且通过vagrant来管理、配置以及安装虚拟机。<br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://developer.hashicorp.com/vagrant/downloads" target="_blank">https://developer.hashicorp.com/vagrant/downloads</a><br><br>vagrant是没有图形界面的，安装后也没有桌面快捷方式。Vagrant安装程序，会将安装路径自动加入Path环境变量当中。可以命令行通过命令来操作vagrant。可以使用vagrant version来检查是否成功安装<br><br>虚拟机（Virtual Machine）指通过软件模拟的具有完整硬件<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD/10394740?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%B3%BB%E7%BB%9F%E5%8A%9F%E8%83%BD/10394740?fromModule=lemma_inlink" target="_blank">系统功能</a>的、运行在一个完全隔离环境中的完整<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7210959?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7210959?fromModule=lemma_inlink" target="_blank">计算机系统</a>。在实体计算机中能够完成的工作在虚拟机中都能够实现。在计算机中创建虚拟机时，需要将实体机的部分硬盘和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%86%85%E5%AD%98%E5%AE%B9%E9%87%8F/3361934?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%86%85%E5%AD%98%E5%AE%B9%E9%87%8F/3361934?fromModule=lemma_inlink" target="_blank">内存容量</a>作为虚拟机的硬盘和内存容量。每个虚拟机都有独立的<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/CMOS/428167?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/CMOS/428167?fromModule=lemma_inlink" target="_blank">CMOS</a>、硬盘和<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/192?fromModule=lemma_inlink" target="_blank">操作系统</a>，可以像使用实体机一样对虚拟机进行操作。<br>VirtualBox 是一款开源<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BD%AF%E4%BB%B6/9003764?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BD%AF%E4%BB%B6/9003764?fromModule=lemma_inlink" target="_blank">虚拟机软件</a>。VirtualBox 是由德国 <a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Innotek/4492496?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Innotek/4492496?fromModule=lemma_inlink" target="_blank">Innotek</a> 公司开发，由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Sun/69463?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Sun/69463?fromModule=lemma_inlink" target="_blank">Sun</a> Microsystems公司出品的软件，使用<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Qt/451743?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Qt/451743?fromModule=lemma_inlink" target="_blank">Qt</a>编写，在 Sun 被 <a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Oracle/301207?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Oracle/301207?fromModule=lemma_inlink" target="_blank">Oracle</a> 收购后正式更名成 Oracle VM VirtualBox。Innotek 以 GNU General Public License (<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/GPL/2357903?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/GPL/2357903?fromModule=lemma_inlink" target="_blank">GPL</a>) 释出 VirtualBox，并提供<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E4%BA%8C%E8%BF%9B%E5%88%B6/361457?fromModule=lemma_inlink" target="_blank">二进制</a>版本及 OSE 版本的代码。使用者可以在VirtualBox上安装并且执行<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/Solaris/3517?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/Solaris/3517?fromModule=lemma_inlink" target="_blank">Solaris</a>、Windows、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/DOS/32025?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/DOS/32025?fromModule=lemma_inlink" target="_blank">DOS</a>、Linux、<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/OS%2F2/1958699?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/OS%2F2/1958699?fromModule=lemma_inlink" target="_blank">OS/2</a> Warp、BSD等系统作为客户端操作系统。已由<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8/430115?fromModule=lemma_inlink" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E7%94%B2%E9%AA%A8%E6%96%87%E5%85%AC%E5%8F%B8/430115?fromModule=lemma_inlink" target="_blank">甲骨文公司</a>进行开发，是甲骨文公司xVM虚拟化平台技术的一部分。<br><br><br>通过vagrant创建虚拟机需要先导入镜像文件，也就是各种box。默认的存放目录就在用户目录下的.vagrant.d目录下，对于windows系统来说，c:/user/用户名/.vagrant.d<br>如果都放入cpan，导致c盘空间紧张，可以通过环境变量VAGRANT_HOME来设置存放的位置。<br><br><img style="zoom: 67%;" alt="01.环境变量" src="\01.环境变量.png" referrerpolicy="no-referrer"><br><br><br>vagrant的官网下载：<a rel="noopener nofollow" class="external-link" href="https://developer.hashicorp.com" target="_blank">https://developer.hashicorp.com</a><br>centos的镜像：<a rel="noopener nofollow" class="external-link" href="https://cloud.centos.org/centos/" target="_blank">https://cloud.centos.org/centos/</a><br><br>vagrant box list<br><br>vagrant  box add  文件所在位置 --name box名<br>vagrant box add D:\ftp178\01.soft\CentOS-7.box --name centos7
<br>文件所在位置 : 通过此位置指定一个box镜像文件<br>centos7：给box镜像起的名字，安装虚拟机的时候需要使用此名字，尽量简单好记<br><br>vagrant box remove box名字<br>vagrant box remove centos7
<br><br>vagrant init： 初始化一个虚拟机配置文件vagrantfile，需要先创建目录，在对应的目录下运行此命令。<br>​	vagrant init  box名，如果忘记指定box名，则可以vagrantfile当中进行修改<br>vagrant up：启动虚拟机，无论虚拟机是关闭，还是暂停状态，都可以使用此命令来恢复虚拟机的运行<br>vagrant ssh：进入虚拟机，进行操作<br>vagrant suspend：挂起虚拟机<br>vagrant reload：重启虚拟机，重新加载vagrantfile当中的配置信息<br>vagrant halt：关闭虚拟机<br>vagrant status：查看虚拟机的状态<br>vagrant destroy：删除虚拟机，销毁当前的虚拟机]]></description><link>教程\Vagrant课件.html</link><guid isPermaLink="false">教程/Vagrant课件.md</guid><pubDate>Tue, 16 Jan 2024 02:00:25 GMT</pubDate><enclosure url="\01.环境变量.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="\01.环境变量.png"&gt;&lt;/figure&gt;</content:encoded></item></channel></rss>